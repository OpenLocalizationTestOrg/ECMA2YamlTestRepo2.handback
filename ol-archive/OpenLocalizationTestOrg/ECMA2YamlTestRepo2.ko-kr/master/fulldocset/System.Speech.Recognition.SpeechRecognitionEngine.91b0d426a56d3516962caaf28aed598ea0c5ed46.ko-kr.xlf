<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.2" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="markdown" source-language="en-US" target-language="ko-kr">
    <header>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-192e1fd" tool-company="Microsoft" />
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">4e1507b0a4dd184bf9c482917c9c1a540db925be</xliffext:olfilehash>
      <xliffext:olfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">fulldocset\System.Speech.Recognition.SpeechRecognitionEngine.yml</xliffext:olfilepath>
      <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">fulldocset</xliffext:oltranslationpriority>
      <xliffext:oltranslationtype xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">Human Translation</xliffext:oltranslationtype>
      <xliffext:olskeletonhash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">b94eb1b586a4018cc2146ebb85f70ee9b49e7c8c</xliffext:olskeletonhash>
      <xliffext:olxliffhash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">2438bcf9dbedec08492e9e6fb4d249fc811bd84e</xliffext:olxliffhash>
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Provides the means to access and manage an in-process speech recognition engine.</source>
          <target state="translated">액세스 하 고 처리 중인 음성 인식 엔진 관리 방법을 제공 합니다.</target>       </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can create an instance of this class for any of the installed speech recognizers.</source>
          <target state="translated">설치 된 음성 인식기에 대 한이 클래스의 인스턴스를 만들 수 있습니다.</target>       </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get information about which recognizers are installed, use the static &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt; method.</source>
          <target state="translated">인식기가 설치 되어 있는 방법에 대 한 정보를 얻으려면 정적을 사용 하 여 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;</target>       </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve" extradata="MT">
          <source>This class is for running speech recognition engines in-process, and provides control over various aspects of speech recognition, as follows:      -   To create an in-process speech recognizer, use one of the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.%23ctor%2A&gt; constructors.</source>
          <target state="translated">이 클래스 음성 인식 엔진 프로세스 내에서 실행, 되며 음성 인식의 다양 한 측면에 대 한 제어를 다음과 같이 제공:-를 프로세스에서 음성 인식기를 만드는 중 하나를 사용 하 여는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.%23ctor%2A&gt;생성자.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.%23ctor%2A&gt;</target>       </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   To manage speech recognition grammars, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A&gt; methods, and the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A&gt; property.</source>
          <target state="translated">-음성 인식 문법을 사용 하 여 관리할는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A&gt;, 및 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A&gt;메서드 및 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A&gt;속성.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</target>       </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   To configure the input to the recognizer, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt;, or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt; method.</source>
          <target state="translated">-인식기에 대 한 입력을 구성 하려면 다음을 수행 합니다 사용 된 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt;, 또는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;</target>       </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   To perform speech recognition, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt; method.</source>
          <target state="translated">-음성 인식 기능을 수행 하려면 다음을 수행 합니다는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;또는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</target>       </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   To modify how recognition handles silence or unexpected input, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt; properties.</source>
          <target state="translated">-인식 대기 또는 예기치 않은 입력을 처리 하는 방법을 수정 하려면 사용 된 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;, 및 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;속성.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</target>       </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   To change the number of alternates the recognizer returns, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates%2A&gt; property.</source>
          <target state="translated">-인식기에서 반환 하는 대체 항목의 수를 변경 하려면 사용 된 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates%2A&gt;속성.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates%2A&gt;</target>       </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer returns recognition results in a &lt;xref:System.Speech.Recognition.RecognitionResult&gt; object.</source>
          <target state="translated">인식기에서 인식 결과 반환 합니다.는 &lt;xref:System.Speech.Recognition.RecognitionResult&gt;개체입니다.&lt;/xref:System.Speech.Recognition.RecognitionResult&gt;</target>       </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   To synchronize changes to the recognizer, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt; method.</source>
          <target state="translated">-인식기에 변경 내용을 동기화를 사용 하 여는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</target>       </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer uses more than one thread to perform tasks.</source>
          <target state="translated">인식기에서 둘 이상의 스레드를 사용 하 여 작업을 수행할 수 있습니다.</target>       </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   To emulate input to the recognizer, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt; and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt; methods.</source>
          <target state="translated">-인식기에 대 한 입력을 에뮬레이트 하려면 사용 된 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;및 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;</target>       </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve" extradata="MT">
          <source>The SpeechRecognitionEngine object is for the sole use of the process that instantiated the object.</source>
          <target state="translated">개체를 인스턴스화할 하는 프로세스의 사용 하기 위한 SpeechRecognitionEngine 개체가입니다.</target>       </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve" extradata="MT">
          <source>By contrast, the &lt;xref:System.Speech.Recognition.SpeechRecognizer&gt; shares a single recognizer with any application that wants to use it.</source>
          <target state="translated">반대로, &lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;합니다. 하고자 하는 응용 프로그램과 함께 단일 인식기를 공유 합니다.&lt;/xref:System.Speech.Recognition.SpeechRecognizer&gt;</target>       </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve" extradata="MT">
          <source>&gt; <ph id="ph1">[!NOTE]</ph> &gt;  Always call &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Dispose%2A&gt; before you release your last reference to the speech recognizer.</source>
          <target state="translated">&gt; <ph id="ph1">[!NOTE]</ph> &gt; 항상 호출 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Dispose%2A&gt;음성 인식기에 대 한 마지막 참조를 해제 하기 전에.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.Dispose%2A&gt;</target>       </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve" extradata="MT">
          <source>Otherwise, the resources it is using will not be freed until the garbage collector calls the recognizer object's <ph id="ph1">`Finalize`</ph> method.</source>
          <target state="translated">가비지 수집기 인식기 개체를 호출할 때까지 사용 중인 리소스를 해제 되지 것입니다 그렇지 않으면 <ph id="ph1">`Finalize`</ph> 메서드.</target>       </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Initializes a new instance of the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> class using the default speech recognizer for the system.</source>
          <target state="translated">새 인스턴스를 초기화는 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 클래스는 시스템에 대 한 기본 음성 인식기를 사용 합니다.</target>       </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve" extradata="MT">
          <source>Before the speech recognizer can begin speech recognition, you must load at least one recognition grammar and configure the input for the recognizer.</source>
          <target state="translated">음성 인식기에서 음성 인식 기능을 시작 하려면 먼저 하나 이상의 인식 문법을 로드할 하 고 인식기에 대 한 입력을 구성 해야 합니다.</target>       </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve" extradata="MT">
          <source>To load a grammar, call the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt; method.</source>
          <target state="translated">문법에 로드 하려면 호출 된 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;또는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</target>       </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve" extradata="MT">
          <source>To configure the audio input, use one of the following methods:      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt;</source>
          <target state="translated">오디오 입력을 구성 하려면 다음 방법 중 하나를 사용:- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;</target>       </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>Initializes a new instance of the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> class using the default speech recognizer for a specified locale.</source>
          <target state="translated">새 인스턴스를 초기화는 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 클래스는 지정 된 로캘에 대 한 기본 음성 인식기를 사용 합니다.</target>       </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve" extradata="MT">
          <source>Microsoft Windows and the System.Speech API accept all valid language-country codes.</source>
          <target state="translated">Microsoft Windows와 System.Speech API는 모든 유효한 언어 국가 코드를 받습니다.</target>       </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve" extradata="MT">
          <source>To perform speech recognition using the language specified in the <ph id="ph1">`CultureInfo`</ph> argument, a speech recognition engine that supports that language-country code must be installed.</source>
          <target state="translated">에 지정 된 언어를 사용 하 여 음성 인식을 수행 하는 <ph id="ph1">`CultureInfo`</ph> 인수를 지 원하는 언어 국가 코드를 설치 해야 하는 음성 인식 엔진입니다.</target>       </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve" extradata="MT">
          <source>The speech recognition engines that shipped with Microsoft Windows 7 work with the following language-country codes.</source>
          <target state="translated">Microsoft Windows 7과 함께 제공 된 음성 인식 엔진 다음 언어 국가 코드를 사용 합니다.</target>       </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   en-GB.</source>
          <target state="translated">-EN-GB 합니다.</target>       </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve" extradata="MT">
          <source>English (United Kingdom)      -   en-US.</source>
          <target state="translated">영어 (영국)-EN-US입니다.</target>       </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve" extradata="MT">
          <source>English (United States)      -   de-DE.</source>
          <target state="translated">영어 (미국)-d e d E.</target>       </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve" extradata="MT">
          <source>German (Germany)      -   es-ES.</source>
          <target state="translated">독일어 (독일)-ES-ES 합니다.</target>       </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve" extradata="MT">
          <source>Spanish (Spain)      -   fr-FR.</source>
          <target state="translated">스페인어 (스페인)-fr fr.</target>       </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve" extradata="MT">
          <source>French (France)      -   ja-JP.</source>
          <target state="translated">프랑스어 (프랑스)-JA-JP 합니다.</target>       </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve" extradata="MT">
          <source>Japanese (Japan)      -   zh-CN.</source>
          <target state="translated">일본어 (일본)-ZH-CN 합니다.</target>       </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve" extradata="MT">
          <source>Chinese (China)      -   zh-TW.</source>
          <target state="translated">중국어 (중국)-zh-tw로 제공 합니다.</target>       </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve" extradata="MT">
          <source>Chinese (Taiwan)       Two-letter language codes such as "en", "fr", or "es" are also permitted.</source>
          <target state="translated">중국어 (대만) 두 문자 언어 코드 "en", "fr" 또는 "es" 등도 허용 됩니다.</target>       </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve" extradata="MT">
          <source>Before the speech recognizer can begin recognition, you must load at least one speech recognition grammar and configure the input for the recognizer.</source>
          <target state="translated">음성 인식기에서 인식을 시작 하려면 먼저 하나 이상의 음성 인식 문법을 로드할 하 고 인식기에 대 한 입력을 구성 해야 합니다.</target>       </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve" extradata="MT">
          <source>To load a grammar, call the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt; method.</source>
          <target state="translated">문법에 로드 하려면 호출 된 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;또는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</target>       </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve" extradata="MT">
          <source>To configure the audio input, use one of the following methods:      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt;</source>
          <target state="translated">오디오 입력을 구성 하려면 다음 방법 중 하나를 사용:- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;</target>       </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>The locale that the speech recognizer must support.</source>
          <target state="translated">음성 인식기에서 지원 해야 하는 로캘.</target>       </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>None of the installed speech recognizers support the specified locale, or <bpt id="p1">&lt;code&gt;</bpt><ph id="ph1">culture</ph><ept id="p1">&lt;/code&gt;</ept> is the invariant culture.</source>
          <target state="translated">지정 된 로캘을 지 원하는 없는 설치 된 음성 인식기 또는 <bpt id="p1">&lt;code&gt;</bpt> <ph id="ph1">culture</ph> <ept id="p1">&lt;/code&gt;</ept> 고정 문화권입니다.</target>       </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;Culture&lt;/code&gt;</ph> is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;Culture&lt;/code&gt;</ph>is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>Initializes a new instance of the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> using the information in a <bpt id="p2">&lt;xref href="System.Speech.Recognition.RecognizerInfo"&gt;</bpt><ept id="p2">&lt;/xref&gt;</ept> object to specify the recognizer to use.</source>
          <target state="translated">새 인스턴스를 초기화는 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 정보를 사용 하는 <bpt id="p2">&lt;xref href="System.Speech.Recognition.RecognizerInfo"&gt;</bpt> <ept id="p2">&lt;/xref&gt;</ept> 인식기에서 사용 하도록 지정 하는 개체입니다.</target>       </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can create an instance of this class for any of the installed speech recognizers.</source>
          <target state="translated">설치 된 음성 인식기에 대 한이 클래스의 인스턴스를 만들 수 있습니다.</target>       </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get information about which recognizers are installed, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt; method.</source>
          <target state="translated">인식기가 설치 되어 있는 방법에 대 한 정보를 가져오려면는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;</target>       </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve" extradata="MT">
          <source>Before the speech recognizer can begin recognition, you must load at least one speech recognition grammar and configure the input for the recognizer.</source>
          <target state="translated">음성 인식기에서 인식을 시작 하려면 먼저 하나 이상의 음성 인식 문법을 로드할 하 고 인식기에 대 한 입력을 구성 해야 합니다.</target>       </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve" extradata="MT">
          <source>To load a grammar, call the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt; method.</source>
          <target state="translated">문법에 로드 하려면 호출 된 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;또는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</target>       </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve" extradata="MT">
          <source>To configure the audio input, use one of the following methods:      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt;</source>
          <target state="translated">오디오 입력을 구성 하려면 다음 방법 중 하나를 사용:- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;</target>       </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>The information for the specific speech recognizer.</source>
          <target state="translated">특정 음성 인식기에 대 한 정보입니다.</target>       </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>Initializes a new instance of the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> class with a string parameter that specifies the name of the recognizer to use.</source>
          <target state="translated">새 인스턴스를 초기화는 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 사용할 인식기의 이름을 지정 하는 문자열 매개 변수를 사용 하 여 클래스입니다.</target>       </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve" extradata="MT">
          <source>The token name of the recognizer is the value of the &lt;xref:System.Speech.Recognition.RecognizerInfo.Id%2A&gt; property of the &lt;xref:System.Speech.Recognition.RecognizerInfo&gt; object returned by the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A&gt; property of the recognizer.</source>
          <target state="translated">토큰 이름 인식기의 값인는 &lt;xref:System.Speech.Recognition.RecognizerInfo.Id%2A&gt;속성의는 &lt;xref:System.Speech.Recognition.RecognizerInfo&gt;에서 반환 된 개체는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A&gt;인식기 속성.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A&gt; &lt;/xref:System.Speech.Recognition.RecognizerInfo&gt; &lt;/xref:System.Speech.Recognition.RecognizerInfo.Id%2A&gt;</target>       </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get a collection of all the installed recognizers, use the static &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt; method.</source>
          <target state="translated">설치 된 모든 인식기의 컬렉션을 사용 정적 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;</target>       </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve" extradata="MT">
          <source>Before the speech recognizer can begin recognition, you must load at least one speech recognition grammar and configure the input for the recognizer.</source>
          <target state="translated">음성 인식기에서 인식을 시작 하려면 먼저 하나 이상의 음성 인식 문법을 로드할 하 고 인식기에 대 한 입력을 구성 해야 합니다.</target>       </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve" extradata="MT">
          <source>To load a grammar, call the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt; method.</source>
          <target state="translated">문법에 로드 하려면 호출 된 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;또는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</target>       </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve" extradata="MT">
          <source>To configure the audio input, use one of the following methods:      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt;</source>
          <target state="translated">오디오 입력을 구성 하려면 다음 방법 중 하나를 사용:- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;</target>       </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>The token name of the speech recognizer to use.</source>
          <target state="translated">사용할 음성 인식기의 토큰 이름입니다.</target>       </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>No speech recognizer with that token name is installed, or <bpt id="p1">&lt;code&gt;</bpt><ph id="ph1">recognizerId</ph><ept id="p1">&lt;/code&gt;</ept> is the empty string ("").</source>
          <target state="translated">토큰 이름이 없는 음성 인식기가 설치 되어 또는 <bpt id="p1">&lt;code&gt;</bpt> <ph id="ph1">recognizerId</ph> <ept id="p1">&lt;/code&gt;</ept> 은 빈 문자열 ("").</target>       </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;recognizerId&lt;/code&gt;</ph> is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;recognizerId&lt;/code&gt;</ph>is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>Gets the format of the audio being received by the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated">수신 된 오디오의 형식을 가져옵니다는 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept>합니다.</target>       </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve" extradata="MT">
          <source>To configure the audio input, use one of the following methods:      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt;</source>
          <target state="translated">오디오 입력을 구성 하려면 다음 방법 중 하나를 사용:- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;</target>       </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>The format of audio at the input to the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> instance, or <bpt id="p2">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p2">&lt;/xref&gt;</ept> if the input is not configured or set to the null input.</source>
          <target state="translated">에 대 한 입력에 오디오 형식의 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 인스턴스, 또는 <bpt id="p2">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt> <ept id="p2">&lt;/xref&gt;</ept> 입력 구성 하지 않거나 null 입력으로 설정 하는 경우.</target>       </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>Gets the level of the audio being received by the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated">수신 된 오디오의 수준을 가져옵니다는 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept>합니다.</target>       </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve" extradata="MT">
          <source>The value 0 represents silence, and 100 represents the maximum input volume.</source>
          <target state="translated">값 0 대기를 나타내고 100 최대 입력된 부피를 나타냅니다.</target>       </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>The audio level of the input to the speech recognizer, from 0 through 100.</source>
          <target state="translated">0에서 100 사이의 음성 인식기에서 입력의 오디오 수준입니다.</target>       </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>Raised when the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> reports the level of its audio input.</source>
          <target state="translated">발생 시기는 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 오디오 입력 값의 수준을 보고 합니다.</target>       </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve" extradata="MT">
          <source>The &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; raises this event multiple times per second.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;1 초에 여러 번이이 이벤트를 발생 시킵니다.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve" extradata="MT">
          <source>The frequency with which the event is raised depends on the computer on which the application is running.</source>
          <target state="translated">응용 프로그램이 실행 중인 컴퓨터에는 이벤트가 발생 하는 빈도 따라 다릅니다.</target>       </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get the audio level at the time of the event, use the &lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A&gt; property of the associated &lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt;.</source>
          <target state="translated">오디오 수준에서 이벤트의 시간을 가져오려면 &lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A&gt; &lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt;.&lt;/xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt; 연결된의 속성&lt;/xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A&gt; 을 사용 하 여</target>       </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get the current audio level of the input to the recognizer, use the recognizer's &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel%2A&gt; property.</source>
          <target state="translated">오디오 현재 수준의 인식기에 대 한 입력을 사용 하면 인식기 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel%2A&gt;속성.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel%2A&gt;</target>       </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create an AudioLevelUpdated delegate, you identify the method that will handle the event.</source>
          <target state="translated">AudioLevelUpdated 대리자를 만들 때 이벤트를 처리 하는 메서드를 식별 합니다.</target>       </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다.</target>       </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다.</target>       </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">이벤트 처리기 대리자에 대 한 자세한 내용은 참조 <bpt id="p1">[</bpt>이벤트 및 대리자<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>합니다.</target>       </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">추가할 수 있습니다.</target>       </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>Gets the current location in the audio stream being generated by the device that is providing input to the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated">에 대 한 입력을 제공 하는 장치에 의해 생성 되 고 오디오 스트림의 현재 위치를 가져옵니다는 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept>합니다.</target>       </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve" extradata="MT">
          <source>The AudioPosition property references the input device's position in its generated audio stream.</source>
          <target state="translated">AudioPosition 속성에는 입력된 장치 위치에 생성 된 오디오 스트림 참조합니다.</target>       </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve" extradata="MT">
          <source>By contrast, the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt; property references the recognizer's position within its audio input.</source>
          <target state="translated">반면,는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;속성 오디오 입력 내의 인식기에서 위치를 참조 합니다.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</target>       </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve" extradata="MT">
          <source>These positions can be different.</source>
          <target state="translated">이 위치는 다를 수 있습니다.</target>       </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve" extradata="MT">
          <source>For example, if the recognizer has received input for which it has not yet generated a recognition result then the value of the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt; property is less than the value of the AudioPosition property.</source>
          <target state="translated">인식기에서 받는 경우 하지는 자신이 입력 하 아직 인식 결과 다음 값을 생성 합니다. 예를 들어는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;AudioPosition 속성의 값 보다 작아야 합니다.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</target>       </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source>The current location in the audio stream being generated by the input device.</source>
          <target state="translated">오디오 입력된 장치에 의해 생성 되 고 스트림의 현재 위치입니다.</target>       </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source>Raised when the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> detects a problem in the audio signal.</source>
          <target state="translated">발생 시기는 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 오디오 신호의 문제를 발견 합니다.</target>       </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get which problem occurred, use the &lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A&gt; property of the associated &lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt;.</source>
          <target state="translated">어떤 문제가 발생 한을 가져오려면 &lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A&gt; &lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt;.&lt;/xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt; 연결된의 속성&lt;/xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A&gt; 을 사용 하 여</target>       </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create an AudioSignalProblemOccurred delegate, you identify the method that will handle the event.</source>
          <target state="translated">AudioSignalProblemOccurred 대리자를 만들 때 이벤트를 처리 하는 메서드를 식별 합니다.</target>       </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다.</target>       </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다.</target>       </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">이벤트 처리기 대리자에 대 한 자세한 내용은 참조 <bpt id="p1">[</bpt>이벤트 및 대리자<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>합니다.</target>       </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">추가할 수 있습니다.</target>       </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source>Gets the state of the audio being received by the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated">수신 된 오디오의 상태를 가져옵니다는 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept>합니다.</target>       </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve" extradata="MT">
          <source>The AudioState property represents the audio state with a member of the &lt;xref:System.Speech.Recognition.AudioState&gt; enumeration.</source>
          <target state="translated">AudioState 속성의 멤버와 오디오 상태를 나타내는 &lt;xref:System.Speech.Recognition.AudioState&gt;열거형.&lt;/xref:System.Speech.Recognition.AudioState&gt;</target>       </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source>The state of the audio input to the speech recognizer.</source>
          <target state="translated">음성 인식기에 오디오 입력의 상태입니다.</target>       </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source>Raised when the state changes in the audio being received by the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated">오디오의 상태 변경을 수신 하는 경우 발생 하는 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept>합니다.</target>       </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get the audio state at the time of the event, use the &lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A&gt; property of the associated &lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs&gt;.</source>
          <target state="translated">이벤트의 시간에 오디오 상태를 가져오려면 &lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A&gt; &lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs&gt;.&lt;/xref:System.Speech.Recognition.AudioStateChangedEventArgs&gt; 연결된의 속성&lt;/xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A&gt; 을 사용 하 여</target>       </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get the current audio state of the input to the recognizer, use the recognizer's &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A&gt; property.</source>
          <target state="translated">사용 하 여 인식기에서 인식기에 대 한 입력의 오디오 현재 상태를 가져오려면 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A&gt;속성.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A&gt;</target>       </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about audio state, see the &lt;xref:System.Speech.Recognition.AudioState&gt; enumeration.</source>
          <target state="translated">오디오 상태에 대 한 자세한 내용은 참조는 &lt;xref:System.Speech.Recognition.AudioState&gt;열거형.&lt;/xref:System.Speech.Recognition.AudioState&gt;</target>       </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create an AudioStateChanged delegate, you identify the method that will handle the event.</source>
          <target state="translated">AudioStateChanged 대리자를 만들 때 이벤트를 처리 하는 메서드를 식별 합니다.</target>       </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다.</target>       </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다.</target>       </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">이벤트 처리기 대리자에 대 한 자세한 내용은 참조 <bpt id="p1">[</bpt>이벤트 및 대리자<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>합니다.</target>       </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">추가할 수 있습니다.</target>       </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve">
          <source>Gets or sets the time interval during which a <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> accepts input containing only background noise, before finalizing recognition.</source>
          <target state="translated">시간 간격을 가져오거나는 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 인식을 마무리 하기 전에 입력된 포함만 배경 노이즈를 허용 합니다.</target>       </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve" extradata="MT">
          <source>Each speech recognizer has an algorithm to distinguish between silence and speech.</source>
          <target state="translated">음성 인식기 각 대기 및 음성 간을 서로 구별 하는 알고리즘을 있습니다.</target>       </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer classifies as background noise any non-silence input that does not match the initial rule of any of the recognizer's loaded and enabled speech recognition grammars.</source>
          <target state="translated">인식기에서 인식기의 초기 규칙이 일치 하지 않는 모든 비-대기 입력 배경 노이즈를 로드 하 고 음성 인식 문법을 설정으로 분류 합니다.</target>       </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the recognizer receives only background noise and silence within the babble timeout interval, then the recognizer finalizes that recognition operation.</source>
          <target state="translated">임의 시간 제한 간격 내에서 배경 노이즈 및 대기를 수신 하는 인식기를 하는 경우 인식기에서 인식 작업을 완료 합니다.</target>       </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   For asynchronous recognition operations, the recognizer raises the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt; event, where the &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A?displayProperty=fullName&gt; property is <ph id="ph1">`true`</ph>, and the &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=fullName&gt; property is <ph id="ph2">`null`</ph>.</source>
          <target state="translated">-인식기 발생 비동기 인식 작업에 대 한는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;이벤트, 여기서는 &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A?displayProperty=fullName&gt;속성은 <ph id="ph1">`true`</ph>, 및 &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=fullName&gt;속성은 <ph id="ph2">`null`</ph>.&lt;/xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=fullName&gt; &lt;/xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A?displayProperty=fullName&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</target>       </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   For synchronous recognition operations and emulation, the recognizer returns <ph id="ph1">`null`</ph>, instead of a valid &lt;xref:System.Speech.Recognition.RecognitionResult&gt;.</source>
          <target state="translated">-인식기 동기 인식 작업 및 에뮬레이션에 대 한 반환 <ph id="ph1">`null`</ph>에 유효한 &lt;xref:System.Speech.Recognition.RecognitionResult&gt;.&lt;/xref:System.Speech.Recognition.RecognitionResult&gt; 대신</target>       </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the babble timeout period is set to 0, the recognizer does not perform a babble timeout check.</source>
          <target state="translated">임의 제한 시간을 0으로 설정 하는 경우 인식기에서 임의 시간 제한을 확인을 수행 하지 않습니다.</target>       </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve" extradata="MT">
          <source>The timeout interval can be any non-negative value.</source>
          <target state="translated">시간 제한 간격 임의의 음수가 아닌 값일 수 있습니다.</target>       </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve" extradata="MT">
          <source>The default is 0 seconds.</source>
          <target state="translated">기본값은 0 초입니다.</target>       </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve">
          <source>The duration of the time interval.</source>
          <target state="translated">시간 간격의 기간입니다.</target>       </trans-unit>
        <trans-unit id="208" translate="yes" xml:space="preserve">
          <source>This property is set to less than 0 seconds.</source>
          <target state="translated">이 속성은 0 초 보다 작게 설정 됩니다.</target>       </trans-unit>
        <trans-unit id="209" translate="yes" xml:space="preserve">
          <source>Disposes the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> object.</source>
          <target state="translated">삭제는 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 개체입니다.</target>       </trans-unit>
        <trans-unit id="210" translate="yes" xml:space="preserve">
          <source>Disposes the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> object and releases resources used during the session.</source>
          <target state="translated">삭제는 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 세션 중 사용 되는 개체 및 버전 리소스입니다.</target>       </trans-unit>
        <trans-unit id="211" translate="yes" xml:space="preserve">
          <source><bpt id="p1">&lt;xref uid="langword_csharp_true" name="true" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> to release both managed and unmanaged resources; <bpt id="p2">&lt;xref uid="langword_csharp_false" name="false" href=""&gt;</bpt><ept id="p2">&lt;/xref&gt;</ept> to release only unmanaged resources.</source>
          <target state="translated"><bpt id="p1">&lt;xref uid="langword_csharp_true" name="true" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>관리 되는 관리 되지 않는 리소스만 해제 하려면 <bpt id="p2">&lt;xref uid="langword_csharp_false" name="false" href=""&gt;</bpt> <ept id="p2">&lt;/xref&gt;</ept> 만 관리 되지 않는 리소스를 해제 합니다.</target>       </trans-unit>
        <trans-unit id="212" translate="yes" xml:space="preserve">
          <source>Emulates input of a phrase to the speech recognizer, using text in place of audio for synchronous speech recognition.</source>
          <target state="translated">음성 인식기에서 오디오 대신 텍스트를 사용 하 여 동기 음성 인식에 대 한 입력 구의 에뮬레이션 합니다.</target>       </trans-unit>
        <trans-unit id="213" translate="yes" xml:space="preserve" extradata="MT">
          <source>The speech recognizer raises the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; events as if the recognition operation is not emulated.</source>
          <target state="translated">음성 인식기 발생은 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;, 및 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;이벤트 인식 작업 에뮬레이트되지 않은 마치.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</target>       </trans-unit>
        <trans-unit id="214" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers that ship with Vista and Windows 7 ignore case and character width when applying grammar rules to the input phrase.</source>
          <target state="translated">인식기 Vista 및 Windows 7과 함께 제공 되는 대/소문자를 무시 하 고 입력된 구를에 문법 규칙을 적용 하는 경우 너비를 문자.</target>       </trans-unit>
        <trans-unit id="215" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about this type of comparison, see the &lt;xref:System.Globalization.CompareOptions&gt; enumeration values &lt;xref:System.Globalization.CompareOptions&gt; and &lt;xref:System.Globalization.CompareOptions&gt;.</source>
          <target state="translated">이 유형의 비교에 대 한 자세한 내용은 참조는 &lt;xref:System.Globalization.CompareOptions&gt;열거형 값과 &lt;xref:System.Globalization.CompareOptions&gt;및 &lt;xref:System.Globalization.CompareOptions&gt;.&lt;/xref:System.Globalization.CompareOptions&gt; &lt;/xref:System.Globalization.CompareOptions&gt; &lt;/xref:System.Globalization.CompareOptions&gt;</target>       </trans-unit>
        <trans-unit id="216" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</source>
          <target state="translated">또한 인식기는 새 줄 및 추가 공백을 무시 하 고 문장 부호 리터럴 입력으로 처리 합니다.</target>       </trans-unit>
        <trans-unit id="217" translate="yes" xml:space="preserve">
          <source>The input for the recognition operation.</source>
          <target state="translated">인식 작업에 대 한 입력입니다.</target>       </trans-unit>
        <trans-unit id="218" translate="yes" xml:space="preserve">
          <source>The result for the recognition operation, or <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> if the operation is not successful or the recognizer is not enabled.</source>
          <target state="translated">인식 작업에 대 한 결과 또는 <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 는 작업은 실패 하거나 인식기를 사용할 수 없습니다.</target>       </trans-unit>
        <trans-unit id="219" translate="yes" xml:space="preserve">
          <source>The recognizer has no speech recognition grammars loaded.</source>
          <target state="translated">인식기에 로드 된 음성 인식 문법 없습니다.</target>       </trans-unit>
        <trans-unit id="220" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;inputText&lt;/code&gt;</ph> is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;inputText&lt;/code&gt;</ph>is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="221" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;inputText&lt;/code&gt;</ph> is the empty string ("").</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;inputText&lt;/code&gt;</ph>가 빈 문자열 ("").</target>       </trans-unit>
        <trans-unit id="222" translate="yes" xml:space="preserve">
          <source>Emulates input of specific words to the speech recognizer, using text in place of audio for synchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the words and the loaded speech recognition grammars.</source>
          <target state="translated">음성 인식기 오디오 대신 텍스트를 사용 하 여 동기 음성 인식에 특정 단어의 입력을 에뮬레이트하고 인식기에서 단어 및 로드 된 음성 인식 문법 유니코드 비교를 처리 하는 방법을 지정 합니다.</target>       </trans-unit>
        <trans-unit id="223" translate="yes" xml:space="preserve" extradata="MT">
          <source>The speech recognizer raises the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; events as if the recognition operation is not emulated.</source>
          <target state="translated">음성 인식기 발생은 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;, 및 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;이벤트 인식 작업 에뮬레이트되지 않은 마치.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</target>       </trans-unit>
        <trans-unit id="224" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer uses <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">인식기에서 사용 하 여 <ph id="ph1">`compareOptions`</ph> 때 문법 규칙 입력된 구문에 적용 합니다.</target>       </trans-unit>
        <trans-unit id="225" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the &lt;xref:System.Globalization.CompareOptions&gt; or &lt;xref:System.Globalization.CompareOptions&gt; value is present.</source>
          <target state="translated">인식기 Vista 및 Windows 7과 함께 제공 되는 경우 대/소문자를 무시는 &lt;xref:System.Globalization.CompareOptions&gt;또는 &lt;xref:System.Globalization.CompareOptions&gt;값이 있는.&lt;/xref:System.Globalization.CompareOptions&gt; &lt;/xref:System.Globalization.CompareOptions&gt;</target>       </trans-unit>
        <trans-unit id="226" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer always ignores the character width and never ignores the Kana type.</source>
          <target state="translated">인식기에서 항상 문자 너비를 무시 하 고는 일본어가 나 형식을 무시 하지 않습니다.</target>       </trans-unit>
        <trans-unit id="227" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer also ignores new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">또한 인식기에서 줄 바꿈은 및 추가 공백을 무시 하 고 문장 부호 리터럴 입력으로 처리 합니다.</target>       </trans-unit>
        <trans-unit id="228" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about character width and Kana type, see the &lt;xref:System.Globalization.CompareOptions&gt; enumeration.</source>
          <target state="translated">문자 너비 및 일본어가 나 형식에 대 한 자세한 내용은 참조는 &lt;xref:System.Globalization.CompareOptions&gt;열거형.&lt;/xref:System.Globalization.CompareOptions&gt;</target>       </trans-unit>
        <trans-unit id="229" translate="yes" xml:space="preserve">
          <source>An array of word units that contains the input for the recognition operation.</source>
          <target state="translated">인식 작업에 대 한 입력이 포함 된 배열 단어 단위입니다.</target>       </trans-unit>
        <trans-unit id="230" translate="yes" xml:space="preserve">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">에뮬레이트된 인식 작업에 사용할 비교 유형을 설명 하는 열거형 값의 비트 조합입니다.</target>       </trans-unit>
        <trans-unit id="231" translate="yes" xml:space="preserve">
          <source>The result for the recognition operation, or <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> if the operation is not successful or the recognizer is not enabled.</source>
          <target state="translated">인식 작업에 대 한 결과 또는 <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 는 작업은 실패 하거나 인식기를 사용할 수 없습니다.</target>       </trans-unit>
        <trans-unit id="232" translate="yes" xml:space="preserve">
          <source>The recognizer has no speech recognition grammars loaded.</source>
          <target state="translated">인식기에 로드 된 음성 인식 문법 없습니다.</target>       </trans-unit>
        <trans-unit id="233" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;wordUnits&lt;/code&gt;</ph> is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;wordUnits&lt;/code&gt;</ph>is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="234" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;wordUnits&lt;/code&gt;</ph> contains one or more <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> elements.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;wordUnits&lt;/code&gt;</ph>하나 이상 포함 <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 요소입니다.</target>       </trans-unit>
        <trans-unit id="235" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;compareOptions&lt;/code&gt;</ph> contains the <ph id="ph2">&lt;xref:System.Globalization.CompareOptions&gt;</ph>, <ph id="ph3">&lt;xref:System.Globalization.CompareOptions&gt;</ph>, or <ph id="ph4">&lt;xref:System.Globalization.CompareOptions&gt;</ph> flag.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;compareOptions&lt;/code&gt;</ph>포함 된 <ph id="ph2">&lt;xref:System.Globalization.CompareOptions&gt;</ph>, <ph id="ph3">&lt;xref:System.Globalization.CompareOptions&gt;</ph>, 또는 <ph id="ph4">&lt;xref:System.Globalization.CompareOptions&gt;</ph> 플래그입니다.</target>       </trans-unit>
        <trans-unit id="236" translate="yes" xml:space="preserve">
          <source>Emulates input of a phrase to the speech recognizer, using text in place of audio for synchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the phrase and the loaded speech recognition grammars.</source>
          <target state="translated">음성 인식기에서 오디오 대신 텍스트를 사용 하 여 동기 음성 인식에 대 한 입력 구의 에뮬레이트하고 인식기는 구를 검색 및 로드 된 음성 인식 문법 유니코드 비교를 처리 하는 방법을 지정 합니다.</target>       </trans-unit>
        <trans-unit id="237" translate="yes" xml:space="preserve" extradata="MT">
          <source>The speech recognizer raises the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; events as if the recognition operation is not emulated.</source>
          <target state="translated">음성 인식기 발생은 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;, 및 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;이벤트 인식 작업 에뮬레이트되지 않은 마치.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</target>       </trans-unit>
        <trans-unit id="238" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer uses <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">인식기에서 사용 하 여 <ph id="ph1">`compareOptions`</ph> 때 문법 규칙 입력된 구문에 적용 합니다.</target>       </trans-unit>
        <trans-unit id="239" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the &lt;xref:System.Globalization.CompareOptions&gt; or &lt;xref:System.Globalization.CompareOptions&gt; value is present.</source>
          <target state="translated">인식기 Vista 및 Windows 7과 함께 제공 되는 경우 대/소문자를 무시는 &lt;xref:System.Globalization.CompareOptions&gt;또는 &lt;xref:System.Globalization.CompareOptions&gt;값이 있는.&lt;/xref:System.Globalization.CompareOptions&gt; &lt;/xref:System.Globalization.CompareOptions&gt;</target>       </trans-unit>
        <trans-unit id="240" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer always ignores the character width and never ignores the Kana type.</source>
          <target state="translated">인식기에서 항상 문자 너비를 무시 하 고는 일본어가 나 형식을 무시 하지 않습니다.</target>       </trans-unit>
        <trans-unit id="241" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer also ignores new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">또한 인식기에서 줄 바꿈은 및 추가 공백을 무시 하 고 문장 부호 리터럴 입력으로 처리 합니다.</target>       </trans-unit>
        <trans-unit id="242" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about character width and Kana type, see the &lt;xref:System.Globalization.CompareOptions&gt; enumeration.</source>
          <target state="translated">문자 너비 및 일본어가 나 형식에 대 한 자세한 내용은 참조는 &lt;xref:System.Globalization.CompareOptions&gt;열거형.&lt;/xref:System.Globalization.CompareOptions&gt;</target>       </trans-unit>
        <trans-unit id="243" translate="yes" xml:space="preserve">
          <source>The input phrase for the recognition operation.</source>
          <target state="translated">인식 작업에 대 한 입력된 구입니다.</target>       </trans-unit>
        <trans-unit id="244" translate="yes" xml:space="preserve">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">에뮬레이트된 인식 작업에 사용할 비교 유형을 설명 하는 열거형 값의 비트 조합입니다.</target>       </trans-unit>
        <trans-unit id="245" translate="yes" xml:space="preserve">
          <source>The result for the recognition operation, or <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> if the operation is not successful or the recognizer is not enabled.</source>
          <target state="translated">인식 작업에 대 한 결과 또는 <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 는 작업은 실패 하거나 인식기를 사용할 수 없습니다.</target>       </trans-unit>
        <trans-unit id="246" translate="yes" xml:space="preserve">
          <source>The recognizer has no speech recognition grammars loaded.</source>
          <target state="translated">인식기에 로드 된 음성 인식 문법 없습니다.</target>       </trans-unit>
        <trans-unit id="247" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;inputText&lt;/code&gt;</ph> is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;inputText&lt;/code&gt;</ph>is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="248" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;inputText&lt;/code&gt;</ph> is the empty string ("").</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;inputText&lt;/code&gt;</ph>가 빈 문자열 ("").</target>       </trans-unit>
        <trans-unit id="249" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;compareOptions&lt;/code&gt;</ph> contains the <ph id="ph2">&lt;xref:System.Globalization.CompareOptions&gt;</ph>, <ph id="ph3">&lt;xref:System.Globalization.CompareOptions&gt;</ph>, or <ph id="ph4">&lt;xref:System.Globalization.CompareOptions&gt;</ph> flag.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;compareOptions&lt;/code&gt;</ph>포함 된 <ph id="ph2">&lt;xref:System.Globalization.CompareOptions&gt;</ph>, <ph id="ph3">&lt;xref:System.Globalization.CompareOptions&gt;</ph>, 또는 <ph id="ph4">&lt;xref:System.Globalization.CompareOptions&gt;</ph> 플래그입니다.</target>       </trans-unit>
        <trans-unit id="250" translate="yes" xml:space="preserve">
          <source>Emulates input of a phrase to the speech recognizer, using text in place of audio for asynchronous speech recognition.</source>
          <target state="translated">음성 인식기에서 오디오 대신 텍스트를 사용 하 여 비동기 음성 인식에 대 한 입력 구의 에뮬레이션 합니다.</target>       </trans-unit>
        <trans-unit id="251" translate="yes" xml:space="preserve" extradata="MT">
          <source>The speech recognizer raises the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; events as if the recognition operation is not emulated.</source>
          <target state="translated">음성 인식기 발생은 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;, 및 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;이벤트 인식 작업 에뮬레이트되지 않은 마치.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</target>       </trans-unit>
        <trans-unit id="252" translate="yes" xml:space="preserve" extradata="MT">
          <source>When the recognizer completes the asynchronous recognition operation, it raises the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt; event.</source>
          <target state="translated">인식기에서 인식 비동기 작업이 완료 되 면 발생는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;이벤트.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</target>       </trans-unit>
        <trans-unit id="253" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers that ship with Vista and Windows 7 ignore case and character width when applying grammar rules to the input phrase.</source>
          <target state="translated">인식기 Vista 및 Windows 7과 함께 제공 되는 대/소문자를 무시 하 고 입력된 구를에 문법 규칙을 적용 하는 경우 너비를 문자.</target>       </trans-unit>
        <trans-unit id="254" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about this type of comparison, see the &lt;xref:System.Globalization.CompareOptions&gt; enumeration values &lt;xref:System.Globalization.CompareOptions&gt; and &lt;xref:System.Globalization.CompareOptions&gt;.</source>
          <target state="translated">이 유형의 비교에 대 한 자세한 내용은 참조는 &lt;xref:System.Globalization.CompareOptions&gt;열거형 값과 &lt;xref:System.Globalization.CompareOptions&gt;및 &lt;xref:System.Globalization.CompareOptions&gt;.&lt;/xref:System.Globalization.CompareOptions&gt; &lt;/xref:System.Globalization.CompareOptions&gt; &lt;/xref:System.Globalization.CompareOptions&gt;</target>       </trans-unit>
        <trans-unit id="255" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</source>
          <target state="translated">또한 인식기는 새 줄 및 추가 공백을 무시 하 고 문장 부호 리터럴 입력으로 처리 합니다.</target>       </trans-unit>
        <trans-unit id="256" translate="yes" xml:space="preserve">
          <source>The input for the recognition operation.</source>
          <target state="translated">인식 작업에 대 한 입력입니다.</target>       </trans-unit>
        <trans-unit id="257" translate="yes" xml:space="preserve">
          <source>The recognizer has no speech recognition grammars loaded, or the recognizer has an asynchronous recognition operation that is not yet complete.</source>
          <target state="translated">인식기가 로드 되지 음성 인식 문법 또는 인식기에서 아직 완료 되지 않은 비동기 인식 작업이 정의 되어 있습니다.</target>       </trans-unit>
        <trans-unit id="258" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;inputText&lt;/code&gt;</ph> is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;inputText&lt;/code&gt;</ph>is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="259" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;inputText&lt;/code&gt;</ph> is the empty string ("").</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;inputText&lt;/code&gt;</ph>가 빈 문자열 ("").</target>       </trans-unit>
        <trans-unit id="260" translate="yes" xml:space="preserve">
          <source>Emulates input of specific words to the speech recognizer, using an array of <bpt id="p1">&lt;xref href="System.Speech.Recognition.RecognizedWordUnit"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> objects in place of audio for asynchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the words and the loaded speech recognition grammars.</source>
          <target state="translated">음성 인식기의 배열을 사용 하 여에 특정 단어의 입력을 에뮬레이션 <bpt id="p1">&lt;xref href="System.Speech.Recognition.RecognizedWordUnit"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 비동기 음성 인식 기능에 대 한 오디오 대신 개체를 인식기에서 단어 및 로드 된 음성 인식 문법 유니코드 비교를 처리 하는 방법을 지정 합니다.</target>       </trans-unit>
        <trans-unit id="261" translate="yes" xml:space="preserve" extradata="MT">
          <source>The speech recognizer raises the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; events as if the recognition operation is not emulated.</source>
          <target state="translated">음성 인식기 발생은 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;, 및 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;이벤트 인식 작업 에뮬레이트되지 않은 마치.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</target>       </trans-unit>
        <trans-unit id="262" translate="yes" xml:space="preserve" extradata="MT">
          <source>When the recognizer completes the asynchronous recognition operation, it raises the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt; event.</source>
          <target state="translated">인식기에서 인식 비동기 작업이 완료 되 면 발생는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;이벤트.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</target>       </trans-unit>
        <trans-unit id="263" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer uses <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">인식기에서 사용 하 여 <ph id="ph1">`compareOptions`</ph> 때 문법 규칙 입력된 구문에 적용 합니다.</target>       </trans-unit>
        <trans-unit id="264" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the &lt;xref:System.Globalization.CompareOptions&gt; or &lt;xref:System.Globalization.CompareOptions&gt; value is present.</source>
          <target state="translated">인식기 Vista 및 Windows 7과 함께 제공 되는 경우 대/소문자를 무시는 &lt;xref:System.Globalization.CompareOptions&gt;또는 &lt;xref:System.Globalization.CompareOptions&gt;값이 있는.&lt;/xref:System.Globalization.CompareOptions&gt; &lt;/xref:System.Globalization.CompareOptions&gt;</target>       </trans-unit>
        <trans-unit id="265" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
          <target state="translated">인식기에서 항상 문자 너비를 무시 하 고 일본어가 나 형식 무시 해서는 안됩니다.</target>       </trans-unit>
        <trans-unit id="266" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</source>
          <target state="translated">또한 인식기는 새 줄 및 추가 공백을 무시 하 고 문장 부호 리터럴 입력으로 처리 합니다.</target>       </trans-unit>
        <trans-unit id="267" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about character width and Kana type, see the &lt;xref:System.Globalization.CompareOptions&gt; enumeration.</source>
          <target state="translated">문자 너비 및 일본어가 나 형식에 대 한 자세한 내용은 참조는 &lt;xref:System.Globalization.CompareOptions&gt;열거형.&lt;/xref:System.Globalization.CompareOptions&gt;</target>       </trans-unit>
        <trans-unit id="268" translate="yes" xml:space="preserve">
          <source>An array of word units that contains the input for the recognition operation.</source>
          <target state="translated">인식 작업에 대 한 입력이 포함 된 배열 단어 단위입니다.</target>       </trans-unit>
        <trans-unit id="269" translate="yes" xml:space="preserve">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">에뮬레이트된 인식 작업에 사용할 비교 유형을 설명 하는 열거형 값의 비트 조합입니다.</target>       </trans-unit>
        <trans-unit id="270" translate="yes" xml:space="preserve">
          <source>The recognizer has no speech recognition grammars loaded, or the recognizer has an asynchronous recognition operation that is not yet complete.</source>
          <target state="translated">인식기가 로드 되지 음성 인식 문법 또는 인식기에서 아직 완료 되지 않은 비동기 인식 작업이 정의 되어 있습니다.</target>       </trans-unit>
        <trans-unit id="271" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;wordUnits&lt;/code&gt;</ph> is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;wordUnits&lt;/code&gt;</ph>is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="272" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;wordUnits&lt;/code&gt;</ph> contains one or more <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> elements.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;wordUnits&lt;/code&gt;</ph>하나 이상 포함 <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 요소입니다.</target>       </trans-unit>
        <trans-unit id="273" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;compareOptions&lt;/code&gt;</ph> contains the <ph id="ph2">&lt;xref:System.Globalization.CompareOptions&gt;</ph>, <ph id="ph3">&lt;xref:System.Globalization.CompareOptions&gt;</ph>, or <ph id="ph4">&lt;xref:System.Globalization.CompareOptions&gt;</ph> flag.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;compareOptions&lt;/code&gt;</ph>포함 된 <ph id="ph2">&lt;xref:System.Globalization.CompareOptions&gt;</ph>, <ph id="ph3">&lt;xref:System.Globalization.CompareOptions&gt;</ph>, 또는 <ph id="ph4">&lt;xref:System.Globalization.CompareOptions&gt;</ph> 플래그입니다.</target>       </trans-unit>
        <trans-unit id="274" translate="yes" xml:space="preserve">
          <source>Emulates input of a phrase to the speech recognizer, using text in place of audio for asynchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the phrase and the loaded speech recognition grammars.</source>
          <target state="translated">음성 인식기에서 오디오 대신 텍스트를 사용 하 여 비동기 음성 인식에 대 한 입력 구의 에뮬레이트하고 인식기는 구를 검색 및 로드 된 음성 인식 문법 유니코드 비교를 처리 하는 방법을 지정 합니다.</target>       </trans-unit>
        <trans-unit id="275" translate="yes" xml:space="preserve" extradata="MT">
          <source>The speech recognizer raises the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; events as if the recognition operation is not emulated.</source>
          <target state="translated">음성 인식기 발생은 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;, 및 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;이벤트 인식 작업 에뮬레이트되지 않은 마치.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</target>       </trans-unit>
        <trans-unit id="276" translate="yes" xml:space="preserve" extradata="MT">
          <source>When the recognizer completes the asynchronous recognition operation, it raises the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt; event.</source>
          <target state="translated">인식기에서 인식 비동기 작업이 완료 되 면 발생는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;이벤트.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</target>       </trans-unit>
        <trans-unit id="277" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer uses <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">인식기에서 사용 하 여 <ph id="ph1">`compareOptions`</ph> 때 문법 규칙 입력된 구문에 적용 합니다.</target>       </trans-unit>
        <trans-unit id="278" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the &lt;xref:System.Globalization.CompareOptions&gt; or &lt;xref:System.Globalization.CompareOptions&gt; value is present.</source>
          <target state="translated">인식기 Vista 및 Windows 7과 함께 제공 되는 경우 대/소문자를 무시는 &lt;xref:System.Globalization.CompareOptions&gt;또는 &lt;xref:System.Globalization.CompareOptions&gt;값이 있는.&lt;/xref:System.Globalization.CompareOptions&gt; &lt;/xref:System.Globalization.CompareOptions&gt;</target>       </trans-unit>
        <trans-unit id="279" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
          <target state="translated">인식기에서 항상 문자 너비를 무시 하 고 일본어가 나 형식 무시 해서는 안됩니다.</target>       </trans-unit>
        <trans-unit id="280" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</source>
          <target state="translated">또한 인식기는 새 줄 및 추가 공백을 무시 하 고 문장 부호 리터럴 입력으로 처리 합니다.</target>       </trans-unit>
        <trans-unit id="281" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about character width and Kana type, see the &lt;xref:System.Globalization.CompareOptions&gt; enumeration.</source>
          <target state="translated">문자 너비 및 일본어가 나 형식에 대 한 자세한 내용은 참조는 &lt;xref:System.Globalization.CompareOptions&gt;열거형.&lt;/xref:System.Globalization.CompareOptions&gt;</target>       </trans-unit>
        <trans-unit id="282" translate="yes" xml:space="preserve">
          <source>The input phrase for the recognition operation.</source>
          <target state="translated">인식 작업에 대 한 입력된 구입니다.</target>       </trans-unit>
        <trans-unit id="283" translate="yes" xml:space="preserve">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">에뮬레이트된 인식 작업에 사용할 비교 유형을 설명 하는 열거형 값의 비트 조합입니다.</target>       </trans-unit>
        <trans-unit id="284" translate="yes" xml:space="preserve">
          <source>The recognizer has no speech recognition grammars loaded, or the recognizer has an asynchronous recognition operation that is not yet complete.</source>
          <target state="translated">인식기가 로드 되지 음성 인식 문법 또는 인식기에서 아직 완료 되지 않은 비동기 인식 작업이 정의 되어 있습니다.</target>       </trans-unit>
        <trans-unit id="285" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;inputText&lt;/code&gt;</ph> is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;inputText&lt;/code&gt;</ph>is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="286" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;inputText&lt;/code&gt;</ph> is the empty string ("").</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;inputText&lt;/code&gt;</ph>가 빈 문자열 ("").</target>       </trans-unit>
        <trans-unit id="287" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;compareOptions&lt;/code&gt;</ph> contains the <ph id="ph2">&lt;xref:System.Globalization.CompareOptions&gt;</ph>, <ph id="ph3">&lt;xref:System.Globalization.CompareOptions&gt;</ph>, or <ph id="ph4">&lt;xref:System.Globalization.CompareOptions&gt;</ph> flag.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;compareOptions&lt;/code&gt;</ph>포함 된 <ph id="ph2">&lt;xref:System.Globalization.CompareOptions&gt;</ph>, <ph id="ph3">&lt;xref:System.Globalization.CompareOptions&gt;</ph>, 또는 <ph id="ph4">&lt;xref:System.Globalization.CompareOptions&gt;</ph> 플래그입니다.</target>       </trans-unit>
        <trans-unit id="288" translate="yes" xml:space="preserve">
          <source>Raised when the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> finalizes an asynchronous recognition operation of emulated input.</source>
          <target state="translated">발생 시기는 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 에뮬레이트된 입력의 비동기 인식 작업을 종료 합니다.</target>       </trans-unit>
        <trans-unit id="289" translate="yes" xml:space="preserve" extradata="MT">
          <source>Each &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt; method begins an asynchronous recognition operation.</source>
          <target state="translated">각 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;메서드는 비동기 인식 작업을 시작 합니다.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</target>       </trans-unit>
        <trans-unit id="290" translate="yes" xml:space="preserve" extradata="MT">
          <source>The &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; raises the EmulateRecognizeCompleted event when it finalizes the asynchronous operation.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;비동기 작업을 완료 하는 경우 EmulateRecognizeCompleted 이벤트를 발생 시킵니다.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="291" translate="yes" xml:space="preserve" extradata="MT">
          <source>The &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt; operation can raise the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; events.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;작업을 발생 시킬 수는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;, 및 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;이벤트.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</target>       </trans-unit>
        <trans-unit id="292" translate="yes" xml:space="preserve" extradata="MT">
          <source>The EmulateRecognizeCompleted event is the last such event that the recognizer raises for a given operation.</source>
          <target state="translated">EmulateRecognizeCompleted 이벤트는 마지막 이러한 이벤트 인식기에서 지정된 된 작업에 대 한를 발생 시킵니다.</target>       </trans-unit>
        <trans-unit id="293" translate="yes" xml:space="preserve" extradata="MT">
          <source>If emulated recognition was successful, you can access the recognition result using the either of the following:      -   The &lt;xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A&gt; property in the &lt;xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt; object in the handler for the EmulateRecognizeCompleted event.</source>
          <target state="translated">에뮬레이트된 인식에 성공 하면 다음 중 하나를 사용 하 여 인식 결과 액세스할 수 있습니다:- &lt;xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A&gt;속성에는 &lt;xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt;EmulateRecognizeCompleted 이벤트의 처리기에는 개체입니다.&lt;/xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt; &lt;/xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A&gt;</target>       </trans-unit>
        <trans-unit id="294" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   &lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt; property in the &lt;xref:System.Speech.Recognition.SpeechRecognizedEventArgs&gt; object in the handler for the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; event.</source>
          <target state="translated">- &lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;속성에는 &lt;xref:System.Speech.Recognition.SpeechRecognizedEventArgs&gt;개체에 대 한 처리기는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;이벤트.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognizedEventArgs&gt; &lt;/xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</target>       </trans-unit>
        <trans-unit id="295" translate="yes" xml:space="preserve" extradata="MT">
          <source>If emulated recognition was not successful, the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; event is not raised and the &lt;xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A&gt; will be null.</source>
          <target state="translated">에뮬레이트된 인식 하지 못한 경우, 고 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;이벤트가 발생 하지 않습니다 및 &lt;xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A&gt;null이 됩니다.&lt;/xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</target>       </trans-unit>
        <trans-unit id="296" translate="yes" xml:space="preserve" extradata="MT">
          <source>&lt;xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt; derives from &lt;xref:System.ComponentModel.AsyncCompletedEventArgs&gt;.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt;&lt;xref:System.ComponentModel.AsyncCompletedEventArgs&gt;.&lt;/xref:System.ComponentModel.AsyncCompletedEventArgs&gt; 에서 파생&lt;/xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt;</target>       </trans-unit>
        <trans-unit id="297" translate="yes" xml:space="preserve" extradata="MT">
          <source>&lt;xref:System.Speech.Recognition.SpeechRecognizedEventArgs&gt; derives from &lt;xref:System.Speech.Recognition.RecognitionEventArgs&gt;.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.SpeechRecognizedEventArgs&gt;&lt;xref:System.Speech.Recognition.RecognitionEventArgs&gt;.&lt;/xref:System.Speech.Recognition.RecognitionEventArgs&gt; 에서 파생&lt;/xref:System.Speech.Recognition.SpeechRecognizedEventArgs&gt;</target>       </trans-unit>
        <trans-unit id="298" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create an EmulateRecognizeCompleted delegate, you identify the method that will handle the event.</source>
          <target state="translated">EmulateRecognizeCompleted 대리자를 만들 때 이벤트를 처리 하는 메서드를 식별 합니다.</target>       </trans-unit>
        <trans-unit id="299" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다.</target>       </trans-unit>
        <trans-unit id="300" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다.</target>       </trans-unit>
        <trans-unit id="301" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">이벤트 처리기 대리자에 대 한 자세한 내용은 참조 <bpt id="p1">[</bpt>이벤트 및 대리자<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>합니다.</target>       </trans-unit>
        <trans-unit id="302" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">추가할 수 있습니다.</target>       </trans-unit>
        <trans-unit id="303" translate="yes" xml:space="preserve">
          <source>Gets or sets the interval of silence that the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> will accept at the end of unambiguous input before finalizing a recognition operation.</source>
          <target state="translated">대기 간격을 가져오거나는 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 인식 작업을 마무리 하기 전에 모호 하지 않은 입력의 끝에서 허용 됩니다.</target>       </trans-unit>
        <trans-unit id="304" translate="yes" xml:space="preserve" extradata="MT">
          <source>The speech recognizer uses this timeout interval when the recognition input is unambiguous.</source>
          <target state="translated">음성 인식기에서 인식 입력 모호 하지 않은 경우이 시간 제한 간격을 사용 합니다.</target>       </trans-unit>
        <trans-unit id="305" translate="yes" xml:space="preserve" extradata="MT">
          <source>For example, for a speech recognition grammar that supports recognition of either "new game please" or "new game", "new game please" is an unambiguous input, and "new game" is an ambiguous input.</source>
          <target state="translated">지 원하는 인식의 음성 인식 문법에 대 한 예를 들어 "새 게임을 하십시오" 또는 "새 게임" "새 게임을 하십시오" 한 명확한 입력 하 고 "새 게임"은 모호한 입력 합니다.</target>       </trans-unit>
        <trans-unit id="306" translate="yes" xml:space="preserve" extradata="MT">
          <source>This property determines how long the speech recognition engine will wait for additional input before finalizing a recognition operation.</source>
          <target state="translated">이 속성 인식 작업을 마무리 하기 전에 음성 인식 엔진 추가 입력에 대 한 대기 하는 시간을 결정 합니다.</target>       </trans-unit>
        <trans-unit id="307" translate="yes" xml:space="preserve" extradata="MT">
          <source>The timeout interval can be from 0 seconds to 10 seconds, inclusive.</source>
          <target state="translated">제한 시간 간격은 10 초를 0 초에서 수 있습니다.</target>       </trans-unit>
        <trans-unit id="308" translate="yes" xml:space="preserve" extradata="MT">
          <source>The default is 150 milliseconds.</source>
          <target state="translated">기본값은 150 밀리초입니다.</target>       </trans-unit>
        <trans-unit id="309" translate="yes" xml:space="preserve" extradata="MT">
          <source>To set the timeout interval for ambiguous input, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt; property.</source>
          <target state="translated">모호한 입력에 대 한 제한 시간 간격을 설정 하려면는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;속성.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</target>       </trans-unit>
        <trans-unit id="310" translate="yes" xml:space="preserve">
          <source>The duration of the interval of silence.</source>
          <target state="translated">대기 간격의 기간입니다.</target>       </trans-unit>
        <trans-unit id="311" translate="yes" xml:space="preserve">
          <source>This property is set to less than 0 seconds or greater than 10 seconds.</source>
          <target state="translated">이 속성은 10 초 보다 큰 값 또는 0 초 보다 작게 설정 됩니다.</target>       </trans-unit>
        <trans-unit id="312" translate="yes" xml:space="preserve">
          <source>Gets or sets the interval of silence that the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> will accept at the end of ambiguous input before finalizing a recognition operation.</source>
          <target state="translated">대기 간격을 가져오거나는 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 인식 작업을 마무리 하기 전에 모호한 입력의 끝에 적용 됩니다.</target>       </trans-unit>
        <trans-unit id="313" translate="yes" xml:space="preserve" extradata="MT">
          <source>The speech recognizer uses this timeout interval when the recognition input is ambiguous.</source>
          <target state="translated">음성 인식기에서 인식 입력이 모호한 경우이 시간 제한 간격을 사용 합니다.</target>       </trans-unit>
        <trans-unit id="314" translate="yes" xml:space="preserve" extradata="MT">
          <source>For example, for a speech recognition grammar that supports recognition of either "new game please" or "new game", "new game please" is an unambiguous input, and "new game" is an ambiguous input.</source>
          <target state="translated">지 원하는 인식의 음성 인식 문법에 대 한 예를 들어 "새 게임을 하십시오" 또는 "새 게임" "새 게임을 하십시오" 한 명확한 입력 하 고 "새 게임"은 모호한 입력 합니다.</target>       </trans-unit>
        <trans-unit id="315" translate="yes" xml:space="preserve" extradata="MT">
          <source>This property determines how long the speech recognition engine will wait for additional input before finalizing a recognition operation.</source>
          <target state="translated">이 속성 인식 작업을 마무리 하기 전에 음성 인식 엔진 추가 입력에 대 한 대기 하는 시간을 결정 합니다.</target>       </trans-unit>
        <trans-unit id="316" translate="yes" xml:space="preserve" extradata="MT">
          <source>The timeout interval can be from 0 seconds to 10 seconds, inclusive.</source>
          <target state="translated">제한 시간 간격은 10 초를 0 초에서 수 있습니다.</target>       </trans-unit>
        <trans-unit id="317" translate="yes" xml:space="preserve" extradata="MT">
          <source>The default is 500 milliseconds.</source>
          <target state="translated">기본값은 500 밀리초입니다.</target>       </trans-unit>
        <trans-unit id="318" translate="yes" xml:space="preserve" extradata="MT">
          <source>To set the timeout interval for unambiguous input, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt; property.</source>
          <target state="translated">명확한 입력에 대 한 제한 시간 간격을 설정 하려면는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;속성.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</target>       </trans-unit>
        <trans-unit id="319" translate="yes" xml:space="preserve">
          <source>The duration of the interval of silence.</source>
          <target state="translated">대기 간격의 기간입니다.</target>       </trans-unit>
        <trans-unit id="320" translate="yes" xml:space="preserve">
          <source>This property is set to less than 0 seconds or greater than 10 seconds.</source>
          <target state="translated">이 속성은 10 초 보다 큰 값 또는 0 초 보다 작게 설정 됩니다.</target>       </trans-unit>
        <trans-unit id="321" translate="yes" xml:space="preserve">
          <source>Gets a collection of the <bpt id="p1">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> objects that are loaded in this <bpt id="p2">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p2">&lt;/xref&gt;</ept> instance.</source>
          <target state="translated">컬렉션을 가져옵니다는 <bpt id="p1">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 이 로드 되는 개체 <bpt id="p2">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p2">&lt;/xref&gt;</ept> 인스턴스.</target>       </trans-unit>
        <trans-unit id="322" translate="yes" xml:space="preserve">
          <source>The collection of <bpt id="p1">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> objects.</source>
          <target state="translated">컬렉션 <bpt id="p1">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 개체입니다.</target>       </trans-unit>
        <trans-unit id="323" translate="yes" xml:space="preserve">
          <source>Gets or sets the time interval during which a <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> accepts input containing only silence before finalizing recognition.</source>
          <target state="translated">시간 간격을 가져오거나는 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 인식을 마무리 하기 전에 포함만 대기 입력된을 허용 합니다.</target>       </trans-unit>
        <trans-unit id="324" translate="yes" xml:space="preserve" extradata="MT">
          <source>Each speech recognizer has an algorithm to distinguish between silence and speech.</source>
          <target state="translated">음성 인식기 각 대기 및 음성 간을 서로 구별 하는 알고리즘을 있습니다.</target>       </trans-unit>
        <trans-unit id="325" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the recognizer input is silence during the initial silence timeout period, then the recognizer finalizes that recognition operation.</source>
          <target state="translated">인식기 입력 초기 대기 제한 시간 동안 대기 이면 인식기에서 인식 작업을 완료 합니다.</target>       </trans-unit>
        <trans-unit id="326" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   For asynchronous recognition operations and emulation, the recognizer raises the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt; event, where the &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A?displayProperty=fullName&gt; property is <ph id="ph1">`true`</ph>, and the &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=fullName&gt; property is <ph id="ph2">`null`</ph>.</source>
          <target state="translated">-인식기 발생 비동기 인식 작업 및 에뮬레이션에 대 한는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;이벤트, 여기서는 &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A?displayProperty=fullName&gt;속성은 <ph id="ph1">`true`</ph>, 및 &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=fullName&gt;속성은 <ph id="ph2">`null`</ph>.&lt;/xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=fullName&gt; &lt;/xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A?displayProperty=fullName&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</target>       </trans-unit>
        <trans-unit id="327" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   For synchronous recognition operations and emulation, the recognizer returns <ph id="ph1">`null`</ph>, instead of a valid &lt;xref:System.Speech.Recognition.RecognitionResult&gt;.</source>
          <target state="translated">-인식기 동기 인식 작업 및 에뮬레이션에 대 한 반환 <ph id="ph1">`null`</ph>에 유효한 &lt;xref:System.Speech.Recognition.RecognitionResult&gt;.&lt;/xref:System.Speech.Recognition.RecognitionResult&gt; 대신</target>       </trans-unit>
        <trans-unit id="328" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the initial silence timeout interval is set to 0, the recognizer does not perform an initial silence timeout check.</source>
          <target state="translated">초기 대기 제한 시간 간격을 0으로 설정 하는 경우 인식기에서 초기 대기 제한 시간 확인 작업을 수행 하지 않습니다.</target>       </trans-unit>
        <trans-unit id="329" translate="yes" xml:space="preserve" extradata="MT">
          <source>The timeout interval can be any non-negative value.</source>
          <target state="translated">시간 제한 간격 임의의 음수가 아닌 값일 수 있습니다.</target>       </trans-unit>
        <trans-unit id="330" translate="yes" xml:space="preserve" extradata="MT">
          <source>The default is 0 seconds.</source>
          <target state="translated">기본값은 0 초입니다.</target>       </trans-unit>
        <trans-unit id="331" translate="yes" xml:space="preserve">
          <source>The duration of the interval of silence.</source>
          <target state="translated">대기 간격의 기간입니다.</target>       </trans-unit>
        <trans-unit id="332" translate="yes" xml:space="preserve">
          <source>This property is set to less than 0 seconds.</source>
          <target state="translated">이 속성은 0 초 보다 작게 설정 됩니다.</target>       </trans-unit>
        <trans-unit id="333" translate="yes" xml:space="preserve">
          <source>Returns information for all of the installed speech recognizers on the current system.</source>
          <target state="translated">현재 시스템에 설치 된 음성 인식기의 모든 정보를 반환합니다.</target>       </trans-unit>
        <trans-unit id="334" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get information about the current recognizer, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A&gt; property.</source>
          <target state="translated">현재 인식기에 대 한 정보를 가져오려면는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A&gt;속성.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A&gt;</target>       </trans-unit>
        <trans-unit id="335" translate="yes" xml:space="preserve">
          <source>A read-only collection of the <bpt id="p1">&lt;xref href="System.Speech.Recognition.RecognizerInfo"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> objects that describe the installed recognizers.</source>
          <target state="translated">읽기 전용 컬렉션은 <bpt id="p1">&lt;xref href="System.Speech.Recognition.RecognizerInfo"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 설치 인식기를 설명 하는 개체입니다.</target>       </trans-unit>
        <trans-unit id="336" translate="yes" xml:space="preserve">
          <source>Synchronously loads a <bpt id="p1">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> object.</source>
          <target state="translated">동기식으로 로드 한 <bpt id="p1">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 개체입니다.</target>       </trans-unit>
        <trans-unit id="337" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer throws an exception if the &lt;xref:System.Speech.Recognition.Grammar&gt; object is already loaded, is being asynchronously loaded, or has failed to load into any recognizer.</source>
          <target state="translated">인식기에서 예외를 throw 하는 경우는 &lt;xref:System.Speech.Recognition.Grammar&gt;개체는 이미 로드 되어, 비동기적으로 로드 되 고, 또는 모든 인식기로 로드 하지 못했습니다.&lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="338" translate="yes" xml:space="preserve" extradata="MT">
          <source>You cannot load the same &lt;xref:System.Speech.Recognition.Grammar&gt; object into multiple instances of &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;.</source>
          <target state="translated">동일한 &lt;xref:System.Speech.Recognition.Grammar&gt;개체 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; 의 여러 인스턴스를&lt;/xref:System.Speech.Recognition.Grammar&gt; 로드할 수 없습니다.</target>       </trans-unit>
        <trans-unit id="339" translate="yes" xml:space="preserve" extradata="MT">
          <source>Instead, create a new &lt;xref:System.Speech.Recognition.Grammar&gt; object for each &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; instance.</source>
          <target state="translated">대신 새를 만들 &lt;xref:System.Speech.Recognition.Grammar&gt;각각에 대 한 개체 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;인스턴스.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; &lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="340" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the recognizer is running, applications must use &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt; to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
          <target state="translated">응용 프로그램을 사용 해야 인식기에서 실행 중인 경우 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;를 로드, 언로드, 또는 사용 안 함 문법 하기 전에 음성 인식 엔진을 일시 중지 합니다.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</target>       </trans-unit>
        <trans-unit id="341" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you load a grammar, it is enabled by default.</source>
          <target state="translated">문법적으로 로드 하는 경우 기본적으로 사용 됩니다.</target>       </trans-unit>
        <trans-unit id="342" translate="yes" xml:space="preserve" extradata="MT">
          <source>To disable a loaded grammar, use the &lt;xref:System.Speech.Recognition.Grammar.Enabled%2A&gt; property.</source>
          <target state="translated">로드 된 문법을 사용는 &lt;xref:System.Speech.Recognition.Grammar.Enabled%2A&gt;속성.&lt;/xref:System.Speech.Recognition.Grammar.Enabled%2A&gt;</target>       </trans-unit>
        <trans-unit id="343" translate="yes" xml:space="preserve" extradata="MT">
          <source>To load a &lt;xref:System.Speech.Recognition.Grammar&gt; object asynchronously, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt; method.</source>
          <target state="translated">로드 하는 &lt;xref:System.Speech.Recognition.Grammar&gt;비동기적으로 개체를 가져오려면는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt; &lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="344" translate="yes" xml:space="preserve">
          <source>The grammar object to load.</source>
          <target state="translated">로드할 문법 개체입니다.</target>       </trans-unit>
        <trans-unit id="345" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;Grammar&lt;/code&gt;</ph> is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;Grammar&lt;/code&gt;</ph>is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="346" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;Grammar&lt;/code&gt;</ph> is not in a valid state.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;Grammar&lt;/code&gt;</ph>상태가 올바르지 않습니다.</target>       </trans-unit>
        <trans-unit id="347" translate="yes" xml:space="preserve">
          <source>Asynchronously loads a speech recognition grammar.</source>
          <target state="translated">음성 인식 문법을 비동기적으로 로드 합니다.</target>       </trans-unit>
        <trans-unit id="348" translate="yes" xml:space="preserve" extradata="MT">
          <source>When the recognizer completes loading a &lt;xref:System.Speech.Recognition.Grammar&gt; object, it raises a &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted&gt; event.</source>
          <target state="translated">인식기에서 로드를 완료 하는 경우는 &lt;xref:System.Speech.Recognition.Grammar&gt;개체를 발생 한 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted&gt;이벤트.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted&gt; &lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="349" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer throws an exception if the &lt;xref:System.Speech.Recognition.Grammar&gt; object is already loaded, is being asynchronously loaded, or has failed to load into any recognizer.</source>
          <target state="translated">인식기에서 예외를 throw 하는 경우는 &lt;xref:System.Speech.Recognition.Grammar&gt;개체는 이미 로드 되어, 비동기적으로 로드 되 고, 또는 모든 인식기로 로드 하지 못했습니다.&lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="350" translate="yes" xml:space="preserve" extradata="MT">
          <source>You cannot load the same &lt;xref:System.Speech.Recognition.Grammar&gt; object into multiple instances of &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;.</source>
          <target state="translated">동일한 &lt;xref:System.Speech.Recognition.Grammar&gt;개체 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; 의 여러 인스턴스를&lt;/xref:System.Speech.Recognition.Grammar&gt; 로드할 수 없습니다.</target>       </trans-unit>
        <trans-unit id="351" translate="yes" xml:space="preserve" extradata="MT">
          <source>Instead, create a new &lt;xref:System.Speech.Recognition.Grammar&gt; object for each &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; instance.</source>
          <target state="translated">대신 새를 만들 &lt;xref:System.Speech.Recognition.Grammar&gt;각각에 대 한 개체 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;인스턴스.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; &lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="352" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the recognizer is running, applications must use &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt; to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
          <target state="translated">응용 프로그램을 사용 해야 인식기에서 실행 중인 경우 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;를 로드, 언로드, 또는 사용 안 함 문법 하기 전에 음성 인식 엔진을 일시 중지 합니다.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</target>       </trans-unit>
        <trans-unit id="353" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you load a grammar, it is enabled by default.</source>
          <target state="translated">문법적으로 로드 하는 경우 기본적으로 사용 됩니다.</target>       </trans-unit>
        <trans-unit id="354" translate="yes" xml:space="preserve" extradata="MT">
          <source>To disable a loaded grammar, use the &lt;xref:System.Speech.Recognition.Grammar.Enabled%2A&gt; property.</source>
          <target state="translated">로드 된 문법을 사용는 &lt;xref:System.Speech.Recognition.Grammar.Enabled%2A&gt;속성.&lt;/xref:System.Speech.Recognition.Grammar.Enabled%2A&gt;</target>       </trans-unit>
        <trans-unit id="355" translate="yes" xml:space="preserve" extradata="MT">
          <source>To load a speech recognition grammar synchronously, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt; method.</source>
          <target state="translated">음성 인식 문법에 동기적으로 로드 하려면 사용 하 여는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</target>       </trans-unit>
        <trans-unit id="356" translate="yes" xml:space="preserve">
          <source>The speech recognition grammar to load.</source>
          <target state="translated">음성 인식 문법을 로드 합니다.</target>       </trans-unit>
        <trans-unit id="357" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;Grammar&lt;/code&gt;</ph> is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;Grammar&lt;/code&gt;</ph>is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="358" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;Grammar&lt;/code&gt;</ph> is not in a valid state.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;Grammar&lt;/code&gt;</ph>상태가 올바르지 않습니다.</target>       </trans-unit>
        <trans-unit id="359" translate="yes" xml:space="preserve">
          <source>The asynchronous operation was canceled.</source>
          <target state="translated">비동기 작업이 취소 되었습니다.</target>       </trans-unit>
        <trans-unit id="360" translate="yes" xml:space="preserve">
          <source>Raised when the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> finishes the asynchronous loading of a <bpt id="p2">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt><ept id="p2">&lt;/xref&gt;</ept> object.</source>
          <target state="translated">발생 시기는 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 의 비동기 로드가 완료 되는 <bpt id="p2">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt> <ept id="p2">&lt;/xref&gt;</ept> 개체입니다.</target>       </trans-unit>
        <trans-unit id="361" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer's &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt; method initiates an asynchronous operation.</source>
          <target state="translated">인식기에서 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;메서드는 비동기 작업을 시작 합니다.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</target>       </trans-unit>
        <trans-unit id="362" translate="yes" xml:space="preserve" extradata="MT">
          <source>The &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; raises this event when it completes the operation.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;는 작업을 완료 하는 경우이 이벤트를 발생 시킵니다.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="363" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get the &lt;xref:System.Speech.Recognition.Grammar&gt; object that the recognizer loaded, use the &lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A&gt; property of the associated &lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt;.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.Grammar&gt;인식기에서 로드 하는 개체 &lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A&gt; &lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt;.&lt;/xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt; 연결된의 속성&lt;/xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A&gt; 을 사용&lt;/xref:System.Speech.Recognition.Grammar&gt; 하려면</target>       </trans-unit>
        <trans-unit id="364" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get the current &lt;xref:System.Speech.Recognition.Grammar&gt; objects the recognizer has loaded, use the recognizer's &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A&gt; property.</source>
          <target state="translated">현재 가져오려는 &lt;xref:System.Speech.Recognition.Grammar&gt;인식기가 로드 하는 개체 인식기에서 사용 하 여 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A&gt;속성.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A&gt; &lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="365" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the recognizer is running, applications must use &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt; to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
          <target state="translated">응용 프로그램을 사용 해야 인식기에서 실행 중인 경우 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;를 로드, 언로드, 또는 사용 안 함 문법 하기 전에 음성 인식 엔진을 일시 중지 합니다.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</target>       </trans-unit>
        <trans-unit id="366" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create a LoadGrammarCompleted delegate, you identify the method that will handle the event.</source>
          <target state="translated">LoadGrammarCompleted 대리자를 만들 때 이벤트를 처리 하는 메서드를 식별 합니다.</target>       </trans-unit>
        <trans-unit id="367" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다.</target>       </trans-unit>
        <trans-unit id="368" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다.</target>       </trans-unit>
        <trans-unit id="369" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">이벤트 처리기 대리자에 대 한 자세한 내용은 참조 <bpt id="p1">[</bpt>이벤트 및 대리자<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>합니다.</target>       </trans-unit>
        <trans-unit id="370" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">추가할 수 있습니다.</target>       </trans-unit>
        <trans-unit id="371" translate="yes" xml:space="preserve">
          <source>Gets or sets the maximum number of alternate recognition results that the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> returns for each recognition operation.</source>
          <target state="translated">대체 인식 결과의 최대 수를 가져오거나는 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 각 인식 작업을 반환 합니다.</target>       </trans-unit>
        <trans-unit id="372" translate="yes" xml:space="preserve" extradata="MT">
          <source>The &lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt; property of the &lt;xref:System.Speech.Recognition.RecognitionResult&gt; class contains the collection of &lt;xref:System.Speech.Recognition.RecognizedPhrase&gt; objects that represent possible interpretations of the input.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;속성은 &lt;xref:System.Speech.Recognition.RecognitionResult&gt;의 컬렉션을 포함 하는 클래스 &lt;xref:System.Speech.Recognition.RecognizedPhrase&gt;입력의 가능한 해석을 나타내는 개체입니다.&lt;/xref:System.Speech.Recognition.RecognizedPhrase&gt; &lt;/xref:System.Speech.Recognition.RecognitionResult&gt; &lt;/xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</target>       </trans-unit>
        <trans-unit id="373" translate="yes" xml:space="preserve" extradata="MT">
          <source>The default value for MaxAlternates is 10.</source>
          <target state="translated">MaxAlternates의 기본값은 10입니다.</target>       </trans-unit>
        <trans-unit id="374" translate="yes" xml:space="preserve">
          <source>The number of alternate results to return.</source>
          <target state="translated">대체 반환할 결과의 수입니다.</target>       </trans-unit>
        <trans-unit id="375" translate="yes" xml:space="preserve">
          <source>MaxAlternates is set to a value less than 0.</source>
          <target state="translated">MaxAlternates 0 보다 작은 값으로 설정 됩니다.</target>       </trans-unit>
        <trans-unit id="376" translate="yes" xml:space="preserve">
          <source>Returns the values of settings for the recognizer.</source>
          <target state="translated">인식기에 대 한 설정의 값을 반환합니다.</target>       </trans-unit>
        <trans-unit id="377" translate="yes" xml:space="preserve" extradata="MT">
          <source>Recognizer settings can contain string, 64-bit integer, or memory address data.</source>
          <target state="translated">인식기 설정을 문자열, 64 비트 정수 또는 메모리 주소 데이터를 포함할 수 있습니다.</target>       </trans-unit>
        <trans-unit id="378" translate="yes" xml:space="preserve" extradata="MT">
          <source>The following table describes the settings that are defined for a Microsoft Speech API (SAPI)-compliant recognizer.</source>
          <target state="translated">다음 표에서 Microsoft Speech API (SAPI)에 대해 정의 된 설정을-인식기 규정을 준수 합니다.</target>       </trans-unit>
        <trans-unit id="379" translate="yes" xml:space="preserve" extradata="MT">
          <source>The following settings must have the same range for each recognizer that supports the setting.</source>
          <target state="translated">다음 설정은 각 인식기 설정을 지원에 대 한 동일한 범위가 있어야 합니다.</target>       </trans-unit>
        <trans-unit id="380" translate="yes" xml:space="preserve" extradata="MT">
          <source>A SAPI-compliant recognizer is not required to support these settings and can support other settings.</source>
          <target state="translated">SAPI 규격 인식기 이러한 설정을 지 원하는 데 필요 하지는 및 기타 설정을 지원할 수 있습니다.</target>       </trans-unit>
        <trans-unit id="381" translate="yes" xml:space="preserve" extradata="MT">
          <source>|Name|Description|   |----------|-----------------|   |<ph id="ph1">`ResourceUsage`</ph>|Specifies the recognizer's CPU consumption.</source>
          <target state="translated">| 이름 | 설명 |   |----------|-----------------|   | <ph id="ph1">`ResourceUsage`</ph>| 인식기에서 CPU 소비를 지정합니다.</target>       </trans-unit>
        <trans-unit id="382" translate="yes" xml:space="preserve" extradata="MT">
          <source>The range is from 0 to 100.</source>
          <target state="translated">범위는 0에서 100 까지입니다.</target>       </trans-unit>
        <trans-unit id="383" translate="yes" xml:space="preserve" extradata="MT">
          <source>The default value is 50.|   |<ph id="ph1">`ResponseSpeed`</ph>|Indicates the length of silence at the end of unambiguous input before the speech recognizer completes a recognition operation.</source>
          <target state="translated">기본값은 50입니다. |   | <ph id="ph1">`ResponseSpeed`</ph>| 음성 인식기에서 인식 작업을 완료 하기 전에 대기 모호 하지 않은 입력의 끝에서의 길이 나타냅니다.</target>       </trans-unit>
        <trans-unit id="384" translate="yes" xml:space="preserve" extradata="MT">
          <source>The range is from 0 to 10,000 milliseconds (ms).</source>
          <target state="translated">범위는 0에서 10, 000 밀리초 (ms) 까지입니다.</target>       </trans-unit>
        <trans-unit id="385" translate="yes" xml:space="preserve" extradata="MT">
          <source>This setting corresponds to the recognizer's &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt; property.</source>
          <target state="translated">이 설정은 인식기에 해당 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;속성.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</target>       </trans-unit>
        <trans-unit id="386" translate="yes" xml:space="preserve" extradata="MT">
          <source>Default = 150ms.|   |<ph id="ph1">`ComplexResponseSpeed`</ph>|Indicates the length of silence at the end of ambiguous input before the speech recognizer completes a recognition operation.</source>
          <target state="translated">기본값 = 150ms. |   | <ph id="ph1">`ComplexResponseSpeed`</ph>| 음성 인식기에서 인식 작업을 완료 하기 전에 대기 모호한 입력의 끝에 길이 나타냅니다.</target>       </trans-unit>
        <trans-unit id="387" translate="yes" xml:space="preserve" extradata="MT">
          <source>The range is from 0 to 10,000ms.</source>
          <target state="translated">범위는 0에서 같고 10, 000ms 까지입니다.</target>       </trans-unit>
        <trans-unit id="388" translate="yes" xml:space="preserve" extradata="MT">
          <source>This setting corresponds to the recognizer's &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt; property.</source>
          <target state="translated">이 설정은 인식기에 해당 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;속성.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</target>       </trans-unit>
        <trans-unit id="389" translate="yes" xml:space="preserve" extradata="MT">
          <source>Default = 500ms.|   |<ph id="ph1">`AdaptationOn`</ph>|Indicates whether adaptation of the acoustic model is ON (value = <ph id="ph2">`1`</ph>) or OFF (value = <ph id="ph3">`0`</ph>).</source>
          <target state="translated">기본값은 500 밀리초. |   | <ph id="ph1">`AdaptationOn`</ph>| 음향 모델의 적응 ON 인지를 나타냅니다 (값 = <ph id="ph2">`1`</ph>) 또는 OFF (값 = <ph id="ph3">`0`</ph>).</target>       </trans-unit>
        <trans-unit id="390" translate="yes" xml:space="preserve" extradata="MT">
          <source>The default value is <ph id="ph1">`1`</ph> (ON).|   |<ph id="ph2">`PersistedBackgroundAdaptation`</ph>|Indicates whether background adaptation is ON (value = <ph id="ph3">`1`</ph>) or OFF (value = <ph id="ph4">`0`</ph>), and persists the setting in the registry.</source>
          <target state="translated">기본값은 <ph id="ph1">`1`</ph> (ON). |   | <ph id="ph2">`PersistedBackgroundAdaptation`</ph>| 백그라운드 적용 ON 인지를 나타냅니다 (값 = <ph id="ph3">`1`</ph>) 또는 OFF (값 = <ph id="ph4">`0`</ph>), 레지스트리에서 설정을 유지 합니다.</target>       </trans-unit>
        <trans-unit id="391" translate="yes" xml:space="preserve" extradata="MT">
          <source>The default value is <ph id="ph1">`1`</ph> (ON).|       To update a setting for the recognizer, use one of the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt; methods.</source>
          <target state="translated">기본값은 <ph id="ph1">`1`</ph> (ON). |       인식기 설정을 업데이트 하려면 중 사용 된 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</target>       </trans-unit>
        <trans-unit id="392" translate="yes" xml:space="preserve">
          <source>The name of the setting to return.</source>
          <target state="translated">반환할 설정의 이름입니다.</target>       </trans-unit>
        <trans-unit id="393" translate="yes" xml:space="preserve">
          <source>The value of the setting.</source>
          <target state="translated">설정의 값입니다.</target>       </trans-unit>
        <trans-unit id="394" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;settingName&lt;/code&gt;</ph> is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;settingName&lt;/code&gt;</ph>is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="395" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;settingName&lt;/code&gt;</ph> is the empty string ("").</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;settingName&lt;/code&gt;</ph>가 빈 문자열 ("").</target>       </trans-unit>
        <trans-unit id="396" translate="yes" xml:space="preserve">
          <source>The recognizer does not have a setting by that name.</source>
          <target state="translated">해당 이름의 인식기 설정을 않아도 됩니다.</target>       </trans-unit>
        <trans-unit id="397" translate="yes" xml:space="preserve">
          <source>Performs a synchronous speech recognition operation.</source>
          <target state="translated">동기 음성 인식 작업을 수행합니다.</target>       </trans-unit>
        <trans-unit id="398" translate="yes" xml:space="preserve" extradata="MT">
          <source>This method performs a single recognition operation.</source>
          <target state="translated">이 메서드는 단일 인식 작업을 수행합니다.</target>       </trans-unit>
        <trans-unit id="399" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer performs this operation against its loaded and enabled speech recognition grammars.</source>
          <target state="translated">인식기에서의 로드 하 고 사용할 음성 인식 문법에 대해이 작업을 수행합니다.</target>       </trans-unit>
        <trans-unit id="400" translate="yes" xml:space="preserve" extradata="MT">
          <source>During a call to this method, the recognizer can raise the following events:      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;.</source>
          <target state="translated">인식기에서이 메서드를 호출 하는 동안 다음과 같은 이벤트를 발생 수:- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</target>       </trans-unit>
        <trans-unit id="401" translate="yes" xml:space="preserve" extradata="MT">
          <source>Raised when the recognizer detects input that it can identify as speech.</source>
          <target state="translated">인식기에서 음성으로 식별할 수 있는 입력을 감지할 때 발생 합니다.</target>       </trans-unit>
        <trans-unit id="402" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;.</source>
          <target state="translated">-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</target>       </trans-unit>
        <trans-unit id="403" translate="yes" xml:space="preserve" extradata="MT">
          <source>Raised when input creates an ambiguous match with one of the active grammars.</source>
          <target state="translated">입력 현재 문법 중 하 나와 일치 상태가 모호를 만들 때 발생 합니다.</target>       </trans-unit>
        <trans-unit id="404" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;.</source>
          <target state="translated">-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</target>       </trans-unit>
        <trans-unit id="405" translate="yes" xml:space="preserve" extradata="MT">
          <source>Raised when the recognizer finalizes a recognition operation.</source>
          <target state="translated">인식기에서 인식 작업을 종료 하는 경우 발생 합니다.</target>       </trans-unit>
        <trans-unit id="406" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer does not raise the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt; event when using this method.</source>
          <target state="translated">인식기에서 발생 하지 않습니다는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;이 메서드를 사용 하는 경우에 이벤트입니다.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</target>       </trans-unit>
        <trans-unit id="407" translate="yes" xml:space="preserve" extradata="MT">
          <source>The Recognize method returns a &lt;xref:System.Speech.Recognition.RecognitionResult&gt; object, or <ph id="ph1">`null`</ph> if the operation is not successful.</source>
          <target state="translated">인식 메서드 반환는 &lt;xref:System.Speech.Recognition.RecognitionResult&gt;개체 또는 <ph id="ph1">`null`</ph> 는 작업은 실패 하는 경우.&lt;/xref:System.Speech.Recognition.RecognitionResult&gt;</target>       </trans-unit>
        <trans-unit id="408" translate="yes" xml:space="preserve" extradata="MT">
          <source>A synchronous recognition operation can fail for the following reasons:      -   Speech is not detected before the timeout intervals expire for the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt; properties.</source>
          <target state="translated">동기 인식 작업은 다음과 같은 이유로 실패할 수 있습니다.-에 대 한 시간 제한 간격이 만료 되기 전에 음성 인식 되지 않습니다는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;또는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;속성.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</target>       </trans-unit>
        <trans-unit id="409" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   The recognition engine detects speech but finds no matches in any of its loaded and enabled &lt;xref:System.Speech.Recognition.Grammar&gt; objects.</source>
          <target state="translated">-인식 엔진 음성 검색 했지만 로드 및 사용에 일치 하는 항목을 찾은 &lt;xref:System.Speech.Recognition.Grammar&gt;개체입니다.&lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="410" translate="yes" xml:space="preserve" extradata="MT">
          <source>To perform asynchronous recognition, use one of the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt; methods.</source>
          <target state="translated">비동기 인식 기능을 수행 하려면 중 하나를 사용는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</target>       </trans-unit>
        <trans-unit id="411" translate="yes" xml:space="preserve">
          <source>The recognition result for the input, or <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> if the operation is not successful or the recognizer is not enabled.</source>
          <target state="translated">입력에 대 한 인식 결과 또는 <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 는 작업은 실패 하거나 인식기를 사용할 수 없습니다.</target>       </trans-unit>
        <trans-unit id="412" translate="yes" xml:space="preserve">
          <source>Performs a synchronous speech recognition operation with a specified initial silence timeout period.</source>
          <target state="translated">지정 된 초기 대기 제한 시간으로 동기 음성 인식 작업을 수행합니다.</target>       </trans-unit>
        <trans-unit id="413" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the speech recognition engine detects speech within the time interval specified by <ph id="ph1">`initialSilenceTimeout`</ph> argument, Recognize performs a single recognition operation and then terminates.</source>
          <target state="translated">음성 인식 엔진 감지 하 여 지정 된 시간 간격 내에서 음성 <ph id="ph1">`initialSilenceTimeout`</ph> 인수를 인식 단일 인식 작업을 수행 하 고 다음 종료 합니다.</target>       </trans-unit>
        <trans-unit id="414" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <ph id="ph1">`initialSilenceTimeout`</ph> parameter supersedes the recognizer's &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt; property.</source>
          <target state="translated"><ph id="ph1">`initialSilenceTimeout`</ph> 매개 변수 대체 인식기 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;속성.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</target>       </trans-unit>
        <trans-unit id="415" translate="yes" xml:space="preserve" extradata="MT">
          <source>During a call to this method, the recognizer can raise the following events:      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;.</source>
          <target state="translated">인식기에서이 메서드를 호출 하는 동안 다음과 같은 이벤트를 발생 수:- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</target>       </trans-unit>
        <trans-unit id="416" translate="yes" xml:space="preserve" extradata="MT">
          <source>Raised when the recognizer detects input that it can identify as speech.</source>
          <target state="translated">인식기에서 음성으로 식별할 수 있는 입력을 감지할 때 발생 합니다.</target>       </trans-unit>
        <trans-unit id="417" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;.</source>
          <target state="translated">-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</target>       </trans-unit>
        <trans-unit id="418" translate="yes" xml:space="preserve" extradata="MT">
          <source>Raised when input creates an ambiguous match with one of the active grammars.</source>
          <target state="translated">입력 현재 문법 중 하 나와 일치 상태가 모호를 만들 때 발생 합니다.</target>       </trans-unit>
        <trans-unit id="419" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;.</source>
          <target state="translated">-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</target>       </trans-unit>
        <trans-unit id="420" translate="yes" xml:space="preserve" extradata="MT">
          <source>Raised when the recognizer finalizes a recognition operation.</source>
          <target state="translated">인식기에서 인식 작업을 종료 하는 경우 발생 합니다.</target>       </trans-unit>
        <trans-unit id="421" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer does not raise the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt; event when using this method.</source>
          <target state="translated">인식기에서 발생 하지 않습니다는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;이 메서드를 사용 하는 경우에 이벤트입니다.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</target>       </trans-unit>
        <trans-unit id="422" translate="yes" xml:space="preserve" extradata="MT">
          <source>The &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize&gt; method returns a &lt;xref:System.Speech.Recognition.RecognitionResult&gt; object, or <ph id="ph1">`null`</ph> if the operation is not successful.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize&gt;메서드가 반환 되는 &lt;xref:System.Speech.Recognition.RecognitionResult&gt;개체 또는 <ph id="ph1">`null`</ph> 는 작업은 실패 하는 경우.&lt;/xref:System.Speech.Recognition.RecognitionResult&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize&gt;</target>       </trans-unit>
        <trans-unit id="423" translate="yes" xml:space="preserve" extradata="MT">
          <source>A synchronous recognition operation can fail for the following reasons:      -   Speech is not detected before the timeout intervals expire for the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt; or for the <ph id="ph1">`initialSilenceTimeout`</ph> parameter.</source>
          <target state="translated">동기 인식 작업은 다음과 같은 이유로 실패할 수 있습니다:-에 대 한 시간 제한 간격이 만료 되기 전에 음성 인식 되지 않습니다는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;또는 <ph id="ph1">`initialSilenceTimeout`</ph> 매개 변수.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</target>       </trans-unit>
        <trans-unit id="424" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   The recognition engine detects speech but finds no matches in any of its loaded and enabled &lt;xref:System.Speech.Recognition.Grammar&gt; objects.</source>
          <target state="translated">-인식 엔진 음성 검색 했지만 로드 및 사용에 일치 하는 항목을 찾은 &lt;xref:System.Speech.Recognition.Grammar&gt;개체입니다.&lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="425" translate="yes" xml:space="preserve" extradata="MT">
          <source>To perform asynchronous recognition, use one of the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt; methods.</source>
          <target state="translated">비동기 인식 기능을 수행 하려면 중 하나를 사용는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</target>       </trans-unit>
        <trans-unit id="426" translate="yes" xml:space="preserve">
          <source>The interval of time a speech recognizer accepts input containing only silence before finalizing recognition.</source>
          <target state="translated">음성 인식기에서 허용 하는 시간 간격을만 대기 인식을 마무리 하기 전에 포함 된 입력입니다.</target>       </trans-unit>
        <trans-unit id="427" translate="yes" xml:space="preserve">
          <source>The recognition result for the input, or <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> if the operation is not successful or the recognizer is not enabled.</source>
          <target state="translated">입력에 대 한 인식 결과 또는 <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 는 작업은 실패 하거나 인식기를 사용할 수 없습니다.</target>       </trans-unit>
        <trans-unit id="428" translate="yes" xml:space="preserve">
          <source>Performs a single, asynchronous speech recognition operation.</source>
          <target state="translated">단일, 비동기 음성 인식 작업을 수행합니다.</target>       </trans-unit>
        <trans-unit id="429" translate="yes" xml:space="preserve" extradata="MT">
          <source>This method performs a single, asynchronous recognition operation.</source>
          <target state="translated">이 메서드는 단일, 비동기 인식 작업을 수행합니다.</target>       </trans-unit>
        <trans-unit id="430" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer performs the operation against its loaded and enabled speech recognition grammars.</source>
          <target state="translated">인식기에서의 로드 하 고 사용할 음성 인식 문법에 대해 작업을 수행합니다.</target>       </trans-unit>
        <trans-unit id="431" translate="yes" xml:space="preserve" extradata="MT">
          <source>During a call to this method, the recognizer can raise the following events:      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;.</source>
          <target state="translated">인식기에서이 메서드를 호출 하는 동안 다음과 같은 이벤트를 발생 수:- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</target>       </trans-unit>
        <trans-unit id="432" translate="yes" xml:space="preserve" extradata="MT">
          <source>Raised when the recognizer detects input that it can identify as speech.</source>
          <target state="translated">인식기에서 음성으로 식별할 수 있는 입력을 감지할 때 발생 합니다.</target>       </trans-unit>
        <trans-unit id="433" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;.</source>
          <target state="translated">-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</target>       </trans-unit>
        <trans-unit id="434" translate="yes" xml:space="preserve" extradata="MT">
          <source>Raised when input creates an ambiguous match with one of the active grammars.</source>
          <target state="translated">입력 현재 문법 중 하 나와 일치 상태가 모호를 만들 때 발생 합니다.</target>       </trans-unit>
        <trans-unit id="435" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;.</source>
          <target state="translated">-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</target>       </trans-unit>
        <trans-unit id="436" translate="yes" xml:space="preserve" extradata="MT">
          <source>Raised when the recognizer finalizes a recognition operation.</source>
          <target state="translated">인식기에서 인식 작업을 종료 하는 경우 발생 합니다.</target>       </trans-unit>
        <trans-unit id="437" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;.</source>
          <target state="translated">-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</target>       </trans-unit>
        <trans-unit id="438" translate="yes" xml:space="preserve" extradata="MT">
          <source>Raised when a &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt; operation finishes.</source>
          <target state="translated">발생 시기는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;작업을 완료 합니다.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</target>       </trans-unit>
        <trans-unit id="439" translate="yes" xml:space="preserve" extradata="MT">
          <source>To retrieve the result of an asynchronous recognition operation, attach an event handler to the recognizer's &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; event.</source>
          <target state="translated">비동기 인식 작업의 결과 검색 하려면 인식기를 이벤트 처리기를 연결 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;이벤트.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</target>       </trans-unit>
        <trans-unit id="440" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer raises this event whenever it successfully completes a synchronous or asynchronous recognition operation.</source>
          <target state="translated">인식기에서 인식 동기 또는 비동기 작업을 성공적으로 완료 될 때마다이 이벤트를 발생 시킵니다.</target>       </trans-unit>
        <trans-unit id="441" translate="yes" xml:space="preserve" extradata="MT">
          <source>If recognition was not successful, the &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A&gt; property on &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt; object, which you can access in the handler for the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt; event, will be <ph id="ph1">`null`</ph>.</source>
          <target state="translated">인식 하지 못한 경우는 &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A&gt;속성 &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;이벤트의 처리기에서 액세스할 수 있는 개체는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;이벤트가, <ph id="ph1">`null`</ph>.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt; &lt;/xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt; &lt;/xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A&gt;</target>       </trans-unit>
        <trans-unit id="442" translate="yes" xml:space="preserve" extradata="MT">
          <source>To perform synchronous recognition, use one of the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt; methods.</source>
          <target state="translated">동기 인식 기능을 수행 하려면 중 하나를 사용는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</target>       </trans-unit>
        <trans-unit id="443" translate="yes" xml:space="preserve">
          <source>Performs one or more asynchronous speech recognition operations.</source>
          <target state="translated">하나 이상의 비동기 음성 인식 작업을 수행합니다.</target>       </trans-unit>
        <trans-unit id="444" translate="yes" xml:space="preserve" extradata="MT">
          <source>If <ph id="ph1">`mode`</ph> is &lt;xref:System.Speech.Recognition.RecognizeMode&gt;, the recognizer continues performing asynchronous recognition operations until the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A&gt; method is called.</source>
          <target state="translated">경우 <ph id="ph1">`mode`</ph> 은 &lt;xref:System.Speech.Recognition.RecognizeMode&gt;, 인식기에서 계속 될 때까지 비동기 인식 작업을 수행는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A&gt;또는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A&gt;메서드를 호출 합니다.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A&gt; &lt;/xref:System.Speech.Recognition.RecognizeMode&gt;</target>       </trans-unit>
        <trans-unit id="445" translate="yes" xml:space="preserve" extradata="MT">
          <source>During a call to this method, the recognizer can raise the following events:      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;.</source>
          <target state="translated">인식기에서이 메서드를 호출 하는 동안 다음과 같은 이벤트를 발생 수:- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</target>       </trans-unit>
        <trans-unit id="446" translate="yes" xml:space="preserve" extradata="MT">
          <source>Raised when the recognizer detects input that it can identify as speech.</source>
          <target state="translated">인식기에서 음성으로 식별할 수 있는 입력을 감지할 때 발생 합니다.</target>       </trans-unit>
        <trans-unit id="447" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;.</source>
          <target state="translated">-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</target>       </trans-unit>
        <trans-unit id="448" translate="yes" xml:space="preserve" extradata="MT">
          <source>Raised when input creates an ambiguous match with one of the active grammars.</source>
          <target state="translated">입력 현재 문법 중 하 나와 일치 상태가 모호를 만들 때 발생 합니다.</target>       </trans-unit>
        <trans-unit id="449" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;.</source>
          <target state="translated">-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</target>       </trans-unit>
        <trans-unit id="450" translate="yes" xml:space="preserve" extradata="MT">
          <source>Raised when the recognizer finalizes a recognition operation.</source>
          <target state="translated">인식기에서 인식 작업을 종료 하는 경우 발생 합니다.</target>       </trans-unit>
        <trans-unit id="451" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;.</source>
          <target state="translated">-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</target>       </trans-unit>
        <trans-unit id="452" translate="yes" xml:space="preserve" extradata="MT">
          <source>Raised when a &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt; operation finishes.</source>
          <target state="translated">발생 시기는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;작업을 완료 합니다.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</target>       </trans-unit>
        <trans-unit id="453" translate="yes" xml:space="preserve" extradata="MT">
          <source>To retrieve the result of an asynchronous recognition operation, attach an event handler to the recognizer's &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; event.</source>
          <target state="translated">비동기 인식 작업의 결과 검색 하려면 인식기를 이벤트 처리기를 연결 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;이벤트.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</target>       </trans-unit>
        <trans-unit id="454" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer raises this event whenever it successfully completes a synchronous or asynchronous recognition operation.</source>
          <target state="translated">인식기에서 인식 동기 또는 비동기 작업을 성공적으로 완료 될 때마다이 이벤트를 발생 시킵니다.</target>       </trans-unit>
        <trans-unit id="455" translate="yes" xml:space="preserve" extradata="MT">
          <source>If recognition was not successful, the &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A&gt; property on &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt; object, which you can access in the handler for the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt; event, will be <ph id="ph1">`null`</ph>.</source>
          <target state="translated">인식 하지 못한 경우는 &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A&gt;속성 &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;이벤트의 처리기에서 액세스할 수 있는 개체는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;이벤트가, <ph id="ph1">`null`</ph>.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt; &lt;/xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt; &lt;/xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A&gt;</target>       </trans-unit>
        <trans-unit id="456" translate="yes" xml:space="preserve" extradata="MT">
          <source>An asynchronous recognition operation can fail for the following reasons:      -   Speech is not detected before the timeout intervals expire for the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt; properties.</source>
          <target state="translated">비동기 인식 작업은 다음과 같은 이유로 실패할 수 있습니다.-에 대 한 시간 제한 간격이 만료 되기 전에 음성 인식 되지 않습니다는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;또는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;속성.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</target>       </trans-unit>
        <trans-unit id="457" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   The recognition engine detects speech but finds no matches in any of its loaded and enabled &lt;xref:System.Speech.Recognition.Grammar&gt; objects.</source>
          <target state="translated">-인식 엔진 음성 검색 했지만 로드 및 사용에 일치 하는 항목을 찾은 &lt;xref:System.Speech.Recognition.Grammar&gt;개체입니다.&lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="458" translate="yes" xml:space="preserve" extradata="MT">
          <source>To perform synchronous recognition, use one of the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt; methods.</source>
          <target state="translated">동기 인식 기능을 수행 하려면 중 하나를 사용는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</target>       </trans-unit>
        <trans-unit id="459" translate="yes" xml:space="preserve">
          <source>Indicates whether to perform one or multiple recognition operations.</source>
          <target state="translated">하나 또는 여러 개의 인식 작업을 수행할 것인지 여부를 나타냅니다.</target>       </trans-unit>
        <trans-unit id="460" translate="yes" xml:space="preserve">
          <source>Terminates asynchronous recognition without waiting for the current recognition operation to complete.</source>
          <target state="translated">비동기 인식 현재 인식 작업을 완료 될 때까지 기다리지 않고 종료 합니다.</target>       </trans-unit>
        <trans-unit id="461" translate="yes" xml:space="preserve" extradata="MT">
          <source>This method immediately finalizes asynchronous recognition.</source>
          <target state="translated">이 메서드는 비동기 인식을 즉시 종료합니다.</target>       </trans-unit>
        <trans-unit id="462" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the current asynchronous recognition operation is receiving input, the input is truncated and the operation completes with the existing input.</source>
          <target state="translated">현재 비동기 인식 작업 입력을 받고, 입력 잘리고 기존 입력을 사용 하면 작업이 완료 됩니다.</target>       </trans-unit>
        <trans-unit id="463" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer raises the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt; event when an asynchronous operation is canceled, and sets the &lt;xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A&gt; property of the &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt; to <ph id="ph1">`true`</ph>.</source>
          <target state="translated">인식기 발생은 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;또는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;비동기 작업이 취소 되 고 설정 하는 경우 이벤트는 &lt;xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A&gt;속성은 &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;를 <ph id="ph1">`true`</ph>.&lt;/xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt; &lt;/xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</target>       </trans-unit>
        <trans-unit id="464" translate="yes" xml:space="preserve" extradata="MT">
          <source>This method cancels asynchronous operations initiated by the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt; and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt; methods.</source>
          <target state="translated">시작 된 비동기 작업을 취소 하는이 메서드는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;및 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</target>       </trans-unit>
        <trans-unit id="465" translate="yes" xml:space="preserve" extradata="MT">
          <source>To stop asynchronous recognition without truncating the input, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A&gt; method.</source>
          <target state="translated">비동기 인식 된 입력을 자르지 않고을 중지 하려면 사용 된 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A&gt;</target>       </trans-unit>
        <trans-unit id="466" translate="yes" xml:space="preserve">
          <source>Stops asynchronous recognition after the current recognition operation completes.</source>
          <target state="translated">비동기 인식 현재 인식 작업이 완료 된 후에 중지 합니다.</target>       </trans-unit>
        <trans-unit id="467" translate="yes" xml:space="preserve" extradata="MT">
          <source>This method finalizes asynchronous recognition without truncating input.</source>
          <target state="translated">이 메서드는 입력을 자르지 않고 비동기 인식을 종료 합니다.</target>       </trans-unit>
        <trans-unit id="468" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the current asynchronous recognition operation is receiving input, the recognizer continues accepting input until the current recognition operation is completed.</source>
          <target state="translated">현재 비동기 인식 작업 입력을 받고, 인식기에서 입력을 현재 인식 작업이 완료 될 때까지 적용 계속 됩니다.</target>       </trans-unit>
        <trans-unit id="469" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer raises the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt; event when an asynchronous operation is stopped, and sets the &lt;xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A&gt; property of the &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt; to <ph id="ph1">`true`</ph>.</source>
          <target state="translated">인식기 발생은 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;또는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;비동기 작업이 중지 되 고 설정 하는 경우 이벤트는 &lt;xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A&gt;속성의는 &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;를 <ph id="ph1">`true`</ph>.&lt;/xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt; &lt;/xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</target>       </trans-unit>
        <trans-unit id="470" translate="yes" xml:space="preserve" extradata="MT">
          <source>This method stops asynchronous operations initiated by the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt; and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt; methods.</source>
          <target state="translated">시작 된 비동기 작업을 중지 하는이 메서드는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;및 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</target>       </trans-unit>
        <trans-unit id="471" translate="yes" xml:space="preserve" extradata="MT">
          <source>To immediately cancel asynchronous recognition with only the existing input, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A&gt; method.</source>
          <target state="translated">비동기 인식 기존 입력만 즉시 취소 하려면 사용 하 여는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A&gt;</target>       </trans-unit>
        <trans-unit id="472" translate="yes" xml:space="preserve">
          <source>Raised when the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> finalizes an asynchronous recognition operation.</source>
          <target state="translated">발생 시기는 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 비동기 인식 작업을 종료 합니다.</target>       </trans-unit>
        <trans-unit id="473" translate="yes" xml:space="preserve" extradata="MT">
          <source>The &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; object's &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt; method initiates an asynchronous recognition operation.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;개체의 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;메서드는 비동기 인식 작업을 시작 합니다.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="474" translate="yes" xml:space="preserve" extradata="MT">
          <source>When the recognizer finalizes the asynchronous operation, it raises this event.</source>
          <target state="translated">인식기에서 비동기 작업을 완료 하는 경우이 이벤트를 발생 시킵니다.</target>       </trans-unit>
        <trans-unit id="475" translate="yes" xml:space="preserve" extradata="MT">
          <source>Using the handler for the RecognizeCompleted event, you can access the &lt;xref:System.Speech.Recognition.RecognitionResult&gt; in the &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt; object.</source>
          <target state="translated">RecognizeCompleted 이벤트에 대 한 처리기를 사용, 액세스할 수 있습니다는 &lt;xref:System.Speech.Recognition.RecognitionResult&gt;에 &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;개체입니다.&lt;/xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt; &lt;/xref:System.Speech.Recognition.RecognitionResult&gt;</target>       </trans-unit>
        <trans-unit id="476" translate="yes" xml:space="preserve" extradata="MT">
          <source>If recognition was not successful, &lt;xref:System.Speech.Recognition.RecognitionResult&gt; will be <ph id="ph1">`null`</ph>.</source>
          <target state="translated">인식 하지 못한 경우, &lt;xref:System.Speech.Recognition.RecognitionResult&gt;됩니다 <ph id="ph1">`null`</ph>.&lt;/xref:System.Speech.Recognition.RecognitionResult&gt;</target>       </trans-unit>
        <trans-unit id="477" translate="yes" xml:space="preserve" extradata="MT">
          <source>To determine whether a timeout or an interruption in audio input caused recognition to fail, you can access the properties for &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A&gt;, &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A&gt;, or &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded%2A&gt;.</source>
          <target state="translated">시간 제한 또는 중단에 오디오 입력 실패 인식 원인 인지를 확인 하려면에 대 한 속성에 액세스할 수 있습니다 &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A&gt;, &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A&gt;, 또는 &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded%2A&gt;.&lt;/xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded%2A&gt; &lt;/xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A&gt; &lt;/xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A&gt;</target>       </trans-unit>
        <trans-unit id="478" translate="yes" xml:space="preserve" extradata="MT">
          <source>See the &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt; class for more information.</source>
          <target state="translated">참조는 &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;클래스에 대 한 자세한 내용은.&lt;/xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;</target>       </trans-unit>
        <trans-unit id="479" translate="yes" xml:space="preserve" extradata="MT">
          <source>To obtain details on the best rejected recognition candidates, attach a handler for the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; event.</source>
          <target state="translated">최상의 거부 된 인식 후보에 대 한 세부 정보를 가져오려면 연결에 대 한 처리기는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;이벤트.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</target>       </trans-unit>
        <trans-unit id="480" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create a RecognizeCompleted delegate, you identify the method that will handle the event.</source>
          <target state="translated">RecognizeCompleted 대리자를 만들 때 이벤트를 처리 하는 메서드를 식별 합니다.</target>       </trans-unit>
        <trans-unit id="481" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다.</target>       </trans-unit>
        <trans-unit id="482" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다.</target>       </trans-unit>
        <trans-unit id="483" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">이벤트 처리기 대리자에 대 한 자세한 내용은 참조 <bpt id="p1">[</bpt>이벤트 및 대리자<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>합니다.</target>       </trans-unit>
        <trans-unit id="484" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">추가할 수 있습니다.</target>       </trans-unit>
        <trans-unit id="485" translate="yes" xml:space="preserve">
          <source>Gets the current location of the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> in the audio input that it is processing.</source>
          <target state="translated">현재 위치를 가져옵니다는 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 처리 하는 오디오 입력에서 합니다.</target>       </trans-unit>
        <trans-unit id="486" translate="yes" xml:space="preserve" extradata="MT">
          <source>The audio position is specific to each speech recognizer.</source>
          <target state="translated">오디오 위치는 각 음성 인식기 관련이 있습니다.</target>       </trans-unit>
        <trans-unit id="487" translate="yes" xml:space="preserve" extradata="MT">
          <source>The zero value of an input stream is established when it is enabled.</source>
          <target state="translated">활성화 되 면 입력 스트림의&amp;0; 값은 설정 됩니다.</target>       </trans-unit>
        <trans-unit id="488" translate="yes" xml:space="preserve" extradata="MT">
          <source>The RecognizerAudioPosition property references the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; object's position within its audio input.</source>
          <target state="translated">RecognizerAudioPosition 속성 참조는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;오디오 입력 내에서 개체의 위치입니다.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="489" translate="yes" xml:space="preserve" extradata="MT">
          <source>By contrast, the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt; property references the input device's position in its generated audio stream.</source>
          <target state="translated">반면,는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;속성 참조의 생성 된 오디오 스트림 내의 위치를 입력된 장치.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</target>       </trans-unit>
        <trans-unit id="490" translate="yes" xml:space="preserve" extradata="MT">
          <source>These positions can be different.</source>
          <target state="translated">이 위치는 다를 수 있습니다.</target>       </trans-unit>
        <trans-unit id="491" translate="yes" xml:space="preserve" extradata="MT">
          <source>For example, if the recognizer has received input for which it has not yet generated a recognition result then the value of the RecognizerAudioPosition property is less than the value of the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt; property.</source>
          <target state="translated">예를 들어 인식기에서 받는 경우 하지는 자신이 입력 하면서도 RecognizerAudioPosition 속성의 값은의 값 보다 작은 인식 결과 생성 되는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;속성.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</target>       </trans-unit>
        <trans-unit id="492" translate="yes" xml:space="preserve">
          <source>The position of the recognizer in the audio input that it is processing.</source>
          <target state="translated">인식기에 오디오 입력을 처리 하는 위치입니다.</target>       </trans-unit>
        <trans-unit id="493" translate="yes" xml:space="preserve">
          <source>Gets information about the current instance of <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated">현재 인스턴스에 대 한 정보를 가져옵니다 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept>합니다.</target>       </trans-unit>
        <trans-unit id="494" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get information about all of the installed speech recognizers for the current system, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt; method.</source>
          <target state="translated">현재 시스템에 대 한 모든 설치 된 음성 인식기에 대 한 정보를 가져오려면는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;</target>       </trans-unit>
        <trans-unit id="495" translate="yes" xml:space="preserve">
          <source>Information about the current speech recognizer.</source>
          <target state="translated">현재 음성 인식기에 대 한 정보입니다.</target>       </trans-unit>
        <trans-unit id="496" translate="yes" xml:space="preserve">
          <source>Raised when a running <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> pauses to accept modifications.</source>
          <target state="translated">실행 될 때 발생 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 수정 작업을 허용 하도록 일시 중지 합니다.</target>       </trans-unit>
        <trans-unit id="497" translate="yes" xml:space="preserve" extradata="MT">
          <source>Applications must use &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt; to pause a running instance of &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; before modifying its settings or its &lt;xref:System.Speech.Recognition.Grammar&gt; objects.</source>
          <target state="translated">응용 프로그램 사용 해야 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;를 실행 중인 인스턴스 일시 중지 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;해당 설정을 수정 하기 전에 해당 또는 &lt;xref:System.Speech.Recognition.Grammar&gt;개체.&lt;/xref:System.Speech.Recognition.Grammar&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</target>       </trans-unit>
        <trans-unit id="498" translate="yes" xml:space="preserve" extradata="MT">
          <source>The &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; raises this event when it is ready to accept modifications.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;수정을 수락할 준비가 되었을 때이 이벤트를 발생 시킵니다.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="499" translate="yes" xml:space="preserve" extradata="MT">
          <source>For example, while the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; is paused, you can load, unload, enable, and disable &lt;xref:System.Speech.Recognition.Grammar&gt; objects, and modify values for the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt; properties.</source>
          <target state="translated">예를 들어 동안는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;는 일시 중지 된 있습니다 수 로드, 언로드, 설정 및 해제 &lt;xref:System.Speech.Recognition.Grammar&gt;개체, 및에 대 한 값을 수정는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;, 및 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;속성.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt; &lt;/xref:System.Speech.Recognition.Grammar&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="500" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information, see the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt; method.</source>
          <target state="translated">자세한 내용은 참조는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</target>       </trans-unit>
        <trans-unit id="501" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create a RecognizerUpdateReached delegate, you identify the method that will handle the event.</source>
          <target state="translated">RecognizerUpdateReached 대리자를 만들 때 이벤트를 처리 하는 메서드를 식별 합니다.</target>       </trans-unit>
        <trans-unit id="502" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다.</target>       </trans-unit>
        <trans-unit id="503" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다.</target>       </trans-unit>
        <trans-unit id="504" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">이벤트 처리기 대리자에 대 한 자세한 내용은 참조 <bpt id="p1">[</bpt>이벤트 및 대리자<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>합니다.</target>       </trans-unit>
        <trans-unit id="505" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">추가할 수 있습니다.</target>       </trans-unit>
        <trans-unit id="506" translate="yes" xml:space="preserve">
          <source>Requests that the recognizer pauses to update its state.</source>
          <target state="translated">요청을 인식기에서 업데이트의 상태를 일시 중지할 수입니다.</target>       </trans-unit>
        <trans-unit id="507" translate="yes" xml:space="preserve" extradata="MT">
          <source>When the recognizer generates the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt; event, the &lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt; property of the &lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; is <ph id="ph1">`null`</ph>.</source>
          <target state="translated">인식기에서 생성 하는 경우는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;이벤트는 &lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;속성은 &lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;은 <ph id="ph1">`null`</ph>.&lt;/xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; &lt;/xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</target>       </trans-unit>
        <trans-unit id="508" translate="yes" xml:space="preserve" extradata="MT">
          <source>To provide a user token, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt; method.</source>
          <target state="translated">사용자 토큰을 제공 하기 위해 사용 된 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;또는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</target>       </trans-unit>
        <trans-unit id="509" translate="yes" xml:space="preserve" extradata="MT">
          <source>To specify an audio position offset, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt; method.</source>
          <target state="translated">오디오 위치 오프셋을 지정 하려면 사용 된 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</target>       </trans-unit>
        <trans-unit id="510" translate="yes" xml:space="preserve">
          <source>Requests that the recognizer pauses to update its state and provides a user token for the associated event.</source>
          <target state="translated">요청 인식기의 상태를 업데이트 하려면 일시 중지 하 고 연결된 된 이벤트에 대 한 사용자 토큰을 제공 합니다.</target>       </trans-unit>
        <trans-unit id="511" translate="yes" xml:space="preserve" extradata="MT">
          <source>When the recognizer generates the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt; event, the &lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt; property of the &lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; contains the value of the <ph id="ph1">`userToken`</ph> parameter.</source>
          <target state="translated">인식기에서 생성 하는 경우는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;이벤트에는 &lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;의 속성은 &lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;의 값을 포함는 <ph id="ph1">`userToken`</ph> 매개 변수.&lt;/xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; &lt;/xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</target>       </trans-unit>
        <trans-unit id="512" translate="yes" xml:space="preserve" extradata="MT">
          <source>To specify an audio position offset, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt; method.</source>
          <target state="translated">오디오 위치 오프셋을 지정 하려면 사용 된 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</target>       </trans-unit>
        <trans-unit id="513" translate="yes" xml:space="preserve">
          <source>User-defined information that contains information for the operation.</source>
          <target state="translated">작업에 대 한 정보를 포함 하는 사용자 정의 정보입니다.</target>       </trans-unit>
        <trans-unit id="514" translate="yes" xml:space="preserve">
          <source>Requests that the recognizer pauses to update its state and provides an offset and a user token for the associated event.</source>
          <target state="translated">요청 인식기의 상태를 업데이트 하려면 일시 중지 하 고 연결된 된 이벤트에 대 한 오프셋 및 사용자 토큰을 제공 합니다.</target>       </trans-unit>
        <trans-unit id="515" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer does not initiate the recognizer update request until the recognizer's &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt; equals the current &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt; plus <ph id="ph1">`audioPositionAheadToRaiseUpdate`</ph>.</source>
          <target state="translated">인식기에서 인식기 될 때까지 인식기 업데이트 요청을 시작 하지 않고 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;현재 equals &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;플러스 <ph id="ph1">`audioPositionAheadToRaiseUpdate`</ph>.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</target>       </trans-unit>
        <trans-unit id="516" translate="yes" xml:space="preserve" extradata="MT">
          <source>When the recognizer generates the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt; event, the &lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt; property of the &lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; contains the value of the <ph id="ph1">`userToken`</ph> parameter.</source>
          <target state="translated">인식기에서 생성 하는 경우는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;이벤트에는 &lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;의 속성은 &lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;의 값을 포함는 <ph id="ph1">`userToken`</ph> 매개 변수.&lt;/xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; &lt;/xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</target>       </trans-unit>
        <trans-unit id="517" translate="yes" xml:space="preserve">
          <source>User-defined information that contains information for the operation.</source>
          <target state="translated">작업에 대 한 정보를 포함 하는 사용자 정의 정보입니다.</target>       </trans-unit>
        <trans-unit id="518" translate="yes" xml:space="preserve">
          <source>The offset from the current &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition*&gt; to delay the request.</source>
          <target state="translated">현재에서 오프셋 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition*&gt;요청 지연.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition*&gt;</target>       </trans-unit>
        <trans-unit id="519" translate="yes" xml:space="preserve">
          <source>Configures the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> object to receive input from an audio stream.</source>
          <target state="translated">구성에서 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 입력 오디오 스트림을 받을 개체입니다.</target>       </trans-unit>
        <trans-unit id="520" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the recognizer reaches the end of the input stream during a recognition operation, the recognition operation finalizes with the available input.</source>
          <target state="translated">인식기에서 인식 작업 하는 동안 입력 스트림의 끝에 도달 하는 경우 사용 가능한 입력으로 인식 작업을 종료 합니다.</target>       </trans-unit>
        <trans-unit id="521" translate="yes" xml:space="preserve" extradata="MT">
          <source>Any subsequent recognition operations can generate an exception, unless you update the input to the recognizer.</source>
          <target state="translated">인식기에 대 한 입력을 업데이트 하지 않는 한 모든 후속 인식 작업에서 예외를 생성할 수 있습니다.</target>       </trans-unit>
        <trans-unit id="522" translate="yes" xml:space="preserve">
          <source>The audio input stream.</source>
          <target state="translated">오디오 입력된 스트림입니다.</target>       </trans-unit>
        <trans-unit id="523" translate="yes" xml:space="preserve">
          <source>The format of the audio input.</source>
          <target state="translated">오디오 입력의 형식입니다.</target>       </trans-unit>
        <trans-unit id="524" translate="yes" xml:space="preserve">
          <source>Configures the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> object to receive input from the default audio device.</source>
          <target state="translated">구성에서 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 기본 오디오 장치에서 입력을 받을 개체입니다.</target>       </trans-unit>
        <trans-unit id="525" translate="yes" xml:space="preserve">
          <source>Disables the input to the speech recognizer.</source>
          <target state="translated">음성 인식기에 대 한 입력을 사용 하지 않도록 설정 합니다.</target>       </trans-unit>
        <trans-unit id="526" translate="yes" xml:space="preserve" extradata="MT">
          <source>Configure the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; object for no input when using the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt; and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt; methods, or when taking a recognition engine temporarily off line.</source>
          <target state="translated">구성에서 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;사용 하는 경우 입력에 대 한 개체는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;및 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;메서드를 일시적으로 오프 라인 인식 엔진을 가져올 때 또는.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="527" translate="yes" xml:space="preserve">
          <source>Configures the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> object to receive input from a Waveform audio format (.wav) file.</source>
          <target state="translated">구성에서 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 파형 오디오 (.wav) 형식 파일에서 입력을 받을 개체입니다.</target>       </trans-unit>
        <trans-unit id="528" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the recognizer reaches the end of the input file during a recognition operation, the recognition operation finalizes with the available input.</source>
          <target state="translated">인식기에서 인식 작업 하는 동안 입력된 파일의 끝에 도달 하는 경우 사용 가능한 입력으로 인식 작업을 종료 합니다.</target>       </trans-unit>
        <trans-unit id="529" translate="yes" xml:space="preserve" extradata="MT">
          <source>Any subsequent recognition operations can generate an exception, unless you update the input to the recognizer.</source>
          <target state="translated">인식기에 대 한 입력을 업데이트 하지 않는 한 모든 후속 인식 작업에서 예외를 생성할 수 있습니다.</target>       </trans-unit>
        <trans-unit id="530" translate="yes" xml:space="preserve">
          <source>The path of the file to use as input.</source>
          <target state="translated">입력으로 사용할 파일의 경로입니다.</target>       </trans-unit>
        <trans-unit id="531" translate="yes" xml:space="preserve">
          <source>Configures the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> object to receive input from a stream that contains Waveform audio format (.wav) data.</source>
          <target state="translated">구성에서 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 파형 오디오 (.wav) 형식 데이터가 포함 된 스트림에서 입력을 받을 개체입니다.</target>       </trans-unit>
        <trans-unit id="532" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the recognizer reaches the end of the input stream during a recognition operation, the recognition operation finalizes with the available input.</source>
          <target state="translated">인식기에서 인식 작업 하는 동안 입력 스트림의 끝에 도달 하는 경우 사용 가능한 입력으로 인식 작업을 종료 합니다.</target>       </trans-unit>
        <trans-unit id="533" translate="yes" xml:space="preserve" extradata="MT">
          <source>Any subsequent recognition operations can generate an exception, unless you update the input to the recognizer.</source>
          <target state="translated">인식기에 대 한 입력을 업데이트 하지 않는 한 모든 후속 인식 작업에서 예외를 생성할 수 있습니다.</target>       </trans-unit>
        <trans-unit id="534" translate="yes" xml:space="preserve">
          <source>The stream containing the audio data.</source>
          <target state="translated">오디오 데이터를 포함 하는 스트림.</target>       </trans-unit>
        <trans-unit id="535" translate="yes" xml:space="preserve">
          <source>Raised when the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> detects input that it can identify as speech.</source>
          <target state="translated">발생 시기는 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 음성으로 식별할 수 있는 입력을 검색 합니다.</target>       </trans-unit>
        <trans-unit id="536" translate="yes" xml:space="preserve" extradata="MT">
          <source>Each speech recognizer has an algorithm to distinguish between silence and speech.</source>
          <target state="translated">음성 인식기 각 대기 및 음성 간을 서로 구별 하는 알고리즘을 있습니다.</target>       </trans-unit>
        <trans-unit id="537" translate="yes" xml:space="preserve" extradata="MT">
          <source>When the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; performs a speech recognition operation, it raises the SpeechDetected event when its algorithm identifies the input as speech.</source>
          <target state="translated">경우는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;음성 인식 작업을 수행 하면 해당 알고리즘으로 음성 입력을 식별 하는 경우 SpeechDetected 이벤트를 발생 시킵니다.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="538" translate="yes" xml:space="preserve" extradata="MT">
          <source>The &lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A&gt; property of the associated &lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs&gt; object indicates location in the input stream where the recognizer detected speech.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A&gt;속성은 연결 된 &lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs&gt;개체는 인식기에서 음성을 검색할 입력 스트림의 위치를 나타냅니다.&lt;/xref:System.Speech.Recognition.SpeechDetectedEventArgs&gt; &lt;/xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A&gt;</target>       </trans-unit>
        <trans-unit id="539" translate="yes" xml:space="preserve" extradata="MT">
          <source>The &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; raises the SpeechDetected event before it raises any of the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;, or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; events.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;SpeechDetected 이벤트의 발생 하기 전까지 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;, 또는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;이벤트.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="540" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information see the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt; methods.</source>
          <target state="translated">자세한 내용은 참조는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;, 및 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</target>       </trans-unit>
        <trans-unit id="541" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create a SpeechDetected delegate, you identify the method that will handle the event.</source>
          <target state="translated">SpeechDetected 대리자를 만들 때 이벤트를 처리 하는 메서드를 식별 합니다.</target>       </trans-unit>
        <trans-unit id="542" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다.</target>       </trans-unit>
        <trans-unit id="543" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다.</target>       </trans-unit>
        <trans-unit id="544" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">이벤트 처리기 대리자에 대 한 자세한 내용은 참조 <bpt id="p1">[</bpt>이벤트 및 대리자<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>합니다.</target>       </trans-unit>
        <trans-unit id="545" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">추가할 수 있습니다.</target>       </trans-unit>
        <trans-unit id="546" translate="yes" xml:space="preserve">
          <source>Raised when the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> has recognized a word or words that may be a component of multiple complete phrases in a grammar.</source>
          <target state="translated">발생 시기는 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 에서의 문법에 여러 전체 구 구성 될 수 있는 단어를 인식 합니다.</target>       </trans-unit>
        <trans-unit id="547" translate="yes" xml:space="preserve" extradata="MT">
          <source>The &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; generates numerous SpeechHypothesized events as it attempts to identify an input phrase.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;입력된 구를 식별 하려고 하는 대로 다양 한 SpeechHypothesized 이벤트를 생성 합니다.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="548" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can access the text of partially recognized phrases in the &lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt; property of the &lt;xref:System.Speech.Recognition.SpeechHypothesizedEventArgs&gt; object in the handler for the SpeechHypothesized event.</source>
          <target state="translated">부분적으로 인식 된 구의 텍스트에 액세스할 수 있습니다는 &lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;의 속성은 &lt;xref:System.Speech.Recognition.SpeechHypothesizedEventArgs&gt;SpeechHypothesized 이벤트에 대 한 처리기에서 개체입니다.&lt;/xref:System.Speech.Recognition.SpeechHypothesizedEventArgs&gt; &lt;/xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</target>       </trans-unit>
        <trans-unit id="549" translate="yes" xml:space="preserve" extradata="MT">
          <source>Typically, handling these events is useful only for debugging.</source>
          <target state="translated">일반적으로 이러한 이벤트를 처리는 디버깅에 대해서만 유용 합니다.</target>       </trans-unit>
        <trans-unit id="550" translate="yes" xml:space="preserve" extradata="MT">
          <source>&lt;xref:System.Speech.Recognition.SpeechHypothesizedEventArgs&gt; derives from &lt;xref:System.Speech.Recognition.RecognitionEventArgs&gt;.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.SpeechHypothesizedEventArgs&gt;&lt;xref:System.Speech.Recognition.RecognitionEventArgs&gt;.&lt;/xref:System.Speech.Recognition.RecognitionEventArgs&gt; 에서 파생&lt;/xref:System.Speech.Recognition.SpeechHypothesizedEventArgs&gt;</target>       </trans-unit>
        <trans-unit id="551" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information see the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt; property and the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt; methods.</source>
          <target state="translated">자세한 내용은 참조는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;속성 및 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;, 및 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</target>       </trans-unit>
        <trans-unit id="552" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create a SpeechHypothesized delegate, you identify the method that will handle the event.</source>
          <target state="translated">SpeechHypothesized 대리자를 만들 때 이벤트를 처리 하는 메서드를 식별 합니다.</target>       </trans-unit>
        <trans-unit id="553" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다.</target>       </trans-unit>
        <trans-unit id="554" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다.</target>       </trans-unit>
        <trans-unit id="555" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">이벤트 처리기 대리자에 대 한 자세한 내용은 참조 <bpt id="p1">[</bpt>이벤트 및 대리자<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>합니다.</target>       </trans-unit>
        <trans-unit id="556" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">추가할 수 있습니다.</target>       </trans-unit>
        <trans-unit id="557" translate="yes" xml:space="preserve">
          <source>Raised when the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> receives input that does not match any of its loaded and enabled <bpt id="p2">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt><ept id="p2">&lt;/xref&gt;</ept> objects.</source>
          <target state="translated">발생 시기는 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 의 로드 및 사용 하도록 설정 하는 중 일치 하지 않는 입력을 받는 <bpt id="p2">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt> <ept id="p2">&lt;/xref&gt;</ept> 개체입니다.</target>       </trans-unit>
        <trans-unit id="558" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer raises this event if it determines that input does not match with sufficient confidence any of its loaded and enabled &lt;xref:System.Speech.Recognition.Grammar&gt; objects.</source>
          <target state="translated">인식기 인지는 입력와 일치 하지 않으므로 충분 한 신뢰 된 로드 및 사용 하도록 설정 하는 경우이 이벤트를 발생 시킵니다 &lt;xref:System.Speech.Recognition.Grammar&gt;개체입니다.&lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="559" translate="yes" xml:space="preserve" extradata="MT">
          <source>The &lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt; property of the &lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; contains the rejected &lt;xref:System.Speech.Recognition.RecognitionResult&gt; object.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;의 속성은 &lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;거부 된 포함 &lt;xref:System.Speech.Recognition.RecognitionResult&gt;개체입니다.&lt;/xref:System.Speech.Recognition.RecognitionResult&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; &lt;/xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</target>       </trans-unit>
        <trans-unit id="560" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can use the handler for the SpeechRecognitionRejected event to retrieve recognition &lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt; that were rejected and their &lt;xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A&gt; scores.</source>
          <target state="translated">SpeechRecognitionRejected 이벤트에 대 한 처리기를 사용 하 여 인식 검색할 &lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;는 거부 된 및 해당 &lt;xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A&gt;점수.&lt;/xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A&gt; &lt;/xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</target>       </trans-unit>
        <trans-unit id="561" translate="yes" xml:space="preserve" extradata="MT">
          <source>If your application is using a &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; instance, you can modify the confidence level at which speech input is accepted or rejected with one of the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt; methods.</source>
          <target state="translated">응용 프로그램을 사용 하는 경우는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;인스턴스, 입력은 음성 승인 또는 거부 중 하나가 지정 된 신뢰 수준을 수정할 수 있습니다는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="562" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can modify how the speech recognition responds to non-speech input using the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt; properties.</source>
          <target state="translated">음성 인식 아닌 음성을 사용 하 여 입력에 반응 하는 방법을 수정할 수는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;, 및 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;속성.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</target>       </trans-unit>
        <trans-unit id="563" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create a SpeechRecognitionRejected delegate, you identify the method that will handle the event.</source>
          <target state="translated">SpeechRecognitionRejected 대리자를 만들 때 이벤트를 처리 하는 메서드를 식별 합니다.</target>       </trans-unit>
        <trans-unit id="564" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다.</target>       </trans-unit>
        <trans-unit id="565" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다.</target>       </trans-unit>
        <trans-unit id="566" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">이벤트 처리기 대리자에 대 한 자세한 내용은 참조 <bpt id="p1">[</bpt>이벤트 및 대리자<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>합니다.</target>       </trans-unit>
        <trans-unit id="567" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">추가할 수 있습니다.</target>       </trans-unit>
        <trans-unit id="568" translate="yes" xml:space="preserve">
          <source>Raised when the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> receives input that matches any of its loaded and enabled <bpt id="p2">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt><ept id="p2">&lt;/xref&gt;</ept> objects.</source>
          <target state="translated">발생 시기는 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 의 로드 및 활성화 중 하 나와 일치 하는 입력을 받는 <bpt id="p2">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt> <ept id="p2">&lt;/xref&gt;</ept> 개체입니다.</target>       </trans-unit>
        <trans-unit id="569" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can initiate a recognition operation using the one of the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt; methods.</source>
          <target state="translated">중 하나를 사용 하 여 인식 작업을 시작할 수는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;또는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</target>       </trans-unit>
        <trans-unit id="570" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer raises the SpeechRecognized event if it determines that input matches one of its loaded &lt;xref:System.Speech.Recognition.Grammar&gt; objects with a sufficient level of confidence to constitute recognition.</source>
          <target state="translated">인식기에서 입력의 로드 중 하나를 일치 하는지 결정 하는 경우는 SpeechRecognized 이벤트를 발생 시킨 &lt;xref:System.Speech.Recognition.Grammar&gt;개체는 충분 한 인식을 구성 하는 신뢰 수준으로 됩니다.&lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="571" translate="yes" xml:space="preserve" extradata="MT">
          <source>The &lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt; property of the &lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; contains the accepted &lt;xref:System.Speech.Recognition.RecognitionResult&gt; object.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;의 속성은 &lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;허용 포함 &lt;xref:System.Speech.Recognition.RecognitionResult&gt;개체입니다.&lt;/xref:System.Speech.Recognition.RecognitionResult&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; &lt;/xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</target>       </trans-unit>
        <trans-unit id="572" translate="yes" xml:space="preserve" extradata="MT">
          <source>Handlers of SpeechRecognized events can obtain the recognized phrase as well as a list of recognition &lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt; with lower confidence scores.</source>
          <target state="translated">SpeechRecognized 이벤트의 처리기를 인식된 된 구와 뿐만 아니라 인식의 목록을 가져올 수 &lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;낮은 신뢰성 점수와.&lt;/xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</target>       </trans-unit>
        <trans-unit id="573" translate="yes" xml:space="preserve" extradata="MT">
          <source>If your application is using a &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; instance, you can modify the confidence level at which speech input is accepted or rejected with one of the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt; methods.</source>
          <target state="translated">응용 프로그램을 사용 하는 경우는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;인스턴스, 입력은 음성 승인 또는 거부 중 하나가 지정 된 신뢰 수준을 수정할 수 있습니다는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="574" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can modify how the speech recognition responds to non-speech input using the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt; properties.</source>
          <target state="translated">음성 인식 아닌 음성을 사용 하 여 입력에 반응 하는 방법을 수정할 수는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;, 및 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;속성.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</target>       </trans-unit>
        <trans-unit id="575" translate="yes" xml:space="preserve" extradata="MT">
          <source>When the recognizer receives input that matches a grammar, the &lt;xref:System.Speech.Recognition.Grammar&gt; object can raise its &lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt; event.</source>
          <target state="translated">인식기 문법, 일치 하는 입력을 받을 때의 &lt;xref:System.Speech.Recognition.Grammar&gt;개체가 발생 시킬 수는 &lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;이벤트.&lt;/xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt; &lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="576" translate="yes" xml:space="preserve" extradata="MT">
          <source>The &lt;xref:System.Speech.Recognition.Grammar&gt; object's &lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt; event is raised prior to the speech recognizer's SpeechRecognized event.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.Grammar&gt;개체의 &lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;음성 인식기 SpeechRecognized 이벤트 보다 먼저 발생 합니다.&lt;/xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt; &lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="577" translate="yes" xml:space="preserve" extradata="MT">
          <source>Any tasks specific to a particular grammar should always be performed by a handler for the &lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt; event.</source>
          <target state="translated">에 대 한 처리기가 항상 특정 문법에 관련 된 모든 태스크를 수행 해야는 &lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;이벤트.&lt;/xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</target>       </trans-unit>
        <trans-unit id="578" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create a SpeechRecognized delegate, you identify the method that will handle the event.</source>
          <target state="translated">SpeechRecognized 대리자를 만들 때 이벤트를 처리 하는 메서드를 식별 합니다.</target>       </trans-unit>
        <trans-unit id="579" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">이벤트를 이벤트 처리기를 연결 하려면 대리자의 인스턴스 이벤트에 추가 합니다.</target>       </trans-unit>
        <trans-unit id="580" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">대리자를 제거 하지 않으면 이벤트가 발생할 때마다 이벤트 처리기가 호출 됩니다.</target>       </trans-unit>
        <trans-unit id="581" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">이벤트 처리기 대리자에 대 한 자세한 내용은 참조 <bpt id="p1">[</bpt>이벤트 및 대리자<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>합니다.</target>       </trans-unit>
        <trans-unit id="582" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">추가할 수 있습니다.</target>       </trans-unit>
        <trans-unit id="583" translate="yes" xml:space="preserve">
          <source>Unloads all <bpt id="p1">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> objects from the recognizer.</source>
          <target state="translated">모두 언로드합니다 <bpt id="p1">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 인식기에서 개체입니다.</target>       </trans-unit>
        <trans-unit id="584" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the recognizer is currently loading a &lt;xref:System.Speech.Recognition.Grammar&gt; asynchronously, this method waits until the &lt;xref:System.Speech.Recognition.Grammar&gt; is loaded, before it unloads all of the &lt;xref:System.Speech.Recognition.Grammar&gt; objects from the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; instance.</source>
          <target state="translated">현재 인식기를 로드 하는 경우는 &lt;xref:System.Speech.Recognition.Grammar&gt;이 이렇게 될 때까지 대기 하는 비동기적으로 &lt;xref:System.Speech.Recognition.Grammar&gt;모든 언로드합니다 되기 전에 로드 됩니다는 &lt;xref:System.Speech.Recognition.Grammar&gt;에서 개체는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;인스턴스.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; &lt;/xref:System.Speech.Recognition.Grammar&gt; &lt;/xref:System.Speech.Recognition.Grammar&gt; &lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="585" translate="yes" xml:space="preserve" extradata="MT">
          <source>To unload a specific grammar, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A&gt; method.</source>
          <target state="translated">사용 하 여 특정 문법을 언로드하려면는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A&gt;</target>       </trans-unit>
        <trans-unit id="586" translate="yes" xml:space="preserve">
          <source>Unloads a specified <bpt id="p1">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> object from the <bpt id="p2">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p2">&lt;/xref&gt;</ept> instance.</source>
          <target state="translated">지정 된 언로드합니다 <bpt id="p1">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 에서 개체는 <bpt id="p2">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p2">&lt;/xref&gt;</ept> 인스턴스.</target>       </trans-unit>
        <trans-unit id="587" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the recognizer is running, applications must use &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt; to pause the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; instance before loading, unloading,  enabling, or disabling a &lt;xref:System.Speech.Recognition.Grammar&gt; object.</source>
          <target state="translated">응용 프로그램을 사용 해야 인식기에서 실행 중인 경우 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;일시 중지 하는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;로드, 언로드, 활성화 또는 비활성화 하기 전에 인스턴스는 &lt;xref:System.Speech.Recognition.Grammar&gt;개체입니다.&lt;/xref:System.Speech.Recognition.Grammar&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</target>       </trans-unit>
        <trans-unit id="588" translate="yes" xml:space="preserve" extradata="MT">
          <source>To unload all &lt;xref:System.Speech.Recognition.Grammar&gt; objects, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A&gt; method.</source>
          <target state="translated">모든 언로드 &lt;xref:System.Speech.Recognition.Grammar&gt;개체를 사용 하 여는 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A&gt;메서드.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A&gt; &lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="589" translate="yes" xml:space="preserve">
          <source>The grammar object to unload.</source>
          <target state="translated">언로드할 문법 개체입니다.</target>       </trans-unit>
        <trans-unit id="590" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;Grammar&lt;/code&gt;</ph> is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;Grammar&lt;/code&gt;</ph>is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="591" translate="yes" xml:space="preserve">
          <source>The grammar is not loaded in this recognizer, or this recognizer is currently loading the grammar asynchronously.</source>
          <target state="translated">이 인식기에 문법을 로드 되지 않은 또는이 인식기 문법 비동기적으로 로드 중인 합니다.</target>       </trans-unit>
        <trans-unit id="592" translate="yes" xml:space="preserve">
          <source>Updates the specified setting for the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> with the specified integer value.</source>
          <target state="translated">지정된 된 설정에 대 한 업데이트는 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> 지정 된 정수 값을 사용 합니다.</target>       </trans-unit>
        <trans-unit id="593" translate="yes" xml:space="preserve" extradata="MT">
          <source>With the exception of <ph id="ph1">`PersistedBackgroundAdaptation`</ph>, property values set using the UpdateRecognizerSetting method remain in effect only for the current instance of &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;, after which they revert to their default settings.</source>
          <target state="translated">제외 <ph id="ph1">`PersistedBackgroundAdaptation`</ph>, UpdateRecognizerSetting 메서드를 사용 하 여 설정할 속성 값에 계속 적용만의 현재 인스턴스 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;, 기본 설정으로 되돌리기는 후.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="594" translate="yes" xml:space="preserve" extradata="MT">
          <source>See &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt; for descriptions of supported settings.</source>
          <target state="translated">참조 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;지원 되는 설정에 대 한 설명.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</target>       </trans-unit>
        <trans-unit id="595" translate="yes" xml:space="preserve">
          <source>The name of the setting to update.</source>
          <target state="translated">업데이트 설정의 이름입니다.</target>       </trans-unit>
        <trans-unit id="596" translate="yes" xml:space="preserve">
          <source>The new value for the setting.</source>
          <target state="translated">설정에 대해 새 값입니다.</target>       </trans-unit>
        <trans-unit id="597" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;settingName&lt;/code&gt;</ph> is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;settingName&lt;/code&gt;</ph>is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="598" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;settingName&lt;/code&gt;</ph> is the empty string ("").</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;settingName&lt;/code&gt;</ph>가 빈 문자열 ("").</target>       </trans-unit>
        <trans-unit id="599" translate="yes" xml:space="preserve">
          <source>The recognizer does not have a setting by that name.</source>
          <target state="translated">해당 이름의 인식기 설정을 않아도 됩니다.</target>       </trans-unit>
        <trans-unit id="600" translate="yes" xml:space="preserve">
          <source>Updates the specified speech recognition engine setting with the specified string value.</source>
          <target state="translated">지정된 된 문자열 값으로 지정 된 음성 인식 엔진 설정을 업데이트합니다.</target>       </trans-unit>
        <trans-unit id="601" translate="yes" xml:space="preserve" extradata="MT">
          <source>With the exception of <ph id="ph1">`PersistedBackgroundAdaptation`</ph>, property values set using the UpdateRecognizerSetting method remain in effect only for the current instance of &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;, after which they revert to their default settings.</source>
          <target state="translated">제외 <ph id="ph1">`PersistedBackgroundAdaptation`</ph>, UpdateRecognizerSetting 메서드를 사용 하 여 설정할 속성 값에 계속 적용만의 현재 인스턴스 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;, 기본 설정으로 되돌리기는 후.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="602" translate="yes" xml:space="preserve" extradata="MT">
          <source>See &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt; for descriptions of supported settings.</source>
          <target state="translated">참조 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;지원 되는 설정에 대 한 설명.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</target>       </trans-unit>
        <trans-unit id="603" translate="yes" xml:space="preserve">
          <source>The name of the setting to update.</source>
          <target state="translated">업데이트 설정의 이름입니다.</target>       </trans-unit>
        <trans-unit id="604" translate="yes" xml:space="preserve">
          <source>The new value for the setting.</source>
          <target state="translated">설정에 대해 새 값입니다.</target>       </trans-unit>
        <trans-unit id="605" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;settingName&lt;/code&gt;</ph> is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;settingName&lt;/code&gt;</ph>is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="606" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;settingName&lt;/code&gt;</ph> is the empty string ("").</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;settingName&lt;/code&gt;</ph>가 빈 문자열 ("").</target>       </trans-unit>
        <trans-unit id="607" translate="yes" xml:space="preserve">
          <source>The recognizer does not have a setting by that name.</source>
          <target state="translated">해당 이름의 인식기 설정을 않아도 됩니다.</target>       </trans-unit>
      </group>
    </body>
  </file>
</xliff>