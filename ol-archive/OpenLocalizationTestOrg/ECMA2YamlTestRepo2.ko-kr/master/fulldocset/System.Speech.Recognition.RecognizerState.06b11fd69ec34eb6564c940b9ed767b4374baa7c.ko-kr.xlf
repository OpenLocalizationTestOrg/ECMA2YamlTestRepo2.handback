<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.2" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="markdown" source-language="en-US" target-language="ko-kr">
    <header>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-192e1fd" tool-company="Microsoft" />
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">eac0f9f60e5c77619e9653734c454d15bb1d97f5</xliffext:olfilehash>
      <xliffext:olfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">fulldocset\System.Speech.Recognition.RecognizerState.yml</xliffext:olfilepath>
      <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">fulldocset</xliffext:oltranslationpriority>
      <xliffext:oltranslationtype xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">Human Translation</xliffext:oltranslationtype>
      <xliffext:olskeletonhash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">386fc26107cc0d820a512ad56e94df72fb24a099</xliffext:olskeletonhash>
      <xliffext:olxliffhash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">50a60284e487e541e46eca67e2ffd6431de052bc</xliffext:olxliffhash>
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Enumerates values of the recognizer's state.</source>
          <target state="translated">인식기 상태 값을 열거합니다.</target>       </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve" extradata="MT">
          <source>RecognizerState encapsulates the running state of the default speech recognition engine for clients using &lt;xref:System.Speech.Recognition.SpeechRecognizer&gt; to access the Windows Desktop Speech Recognition Technology service.</source>
          <target state="translated">RecognizerState 기본 음성 인식 엔진의 실행 상태를 사용 하는 클라이언트에 대 한 캡슐화 &lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;Windows 데스크톱 음성 인식 기술 서비스에 액세스 합니다.&lt;/xref:System.Speech.Recognition.SpeechRecognizer&gt;</target>       </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve" extradata="MT">
          <source>Applications can obtain the current state of the desktop recognition engine as a RecognizerState object by querying the &lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt; property on a &lt;xref:System.Speech.Recognition.SpeechRecognizer&gt; instance.</source>
          <target state="translated">응용 프로그램 RecognizerState 개체로 쿼리하여에 데스크톱 인식 엔진의 현재 상태를 가져올 수는 &lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;속성에는 &lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;인스턴스.&lt;/xref:System.Speech.Recognition.SpeechRecognizer&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</target>       </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve" extradata="MT">
          <source>To obtain the state of the desktop recognition engine after it changes, applications can query the &lt;xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A&gt; property of the &lt;xref:System.Speech.Recognition.StateChangedEventArgs&gt; object passed to a handler for &lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt; events.</source>
          <target state="translated">데스크톱 인식 엔진의 상태를 가져오려면 변경한 후 응용 프로그램 쿼리할 수는 &lt;xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A&gt;의 속성은 &lt;xref:System.Speech.Recognition.StateChangedEventArgs&gt;에 대 한 처리기에 전달 된 개체 &lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;이벤트.&lt;/xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt; &lt;/xref:System.Speech.Recognition.StateChangedEventArgs&gt; &lt;/xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A&gt;</target>       </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve" extradata="MT">
          <source>&gt; <ph id="ph1">[!NOTE]</ph> &gt;  &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; instances run in-process and their running state is under the control of the application.</source>
          <target state="translated">&gt; <ph id="ph1">[!NOTE]</ph> &gt; &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;인스턴스 프로세스에서 실행 하 고 실행 중인 상태로 응용 프로그램에 의해 제어 됩니다.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve" extradata="MT">
          <source>Therefore, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; does not contain a property to return a RecognizerState object.</source>
          <target state="translated">따라서 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;RecognizerState 개체를 반환 하는 속성이 포함 되어 있지 않습니다.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve" extradata="MT">
          <source>The state of a desktop speech recognition server is a read-only property and cannot be controlled programmatically.</source>
          <target state="translated">데스크톱 음성 인식 서버 상태는 읽기 전용 속성 이며 프로그래밍 방식으로 제어할 수 없습니다.</target>       </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve" extradata="MT">
          <source>Users can change a shared speech recognizer's state using the Speech Recognition user interface (UI) or through the <bpt id="p1">**</bpt>Speech Recognition<ept id="p1">**</ept> member of the Windows <bpt id="p2">**</bpt>Control Panel<ept id="p2">**</ept>.</source>
          <target state="translated">사용자가 음성 인식 사용자 인터페이스 (UI)를 사용 하 여 공유 음성 인식기의 상태를 변경할 수 또는 <bpt id="p1">**</bpt>음성 인식<ept id="p1">**</ept> Windows 소속 <bpt id="p2">**</bpt>제어판<ept id="p2">**</ept>합니다.</target>       </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve" extradata="MT">
          <source>Both the <bpt id="p1">**</bpt>On<ept id="p1">**</ept> and <bpt id="p2">**</bpt>Sleep<ept id="p2">**</ept> settings in the Speech Recognition UI correspond to the <ph id="ph1">`Listening`</ph> state.</source>
          <target state="translated">두는 <bpt id="p1">**</bpt>에<ept id="p1">**</ept> 및 <bpt id="p2">**</bpt>절전<ept id="p2">**</ept> 음성 인식 UI의 설정에 해당 하는 <ph id="ph1">`Listening`</ph> 상태입니다.</target>       </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <bpt id="p1">**</bpt>Off<ept id="p1">**</ept> setting in the Speech Recognition UI corresponds to Stopped.</source>
          <target state="translated"><bpt id="p1">**</bpt>오프<ept id="p1">**</ept> Stopped에 해당 하는 음성 인식 UI에 설정 합니다.</target>       </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve" extradata="MT">
          <source>&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt; is the other property that affects the readiness of a shared speech recognition engine to receive and process speech input.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;수신 하 고 음성 입력 처리 공유 음성 인식 엔진의 준비 상태에 영향을 주는 속성이입니다.&lt;/xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</target>       </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can use &lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt; to control whether or not a shared speech recognition engine's grammars are active for recognition.</source>
          <target state="translated">사용할 수 있습니다 &lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;공유 음성 인식 엔진의 문법을 인식에 대 한 활성 여부 제어 하는.&lt;/xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</target>       </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve" extradata="MT">
          <source>However, changing the &lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt; property has no effect on the RecognizerState property.</source>
          <target state="translated">그러나 변경 된 &lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;속성이 RecognizerState 속성에 적용 되지 않습니다.&lt;/xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</target>       </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve" extradata="MT">
          <source>Information such as the description, the supported culture and audio formats, and the recognition engine name is encapsulated in the &lt;xref:System.Speech.Recognition.RecognizerInfo&gt; type.</source>
          <target state="translated">설명, 지원 되는 문화권 및 오디오 형식을 인식 엔진 이름 등의 정보에 캡슐화 되어는 &lt;xref:System.Speech.Recognition.RecognizerInfo&gt;유형.&lt;/xref:System.Speech.Recognition.RecognizerInfo&gt;</target>       </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>The recognition engine is available to receive and analyze audio input.</source>
          <target state="translated">인식 엔진을 수신 하 고 오디오 입력을 분석할 수 있습니다.</target>       </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">추가할 수 있습니다.</target>       </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>The recognition engine is not receiving or analyzing audio input.</source>
          <target state="translated">인식 엔진은 수신 또는 오디오 입력 분석 아닙니다.</target>       </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">추가할 수 있습니다.</target>       </trans-unit>
      </group>
    </body>
  </file>
</xliff>