<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.2" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="markdown" source-language="en-US" target-language="it-it">
    <header>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-192e1fd" tool-company="Microsoft" />
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">eac0f9f60e5c77619e9653734c454d15bb1d97f5</xliffext:olfilehash>
      <xliffext:olfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">fulldocset\System.Speech.Recognition.RecognizerState.yml</xliffext:olfilepath>
      <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">fulldocset</xliffext:oltranslationpriority>
      <xliffext:oltranslationtype xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">Human Translation</xliffext:oltranslationtype>
      <xliffext:olskeletonhash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">386fc26107cc0d820a512ad56e94df72fb24a099</xliffext:olskeletonhash>
      <xliffext:olxliffhash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">50a60284e487e541e46eca67e2ffd6431de052bc</xliffext:olxliffhash>
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Enumerates values of the recognizer's state.</source>
          <target state="translated">Enumera i valori dello stato del riconoscimento.</target>       </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve" extradata="MT">
          <source>RecognizerState encapsulates the running state of the default speech recognition engine for clients using &lt;xref:System.Speech.Recognition.SpeechRecognizer&gt; to access the Windows Desktop Speech Recognition Technology service.</source>
          <target state="translated">RecognizerState incapsula lo stato di esecuzione del modulo di riconoscimento vocale predefinito per i client che utilizzano &lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;per accedere al servizio di tecnologia di riconoscimento vocale di Windows Desktop.&lt;/xref:System.Speech.Recognition.SpeechRecognizer&gt;</target>       </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve" extradata="MT">
          <source>Applications can obtain the current state of the desktop recognition engine as a RecognizerState object by querying the &lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt; property on a &lt;xref:System.Speech.Recognition.SpeechRecognizer&gt; instance.</source>
          <target state="translated">Le applicazioni possono ottenere lo stato corrente del motore di riconoscimento desktop come oggetto RecognizerState eseguendo la &lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;proprietà su un &lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;istanza.&lt;/xref:System.Speech.Recognition.SpeechRecognizer&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</target>       </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve" extradata="MT">
          <source>To obtain the state of the desktop recognition engine after it changes, applications can query the &lt;xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A&gt; property of the &lt;xref:System.Speech.Recognition.StateChangedEventArgs&gt; object passed to a handler for &lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt; events.</source>
          <target state="translated">Per ottenere lo stato del motore di riconoscimento del desktop dopo avere modificato, le applicazioni possono eseguire una query di &lt;xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A&gt;proprietà del &lt;xref:System.Speech.Recognition.StateChangedEventArgs&gt;oggetto passato a un gestore per &lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;eventi.&lt;/xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt; &lt;/xref:System.Speech.Recognition.StateChangedEventArgs&gt; &lt;/xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A&gt;</target>       </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve" extradata="MT">
          <source>&gt; <ph id="ph1">[!NOTE]</ph> &gt;  &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; instances run in-process and their running state is under the control of the application.</source>
          <target state="translated">&gt; <ph id="ph1">[!NOTE]</ph> &gt; &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;istanze eseguite in-process e il relativo stato di esecuzione è sotto il controllo dell'applicazione.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve" extradata="MT">
          <source>Therefore, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; does not contain a property to return a RecognizerState object.</source>
          <target state="translated">Pertanto, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;non contiene una proprietà per restituire un oggetto RecognizerState.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve" extradata="MT">
          <source>The state of a desktop speech recognition server is a read-only property and cannot be controlled programmatically.</source>
          <target state="translated">Lo stato di un server di riconoscimento vocale desktop è una proprietà di sola lettura e non può essere controllato a livello di codice.</target>       </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve" extradata="MT">
          <source>Users can change a shared speech recognizer's state using the Speech Recognition user interface (UI) or through the <bpt id="p1">**</bpt>Speech Recognition<ept id="p1">**</ept> member of the Windows <bpt id="p2">**</bpt>Control Panel<ept id="p2">**</ept>.</source>
          <target state="translated">Gli utenti possono modificare lo stato del sistema di riconoscimento vocale condivisa tramite l'interfaccia utente di riconoscimento vocale (UI) o tramite il <bpt id="p1">**</bpt>il riconoscimento vocale<ept id="p1">**</ept> membro delle finestre <bpt id="p2">**</bpt>Pannello di controllo<ept id="p2">**</ept>.</target>       </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve" extradata="MT">
          <source>Both the <bpt id="p1">**</bpt>On<ept id="p1">**</ept> and <bpt id="p2">**</bpt>Sleep<ept id="p2">**</ept> settings in the Speech Recognition UI correspond to the <ph id="ph1">`Listening`</ph> state.</source>
          <target state="translated">Sia il <bpt id="p1">**</bpt>su<ept id="p1">**</ept> e <bpt id="p2">**</bpt>sospensione<ept id="p2">**</ept> impostazioni nell'interfaccia utente di riconoscimento vocale corrispondono al <ph id="ph1">`Listening`</ph> dello stato.</target>       </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <bpt id="p1">**</bpt>Off<ept id="p1">**</ept> setting in the Speech Recognition UI corresponds to Stopped.</source>
          <target state="translated">Il <bpt id="p1">**</bpt>Off<ept id="p1">**</ept> impostazione nell'interfaccia utente di riconoscimento vocale corrisponde all'operazione interrotta.</target>       </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve" extradata="MT">
          <source>&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt; is the other property that affects the readiness of a shared speech recognition engine to receive and process speech input.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;è l'altra proprietà che interessa la preparazione di un modulo di riconoscimento vocale condivisa per ricevere ed elaborare l'input vocale.&lt;/xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</target>       </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can use &lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt; to control whether or not a shared speech recognition engine's grammars are active for recognition.</source>
          <target state="translated">È possibile utilizzare &lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;per controllare o meno le grammatiche del motore di riconoscimento vocale condivisa sono attive per il riconoscimento.&lt;/xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</target>       </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve" extradata="MT">
          <source>However, changing the &lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt; property has no effect on the RecognizerState property.</source>
          <target state="translated">Tuttavia, se si modifica la &lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;proprietà non ha alcun effetto sulla proprietà RecognizerState.&lt;/xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</target>       </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve" extradata="MT">
          <source>Information such as the description, the supported culture and audio formats, and the recognition engine name is encapsulated in the &lt;xref:System.Speech.Recognition.RecognizerInfo&gt; type.</source>
          <target state="translated">Informazioni quali la descrizione, la lingua supportata e formati audio e il nome del motore di riconoscimento sono incapsulate nel &lt;xref:System.Speech.Recognition.RecognizerInfo&gt;tipo.&lt;/xref:System.Speech.Recognition.RecognizerInfo&gt;</target>       </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>The recognition engine is available to receive and analyze audio input.</source>
          <target state="translated">Il modulo di riconoscimento è disponibile per ricevere e analizzare l'input audio.</target>       </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">Da aggiungere.</target>       </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>The recognition engine is not receiving or analyzing audio input.</source>
          <target state="translated">Il modulo di riconoscimento non sta ricevendo o analisi di input audio.</target>       </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">Da aggiungere.</target>       </trans-unit>
      </group>
    </body>
  </file>
</xliff>