<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.2" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="markdown" source-language="en-US" target-language="pl-pl">
    <header>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-192e1fd" tool-company="Microsoft" />
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">4e1507b0a4dd184bf9c482917c9c1a540db925be</xliffext:olfilehash>
      <xliffext:olfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">fulldocset\System.Speech.Recognition.SpeechRecognitionEngine.yml</xliffext:olfilepath>
      <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">fulldocset</xliffext:oltranslationpriority>
      <xliffext:oltranslationtype xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">Human Translation</xliffext:oltranslationtype>
      <xliffext:olskeletonhash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">b94eb1b586a4018cc2146ebb85f70ee9b49e7c8c</xliffext:olskeletonhash>
      <xliffext:olxliffhash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">2438bcf9dbedec08492e9e6fb4d249fc811bd84e</xliffext:olxliffhash>
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Provides the means to access and manage an in-process speech recognition engine.</source>
          <target state="translated">Pozwala na uzyskanie dostępu i zarządzanie aparatu rozpoznawania mowy w procesie.</target>       </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can create an instance of this class for any of the installed speech recognizers.</source>
          <target state="translated">Dla każdego aparatów rozpoznawania mowy zainstalowane, można utworzyć wystąpienia tej klasy.</target>       </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get information about which recognizers are installed, use the static &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt; method.</source>
          <target state="translated">Aby uzyskać informacje o tym, które są zainstalowane aparatów rozpoznawania, użyj statycznych &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;</target>       </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve" extradata="MT">
          <source>This class is for running speech recognition engines in-process, and provides control over various aspects of speech recognition, as follows:      -   To create an in-process speech recognizer, use one of the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.%23ctor%2A&gt; constructors.</source>
          <target state="translated">Ta klasa jest uruchomiona mowy rozpoznawania aparaty w procesie i zapewnia kontrolę nad różnych aspektów rozpoznawanie mowy w następujący sposób: — Aby utworzyć rozpoznawania mowy w procesie, użyj jednej z &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.%23ctor%2A&gt;konstruktorów.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.%23ctor%2A&gt;</target>       </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   To manage speech recognition grammars, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A&gt; methods, and the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A&gt; property.</source>
          <target state="translated">-Aby zarządzać gramatyki rozpoznawania mowy, użyj &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A&gt;, i &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A&gt;metod i &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A&gt;Właściwości.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</target>       </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   To configure the input to the recognizer, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt;, or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt; method.</source>
          <target state="translated">— Aby skonfigurować dane wejściowe dla aparatu rozpoznawania, użyj &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt;, lub &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;</target>       </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   To perform speech recognition, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt; method.</source>
          <target state="translated">-Aby przeprowadzić rozpoznawanie mowy, należy użyć &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;lub &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</target>       </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   To modify how recognition handles silence or unexpected input, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt; properties.</source>
          <target state="translated">— Aby zmodyfikować sposób rozpoznawania obsługi wyciszenia lub nieoczekiwane dane wejściowe, należy użyć &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;, i &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;Właściwości.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</target>       </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   To change the number of alternates the recognizer returns, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates%2A&gt; property.</source>
          <target state="translated">— Aby zmienić numer alternatyw zwraca aparat rozpoznawania, użyj &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates%2A&gt;Właściwości.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates%2A&gt;</target>       </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer returns recognition results in a &lt;xref:System.Speech.Recognition.RecognitionResult&gt; object.</source>
          <target state="translated">Aparat rozpoznawania zwraca wyniki rozpoznawania w &lt;xref:System.Speech.Recognition.RecognitionResult&gt;obiektu.&lt;/xref:System.Speech.Recognition.RecognitionResult&gt;</target>       </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   To synchronize changes to the recognizer, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt; method.</source>
          <target state="translated">-Aby zsynchronizować zmiany aparat rozpoznawania, użyj &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</target>       </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer uses more than one thread to perform tasks.</source>
          <target state="translated">Aparat rozpoznawania używa więcej niż jeden wątek, do wykonywania zadań.</target>       </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   To emulate input to the recognizer, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt; and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt; methods.</source>
          <target state="translated">-Aby emulować dane wejściowe dla aparatu rozpoznawania, należy użyć &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;i &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;</target>       </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve" extradata="MT">
          <source>The SpeechRecognitionEngine object is for the sole use of the process that instantiated the object.</source>
          <target state="translated">Obiekt SpeechRecognitionEngine jest wyłącznie do użytku procesu wystąpienia obiektu.</target>       </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve" extradata="MT">
          <source>By contrast, the &lt;xref:System.Speech.Recognition.SpeechRecognizer&gt; shares a single recognizer with any application that wants to use it.</source>
          <target state="translated">Przez kontrast, &lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;udostępnia jeden aparat rozpoznawania z dowolnej aplikacji, która chce go używać.&lt;/xref:System.Speech.Recognition.SpeechRecognizer&gt;</target>       </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve" extradata="MT">
          <source>&gt; <ph id="ph1">[!NOTE]</ph> &gt;  Always call &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Dispose%2A&gt; before you release your last reference to the speech recognizer.</source>
          <target state="translated">&gt; <ph id="ph1">[!NOTE]</ph> &gt; Wywołania zawsze &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Dispose%2A&gt;przed zwolnieniem ostatniego odwołania do rozpoznawania mowy.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.Dispose%2A&gt;</target>       </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve" extradata="MT">
          <source>Otherwise, the resources it is using will not be freed until the garbage collector calls the recognizer object's <ph id="ph1">`Finalize`</ph> method.</source>
          <target state="translated">W przeciwnym razie używa zasobów nie zostanie zwolniona, dopóki moduł garbage collector wywołuje obiekt aparatu rozpoznawania <ph id="ph1">`Finalize`</ph> metody.</target>       </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Initializes a new instance of the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> class using the default speech recognizer for the system.</source>
          <target state="translated">Inicjuje nowe wystąpienie klasy <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> przy użyciu aparatu rozpoznawania mowy domyślne systemu.</target>       </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve" extradata="MT">
          <source>Before the speech recognizer can begin speech recognition, you must load at least one recognition grammar and configure the input for the recognizer.</source>
          <target state="translated">Rozpoczęciem rozpoznawania mowy rozpoznawania mowy, należy załadować co najmniej jedną gramatykę rozpoznawania i skonfigurować dane wejściowe dla aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve" extradata="MT">
          <source>To load a grammar, call the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt; method.</source>
          <target state="translated">Aby załadować gramatyki, należy wywołać &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;lub &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</target>       </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve" extradata="MT">
          <source>To configure the audio input, use one of the following methods:      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt;</source>
          <target state="translated">Aby skonfigurować wejście audio, użyj jednej z następujących metod:- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;</target>       </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>Initializes a new instance of the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> class using the default speech recognizer for a specified locale.</source>
          <target state="translated">Inicjuje nowe wystąpienie klasy <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> dla określonych ustawień regionalnych przy użyciu domyślnego rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve" extradata="MT">
          <source>Microsoft Windows and the System.Speech API accept all valid language-country codes.</source>
          <target state="translated">Microsoft Windows i interfejsu API System.Speech zaakceptować wszystkie prawidłowe kody języka kraju.</target>       </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve" extradata="MT">
          <source>To perform speech recognition using the language specified in the <ph id="ph1">`CultureInfo`</ph> argument, a speech recognition engine that supports that language-country code must be installed.</source>
          <target state="translated">Aby przeprowadzić rozpoznawanie mowy przy użyciu języka określonego w <ph id="ph1">`CultureInfo`</ph> argument, który obsługuje kod kraju język musi być zainstalowany aparatu rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve" extradata="MT">
          <source>The speech recognition engines that shipped with Microsoft Windows 7 work with the following language-country codes.</source>
          <target state="translated">Aparatów rozpoznawania mowy dostarczonych z programem Microsoft Windows 7 skontaktować się z następujących kodów kraju języka.</target>       </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   en-GB.</source>
          <target state="translated">-en-GB.</target>       </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve" extradata="MT">
          <source>English (United Kingdom)      -   en-US.</source>
          <target state="translated">Angielski (brytyjski) - en US.</target>       </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve" extradata="MT">
          <source>English (United States)      -   de-DE.</source>
          <target state="translated">Angielski (Stany Zjednoczone) - de-DE.</target>       </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve" extradata="MT">
          <source>German (Germany)      -   es-ES.</source>
          <target state="translated">Niemiecki (Niemcy) - es-ES.</target>       </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve" extradata="MT">
          <source>Spanish (Spain)      -   fr-FR.</source>
          <target state="translated">Hiszpański (Hiszpania) - np.</target>       </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve" extradata="MT">
          <source>French (France)      -   ja-JP.</source>
          <target state="translated">Francuski (Francja) - ja-JP.</target>       </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve" extradata="MT">
          <source>Japanese (Japan)      -   zh-CN.</source>
          <target state="translated">Japoński (Japonia) - zh-CN.</target>       </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve" extradata="MT">
          <source>Chinese (China)      -   zh-TW.</source>
          <target state="translated">Chiński (Chiny) - zh-TW.</target>       </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve" extradata="MT">
          <source>Chinese (Taiwan)       Two-letter language codes such as "en", "fr", or "es" are also permitted.</source>
          <target state="translated">Chiński (Tajwan) dwuliterowych kodów języków przykład "en", "fr" lub "es" również jest dozwolone.</target>       </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve" extradata="MT">
          <source>Before the speech recognizer can begin recognition, you must load at least one speech recognition grammar and configure the input for the recognizer.</source>
          <target state="translated">Rozpoczęciem rozpoznawania mowy rozpoznawania, należy załadować gramatyki rozpoznawania mowy co najmniej jedną i skonfigurować dane wejściowe dla aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve" extradata="MT">
          <source>To load a grammar, call the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt; method.</source>
          <target state="translated">Aby załadować gramatyki, należy wywołać &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;lub &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</target>       </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve" extradata="MT">
          <source>To configure the audio input, use one of the following methods:      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt;</source>
          <target state="translated">Aby skonfigurować wejście audio, użyj jednej z następujących metod:- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;</target>       </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>The locale that the speech recognizer must support.</source>
          <target state="translated">Ustawienia regionalne muszą obsługiwać rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>None of the installed speech recognizers support the specified locale, or <bpt id="p1">&lt;code&gt;</bpt><ph id="ph1">culture</ph><ept id="p1">&lt;/code&gt;</ept> is the invariant culture.</source>
          <target state="translated">Żadne aparaty rozpoznawania mowy zainstalowanych obsługuje określonych ustawień regionalnych, lub <bpt id="p1">&lt;code&gt;</bpt> <ph id="ph1">culture</ph> <ept id="p1">&lt;/code&gt;</ept> jest niezmienna kultura.</target>       </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;Culture&lt;/code&gt;</ph> is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;Culture&lt;/code&gt;</ph>is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>Initializes a new instance of the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> using the information in a <bpt id="p2">&lt;xref href="System.Speech.Recognition.RecognizerInfo"&gt;</bpt><ept id="p2">&lt;/xref&gt;</ept> object to specify the recognizer to use.</source>
          <target state="translated">Inicjuje nowe wystąpienie klasy <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> korzystając z informacji w <bpt id="p2">&lt;xref href="System.Speech.Recognition.RecognizerInfo"&gt;</bpt> <ept id="p2">&lt;/xref&gt;</ept> obiektu w celu określenia aparatu rozpoznawania do użycia.</target>       </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can create an instance of this class for any of the installed speech recognizers.</source>
          <target state="translated">Dla każdego aparatów rozpoznawania mowy zainstalowane, można utworzyć wystąpienia tej klasy.</target>       </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get information about which recognizers are installed, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt; method.</source>
          <target state="translated">Aby uzyskać informacje o tym, które są zainstalowane aparatów rozpoznawania, użyj &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;</target>       </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve" extradata="MT">
          <source>Before the speech recognizer can begin recognition, you must load at least one speech recognition grammar and configure the input for the recognizer.</source>
          <target state="translated">Rozpoczęciem rozpoznawania mowy rozpoznawania, należy załadować gramatyki rozpoznawania mowy co najmniej jedną i skonfigurować dane wejściowe dla aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve" extradata="MT">
          <source>To load a grammar, call the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt; method.</source>
          <target state="translated">Aby załadować gramatyki, należy wywołać &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;lub &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</target>       </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve" extradata="MT">
          <source>To configure the audio input, use one of the following methods:      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt;</source>
          <target state="translated">Aby skonfigurować wejście audio, użyj jednej z następujących metod:- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;</target>       </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>The information for the specific speech recognizer.</source>
          <target state="translated">Informacje dotyczące aparatu rozpoznawania mowy określonych.</target>       </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>Initializes a new instance of the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> class with a string parameter that specifies the name of the recognizer to use.</source>
          <target state="translated">Inicjuje nowe wystąpienie klasy <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> klasy z parametrem ciąg określający nazwę aparatu rozpoznawania do użycia.</target>       </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve" extradata="MT">
          <source>The token name of the recognizer is the value of the &lt;xref:System.Speech.Recognition.RecognizerInfo.Id%2A&gt; property of the &lt;xref:System.Speech.Recognition.RecognizerInfo&gt; object returned by the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A&gt; property of the recognizer.</source>
          <target state="translated">Nazwa tokenu aparat rozpoznawania jest wartość &lt;xref:System.Speech.Recognition.RecognizerInfo.Id%2A&gt;Właściwość &lt;xref:System.Speech.Recognition.RecognizerInfo&gt;obiektu zwróconego przez &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A&gt;Właściwości aparat rozpoznawania.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A&gt; &lt;/xref:System.Speech.Recognition.RecognizerInfo&gt; &lt;/xref:System.Speech.Recognition.RecognizerInfo.Id%2A&gt;</target>       </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get a collection of all the installed recognizers, use the static &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt; method.</source>
          <target state="translated">Aby uzyskać kolekcję wszystkich zainstalowanych aparatów rozpoznawania, użyj statycznych &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;</target>       </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve" extradata="MT">
          <source>Before the speech recognizer can begin recognition, you must load at least one speech recognition grammar and configure the input for the recognizer.</source>
          <target state="translated">Rozpoczęciem rozpoznawania mowy rozpoznawania, należy załadować gramatyki rozpoznawania mowy co najmniej jedną i skonfigurować dane wejściowe dla aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve" extradata="MT">
          <source>To load a grammar, call the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt; method.</source>
          <target state="translated">Aby załadować gramatyki, należy wywołać &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;lub &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</target>       </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve" extradata="MT">
          <source>To configure the audio input, use one of the following methods:      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt;</source>
          <target state="translated">Aby skonfigurować wejście audio, użyj jednej z następujących metod:- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;</target>       </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>The token name of the speech recognizer to use.</source>
          <target state="translated">Nazwa tokenu aparatu rozpoznawania mowy do użycia.</target>       </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>No speech recognizer with that token name is installed, or <bpt id="p1">&lt;code&gt;</bpt><ph id="ph1">recognizerId</ph><ept id="p1">&lt;/code&gt;</ept> is the empty string ("").</source>
          <target state="translated">Zainstalowano żadnego aparatu rozpoznawania mowy o tej nazwie tokenu, lub <bpt id="p1">&lt;code&gt;</bpt> <ph id="ph1">recognizerId</ph> <ept id="p1">&lt;/code&gt;</ept> jest pustym ciągiem ("").</target>       </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;recognizerId&lt;/code&gt;</ph> is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;recognizerId&lt;/code&gt;</ph>is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>Gets the format of the audio being received by the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated">Pobiera format audio odbierane przez <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve" extradata="MT">
          <source>To configure the audio input, use one of the following methods:      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt;      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt;</source>
          <target state="translated">Aby skonfigurować wejście audio, użyj jednej z następujących metod:- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt;- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;</target>       </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>The format of audio at the input to the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> instance, or <bpt id="p2">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p2">&lt;/xref&gt;</ept> if the input is not configured or set to the null input.</source>
          <target state="translated">Format audio w danych wejściowych na <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> wystąpienia, lub <bpt id="p2">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt> <ept id="p2">&lt;/xref&gt;</ept> Jeśli dane wejściowe nie jest skonfigurowany lub wartość null danych wejściowych.</target>       </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>Gets the level of the audio being received by the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated">Pobiera poziom dźwięku odbierane przez <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve" extradata="MT">
          <source>The value 0 represents silence, and 100 represents the maximum input volume.</source>
          <target state="translated">Wartość 0 oznacza wyciszenia, a maksymalna głośność reprezentuje 100.</target>       </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>The audio level of the input to the speech recognizer, from 0 through 100.</source>
          <target state="translated">Poziom audio w danych wejściowych rozpoznawania mowy od 0 do 100.</target>       </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>Raised when the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> reports the level of its audio input.</source>
          <target state="translated">Wywoływane, gdy <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> raportuje poziomu jego wejście audio.</target>       </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve" extradata="MT">
          <source>The &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; raises this event multiple times per second.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;Zgłasza zdarzenie, to wiele razy w ciągu sekundy.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve" extradata="MT">
          <source>The frequency with which the event is raised depends on the computer on which the application is running.</source>
          <target state="translated">Częstotliwość, z którym zdarzenia zależy od komputera, na którym jest uruchomiona aplikacja.</target>       </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get the audio level at the time of the event, use the &lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A&gt; property of the associated &lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt;.</source>
          <target state="translated">Aby uzyskać poziom audio w czasie zdarzenia, użyj &lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A&gt;właściwości skojarzone &lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt;.&lt;/xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt; &lt;/xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A&gt;</target>       </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get the current audio level of the input to the recognizer, use the recognizer's &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel%2A&gt; property.</source>
          <target state="translated">Aby uzyskać bieżący poziom audio w danych wejściowych aparat rozpoznawania, należy użyć aparat rozpoznawania &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel%2A&gt;Właściwości.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel%2A&gt;</target>       </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create an AudioLevelUpdated delegate, you identify the method that will handle the event.</source>
          <target state="translated">Podczas tworzenia obiektu delegowanego AudioLevelUpdated, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływana, gdy wystąpi zdarzenie, o ile nie usuniesz delegata.</target>       </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">Do dodania.</target>       </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>Gets the current location in the audio stream being generated by the device that is providing input to the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated">Pobiera bieżącą lokalizację w strumieniem audio generowany przez urządzenie, który dostarcza dane wejściowe <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve" extradata="MT">
          <source>The AudioPosition property references the input device's position in its generated audio stream.</source>
          <target state="translated">Właściwość AudioPosition odwołuje się do pozycji urządzenia wejściowego w jego wygenerowanego strumieniem audio.</target>       </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve" extradata="MT">
          <source>By contrast, the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt; property references the recognizer's position within its audio input.</source>
          <target state="translated">Z kolei &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;właściwość odwołuje się do pozycji aparat rozpoznawania w jego wejście audio.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</target>       </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve" extradata="MT">
          <source>These positions can be different.</source>
          <target state="translated">Te pozycje mogą być różne.</target>       </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve" extradata="MT">
          <source>For example, if the recognizer has received input for which it has not yet generated a recognition result then the value of the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt; property is less than the value of the AudioPosition property.</source>
          <target state="translated">Na przykład jeśli aparat rozpoznawania otrzymał wejściowych, do których nie ma jeszcze generowane w wyniku rozpoznawania, a następnie wartość &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;Właściwości jest mniejsza niż wartość właściwości AudioPosition.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</target>       </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source>The current location in the audio stream being generated by the input device.</source>
          <target state="translated">Bieżąca lokalizacja strumieniem audio generowany przez urządzenia wejściowego.</target>       </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source>Raised when the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> detects a problem in the audio signal.</source>
          <target state="translated">Wywoływane, gdy <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> wykryje problem w sygnału dźwiękowego.</target>       </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get which problem occurred, use the &lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A&gt; property of the associated &lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt;.</source>
          <target state="translated">Aby uzyskać, jaki problem wystąpił, użyj &lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A&gt;właściwości skojarzone &lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt;.&lt;/xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt; &lt;/xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A&gt;</target>       </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create an AudioSignalProblemOccurred delegate, you identify the method that will handle the event.</source>
          <target state="translated">Podczas tworzenia obiektu delegowanego AudioSignalProblemOccurred, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływana, gdy wystąpi zdarzenie, o ile nie usuniesz delegata.</target>       </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">Do dodania.</target>       </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source>Gets the state of the audio being received by the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated">Pobiera stan audio odbierane przez <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve" extradata="MT">
          <source>The AudioState property represents the audio state with a member of the &lt;xref:System.Speech.Recognition.AudioState&gt; enumeration.</source>
          <target state="translated">Właściwość AudioState reprezentuje stan dźwięku z elementem członkowskim o &lt;xref:System.Speech.Recognition.AudioState&gt;wyliczenie.&lt;/xref:System.Speech.Recognition.AudioState&gt;</target>       </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source>The state of the audio input to the speech recognizer.</source>
          <target state="translated">Stan wejście audio do rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source>Raised when the state changes in the audio being received by the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated">Wywoływane, gdy zmian stanu, które usłyszysz odbierane przez <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get the audio state at the time of the event, use the &lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A&gt; property of the associated &lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs&gt;.</source>
          <target state="translated">Aby pobrać stan dźwięku w czasie zdarzenia, użyj &lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A&gt;właściwości skojarzone &lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs&gt;.&lt;/xref:System.Speech.Recognition.AudioStateChangedEventArgs&gt; &lt;/xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A&gt;</target>       </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get the current audio state of the input to the recognizer, use the recognizer's &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A&gt; property.</source>
          <target state="translated">Aby uzyskać bieżący stan audio w danych wejściowych aparat rozpoznawania, należy użyć aparat rozpoznawania &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A&gt;Właściwości.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A&gt;</target>       </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about audio state, see the &lt;xref:System.Speech.Recognition.AudioState&gt; enumeration.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat stanu audio, zobacz &lt;xref:System.Speech.Recognition.AudioState&gt;wyliczenie.&lt;/xref:System.Speech.Recognition.AudioState&gt;</target>       </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create an AudioStateChanged delegate, you identify the method that will handle the event.</source>
          <target state="translated">Podczas tworzenia obiektu delegowanego AudioStateChanged, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływana, gdy wystąpi zdarzenie, o ile nie usuniesz delegata.</target>       </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">Do dodania.</target>       </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve">
          <source>Gets or sets the time interval during which a <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> accepts input containing only background noise, before finalizing recognition.</source>
          <target state="translated">Pobiera lub ustawia przedział czasu, w którym <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> akceptuje wejściowych zawierających tylko szumu tła, przed zakończeniem rozpoznawania.</target>       </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve" extradata="MT">
          <source>Each speech recognizer has an algorithm to distinguish between silence and speech.</source>
          <target state="translated">Każdy aparat rozpoznawania mowy zawiera algorytm odróżnić wyciszenia mowy.</target>       </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer classifies as background noise any non-silence input that does not match the initial rule of any of the recognizer's loaded and enabled speech recognition grammars.</source>
          <target state="translated">Aparat rozpoznawania klasyfikuje szumu tła żadnych innych niż wyciszenia wejściowej niezgodny początkowej reguły dowolnego aparat rozpoznawania załadowane i włączone gramatyki rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the recognizer receives only background noise and silence within the babble timeout interval, then the recognizer finalizes that recognition operation.</source>
          <target state="translated">Jeśli aparat rozpoznawania odbiera tylko hałas w tle i wyciszenia w babble — interwał limitu czasu, następnie aparat rozpoznawania Kończenie znajdujących się w tej operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   For asynchronous recognition operations, the recognizer raises the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt; event, where the &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A?displayProperty=fullName&gt; property is <ph id="ph1">`true`</ph>, and the &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=fullName&gt; property is <ph id="ph2">`null`</ph>.</source>
          <target state="translated">— Dla operacji asynchronicznych rozpoznawania zgłasza aparat rozpoznawania &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;zdarzeń, gdy &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A?displayProperty=fullName&gt;właściwość jest <ph id="ph1">`true`</ph>i &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=fullName&gt;jest właściwość <ph id="ph2">`null`</ph>.&lt;/xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=fullName&gt; &lt;/xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A?displayProperty=fullName&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</target>       </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   For synchronous recognition operations and emulation, the recognizer returns <ph id="ph1">`null`</ph>, instead of a valid &lt;xref:System.Speech.Recognition.RecognitionResult&gt;.</source>
          <target state="translated">— Dla operacji rozpoznawania synchroniczne i emulacji zwraca aparat rozpoznawania <ph id="ph1">`null`</ph>, zamiast prawidłową &lt;xref:System.Speech.Recognition.RecognitionResult&gt;.&lt;/xref:System.Speech.Recognition.RecognitionResult&gt;</target>       </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the babble timeout period is set to 0, the recognizer does not perform a babble timeout check.</source>
          <target state="translated">Jeśli babble limit czasu jest ustawiona na 0, aparat rozpoznawania nie sprawdzić babble limitu czasu.</target>       </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve" extradata="MT">
          <source>The timeout interval can be any non-negative value.</source>
          <target state="translated">Interwał limitu czasu może być wartością nieujemną.</target>       </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve" extradata="MT">
          <source>The default is 0 seconds.</source>
          <target state="translated">Wartość domyślna to 0 sekund.</target>       </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve">
          <source>The duration of the time interval.</source>
          <target state="translated">Czas trwania interwału czasu.</target>       </trans-unit>
        <trans-unit id="208" translate="yes" xml:space="preserve">
          <source>This property is set to less than 0 seconds.</source>
          <target state="translated">Ta właściwość ma ustawioną mniejszy niż 0 sekund.</target>       </trans-unit>
        <trans-unit id="209" translate="yes" xml:space="preserve">
          <source>Disposes the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> object.</source>
          <target state="translated">Usuwa <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> obiektu.</target>       </trans-unit>
        <trans-unit id="210" translate="yes" xml:space="preserve">
          <source>Disposes the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> object and releases resources used during the session.</source>
          <target state="translated">Usuwa <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> obiektu i zwalnia zasoby używane w podczas sesji.</target>       </trans-unit>
        <trans-unit id="211" translate="yes" xml:space="preserve">
          <source><bpt id="p1">&lt;xref uid="langword_csharp_true" name="true" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> to release both managed and unmanaged resources; <bpt id="p2">&lt;xref uid="langword_csharp_false" name="false" href=""&gt;</bpt><ept id="p2">&lt;/xref&gt;</ept> to release only unmanaged resources.</source>
          <target state="translated"><bpt id="p1">&lt;xref uid="langword_csharp_true" name="true" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>Aby zwolnić zasoby zarządzane i niezarządzane; <bpt id="p2">&lt;xref uid="langword_csharp_false" name="false" href=""&gt;</bpt> <ept id="p2">&lt;/xref&gt;</ept> aby zwolnić tylko zasoby niezarządzane.</target>       </trans-unit>
        <trans-unit id="212" translate="yes" xml:space="preserve">
          <source>Emulates input of a phrase to the speech recognizer, using text in place of audio for synchronous speech recognition.</source>
          <target state="translated">Emuluje wprowadzania frazę do rozpoznawania mowy, przy użyciu tekstu zamiast audio rozpoznawania mowy synchronicznego.</target>       </trans-unit>
        <trans-unit id="213" translate="yes" xml:space="preserve" extradata="MT">
          <source>The speech recognizer raises the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; events as if the recognition operation is not emulated.</source>
          <target state="translated">Generuje aparatu rozpoznawania mowy &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;, i &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;zdarzeń tak, jakby operacji rozpoznawania nie jest emulowana.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</target>       </trans-unit>
        <trans-unit id="214" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers that ship with Vista and Windows 7 ignore case and character width when applying grammar rules to the input phrase.</source>
          <target state="translated">Aparaty rozpoznawania, które są dostarczane z Vista i Windows 7 Ignoruj wielkość liter i znaków szerokości, stosując reguły gramatyki do wprowadzania frazy.</target>       </trans-unit>
        <trans-unit id="215" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about this type of comparison, see the &lt;xref:System.Globalization.CompareOptions&gt; enumeration values &lt;xref:System.Globalization.CompareOptions&gt; and &lt;xref:System.Globalization.CompareOptions&gt;.</source>
          <target state="translated">Aby uzyskać więcej informacji o tym typie porównanie zobacz &lt;xref:System.Globalization.CompareOptions&gt;wartości wyliczenia &lt;xref:System.Globalization.CompareOptions&gt;i &lt;xref:System.Globalization.CompareOptions&gt;.&lt;/xref:System.Globalization.CompareOptions&gt; &lt;/xref:System.Globalization.CompareOptions&gt; &lt;/xref:System.Globalization.CompareOptions&gt;</target>       </trans-unit>
        <trans-unit id="216" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</source>
          <target state="translated">Aparatów rozpoznawania także zignorować nowych wierszy oraz dodatkowy biały znak i Traktuj znaki interpunkcyjne jako dane wejściowe literału.</target>       </trans-unit>
        <trans-unit id="217" translate="yes" xml:space="preserve">
          <source>The input for the recognition operation.</source>
          <target state="translated">Dane wejściowe dla operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="218" translate="yes" xml:space="preserve">
          <source>The result for the recognition operation, or <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> if the operation is not successful or the recognizer is not enabled.</source>
          <target state="translated">Wynik operacji rozpoznawania lub <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> Jeśli operacja nie powiedzie się lub nie włączono aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="219" translate="yes" xml:space="preserve">
          <source>The recognizer has no speech recognition grammars loaded.</source>
          <target state="translated">Aparat rozpoznawania ma nie gramatyki rozpoznawania mowy załadowane.</target>       </trans-unit>
        <trans-unit id="220" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;inputText&lt;/code&gt;</ph> is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;inputText&lt;/code&gt;</ph>is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="221" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;inputText&lt;/code&gt;</ph> is the empty string ("").</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;inputText&lt;/code&gt;</ph>jest pustym ciągiem ("").</target>       </trans-unit>
        <trans-unit id="222" translate="yes" xml:space="preserve">
          <source>Emulates input of specific words to the speech recognizer, using text in place of audio for synchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the words and the loaded speech recognition grammars.</source>
          <target state="translated">Emuluje wprowadzania słów do rozpoznawania mowy, przy użyciu tekstu zamiast audio rozpoznawania mowy synchroniczne i określa sposób obsługi przez aparat rozpoznawania porównanie Unicode słów i gramatyki rozpoznawania mowy załadowany.</target>       </trans-unit>
        <trans-unit id="223" translate="yes" xml:space="preserve" extradata="MT">
          <source>The speech recognizer raises the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; events as if the recognition operation is not emulated.</source>
          <target state="translated">Generuje aparatu rozpoznawania mowy &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;, i &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;zdarzeń tak, jakby operacji rozpoznawania nie jest emulowana.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</target>       </trans-unit>
        <trans-unit id="224" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer uses <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">Aparat rozpoznawania używa <ph id="ph1">`compareOptions`</ph> po stosuje reguły gramatyki do frazy wejściowych.</target>       </trans-unit>
        <trans-unit id="225" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the &lt;xref:System.Globalization.CompareOptions&gt; or &lt;xref:System.Globalization.CompareOptions&gt; value is present.</source>
          <target state="translated">Aparaty rozpoznawania, które są dostarczane z Vista i Windows 7 Ignoruj wielkość liter, jeśli &lt;xref:System.Globalization.CompareOptions&gt;lub &lt;xref:System.Globalization.CompareOptions&gt;ma wartość.&lt;/xref:System.Globalization.CompareOptions&gt; &lt;/xref:System.Globalization.CompareOptions&gt;</target>       </trans-unit>
        <trans-unit id="226" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer always ignores the character width and never ignores the Kana type.</source>
          <target state="translated">Aparat rozpoznawania zawsze ignoruje szerokość znaku i nigdy nie ignoruje typu znaki Kana.</target>       </trans-unit>
        <trans-unit id="227" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer also ignores new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Aparat rozpoznawania również ignoruje nowych wierszy oraz dodatkowy biały znak i traktuje jako dane wejściowe literał znaków interpunkcyjnych.</target>       </trans-unit>
        <trans-unit id="228" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about character width and Kana type, see the &lt;xref:System.Globalization.CompareOptions&gt; enumeration.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat szerokość znaków i wpisz znaki Kana, zobacz &lt;xref:System.Globalization.CompareOptions&gt;wyliczenie.&lt;/xref:System.Globalization.CompareOptions&gt;</target>       </trans-unit>
        <trans-unit id="229" translate="yes" xml:space="preserve">
          <source>An array of word units that contains the input for the recognition operation.</source>
          <target state="translated">Tablica jednostki słowa zawierającego dane wejściowe dla operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="230" translate="yes" xml:space="preserve">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">Bitowe połączenie wartości wyliczenia, które opisują typ porównania do użycia dla operacji rozpoznawania emulowanej.</target>       </trans-unit>
        <trans-unit id="231" translate="yes" xml:space="preserve">
          <source>The result for the recognition operation, or <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> if the operation is not successful or the recognizer is not enabled.</source>
          <target state="translated">Wynik operacji rozpoznawania lub <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> Jeśli operacja nie powiedzie się lub nie włączono aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="232" translate="yes" xml:space="preserve">
          <source>The recognizer has no speech recognition grammars loaded.</source>
          <target state="translated">Aparat rozpoznawania ma nie gramatyki rozpoznawania mowy załadowane.</target>       </trans-unit>
        <trans-unit id="233" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;wordUnits&lt;/code&gt;</ph> is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;wordUnits&lt;/code&gt;</ph>is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="234" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;wordUnits&lt;/code&gt;</ph> contains one or more <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> elements.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;wordUnits&lt;/code&gt;</ph>zawiera co najmniej jeden <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> elementów.</target>       </trans-unit>
        <trans-unit id="235" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;compareOptions&lt;/code&gt;</ph> contains the <ph id="ph2">&lt;xref:System.Globalization.CompareOptions&gt;</ph>, <ph id="ph3">&lt;xref:System.Globalization.CompareOptions&gt;</ph>, or <ph id="ph4">&lt;xref:System.Globalization.CompareOptions&gt;</ph> flag.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;compareOptions&lt;/code&gt;</ph>zawiera <ph id="ph2">&lt;xref:System.Globalization.CompareOptions&gt;</ph>, <ph id="ph3">&lt;xref:System.Globalization.CompareOptions&gt;</ph>, lub <ph id="ph4">&lt;xref:System.Globalization.CompareOptions&gt;</ph> flagi.</target>       </trans-unit>
        <trans-unit id="236" translate="yes" xml:space="preserve">
          <source>Emulates input of a phrase to the speech recognizer, using text in place of audio for synchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the phrase and the loaded speech recognition grammars.</source>
          <target state="translated">Emuluje wprowadzania frazę do rozpoznawania mowy, przy użyciu tekstu zamiast audio rozpoznawania mowy synchroniczne i określa sposób obsługi przez aparat rozpoznawania Unicode porównanie frazę gramatyki rozpoznawania mowy załadowany.</target>       </trans-unit>
        <trans-unit id="237" translate="yes" xml:space="preserve" extradata="MT">
          <source>The speech recognizer raises the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; events as if the recognition operation is not emulated.</source>
          <target state="translated">Generuje aparatu rozpoznawania mowy &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;, i &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;zdarzeń tak, jakby operacji rozpoznawania nie jest emulowana.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</target>       </trans-unit>
        <trans-unit id="238" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer uses <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">Aparat rozpoznawania używa <ph id="ph1">`compareOptions`</ph> po stosuje reguły gramatyki do frazy wejściowych.</target>       </trans-unit>
        <trans-unit id="239" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the &lt;xref:System.Globalization.CompareOptions&gt; or &lt;xref:System.Globalization.CompareOptions&gt; value is present.</source>
          <target state="translated">Aparaty rozpoznawania, które są dostarczane z Vista i Windows 7 Ignoruj wielkość liter, jeśli &lt;xref:System.Globalization.CompareOptions&gt;lub &lt;xref:System.Globalization.CompareOptions&gt;ma wartość.&lt;/xref:System.Globalization.CompareOptions&gt; &lt;/xref:System.Globalization.CompareOptions&gt;</target>       </trans-unit>
        <trans-unit id="240" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer always ignores the character width and never ignores the Kana type.</source>
          <target state="translated">Aparat rozpoznawania zawsze ignoruje szerokość znaku i nigdy nie ignoruje typu znaki Kana.</target>       </trans-unit>
        <trans-unit id="241" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer also ignores new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Aparat rozpoznawania również ignoruje nowych wierszy oraz dodatkowy biały znak i traktuje jako dane wejściowe literał znaków interpunkcyjnych.</target>       </trans-unit>
        <trans-unit id="242" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about character width and Kana type, see the &lt;xref:System.Globalization.CompareOptions&gt; enumeration.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat szerokość znaków i wpisz znaki Kana, zobacz &lt;xref:System.Globalization.CompareOptions&gt;wyliczenie.&lt;/xref:System.Globalization.CompareOptions&gt;</target>       </trans-unit>
        <trans-unit id="243" translate="yes" xml:space="preserve">
          <source>The input phrase for the recognition operation.</source>
          <target state="translated">Wyrażenie wejściowych dla operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="244" translate="yes" xml:space="preserve">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">Bitowe połączenie wartości wyliczenia, które opisują typ porównania do użycia dla operacji rozpoznawania emulowanej.</target>       </trans-unit>
        <trans-unit id="245" translate="yes" xml:space="preserve">
          <source>The result for the recognition operation, or <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> if the operation is not successful or the recognizer is not enabled.</source>
          <target state="translated">Wynik operacji rozpoznawania lub <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> Jeśli operacja nie powiedzie się lub nie włączono aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="246" translate="yes" xml:space="preserve">
          <source>The recognizer has no speech recognition grammars loaded.</source>
          <target state="translated">Aparat rozpoznawania ma nie gramatyki rozpoznawania mowy załadowane.</target>       </trans-unit>
        <trans-unit id="247" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;inputText&lt;/code&gt;</ph> is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;inputText&lt;/code&gt;</ph>is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="248" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;inputText&lt;/code&gt;</ph> is the empty string ("").</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;inputText&lt;/code&gt;</ph>jest pustym ciągiem ("").</target>       </trans-unit>
        <trans-unit id="249" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;compareOptions&lt;/code&gt;</ph> contains the <ph id="ph2">&lt;xref:System.Globalization.CompareOptions&gt;</ph>, <ph id="ph3">&lt;xref:System.Globalization.CompareOptions&gt;</ph>, or <ph id="ph4">&lt;xref:System.Globalization.CompareOptions&gt;</ph> flag.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;compareOptions&lt;/code&gt;</ph>zawiera <ph id="ph2">&lt;xref:System.Globalization.CompareOptions&gt;</ph>, <ph id="ph3">&lt;xref:System.Globalization.CompareOptions&gt;</ph>, lub <ph id="ph4">&lt;xref:System.Globalization.CompareOptions&gt;</ph> flagi.</target>       </trans-unit>
        <trans-unit id="250" translate="yes" xml:space="preserve">
          <source>Emulates input of a phrase to the speech recognizer, using text in place of audio for asynchronous speech recognition.</source>
          <target state="translated">Emuluje wprowadzania frazę do rozpoznawania mowy, przy użyciu tekstu zamiast audio rozpoznawania mowy asynchronicznego.</target>       </trans-unit>
        <trans-unit id="251" translate="yes" xml:space="preserve" extradata="MT">
          <source>The speech recognizer raises the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; events as if the recognition operation is not emulated.</source>
          <target state="translated">Generuje aparatu rozpoznawania mowy &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;, i &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;zdarzeń tak, jakby operacji rozpoznawania nie jest emulowana.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</target>       </trans-unit>
        <trans-unit id="252" translate="yes" xml:space="preserve" extradata="MT">
          <source>When the recognizer completes the asynchronous recognition operation, it raises the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt; event.</source>
          <target state="translated">Po ukończeniu operacji asynchronicznej rozpoznawania aparat rozpoznawania zgłasza &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;zdarzeń.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</target>       </trans-unit>
        <trans-unit id="253" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers that ship with Vista and Windows 7 ignore case and character width when applying grammar rules to the input phrase.</source>
          <target state="translated">Aparaty rozpoznawania, które są dostarczane z Vista i Windows 7 Ignoruj wielkość liter i znaków szerokości, stosując reguły gramatyki do wprowadzania frazy.</target>       </trans-unit>
        <trans-unit id="254" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about this type of comparison, see the &lt;xref:System.Globalization.CompareOptions&gt; enumeration values &lt;xref:System.Globalization.CompareOptions&gt; and &lt;xref:System.Globalization.CompareOptions&gt;.</source>
          <target state="translated">Aby uzyskać więcej informacji o tym typie porównanie zobacz &lt;xref:System.Globalization.CompareOptions&gt;wartości wyliczenia &lt;xref:System.Globalization.CompareOptions&gt;i &lt;xref:System.Globalization.CompareOptions&gt;.&lt;/xref:System.Globalization.CompareOptions&gt; &lt;/xref:System.Globalization.CompareOptions&gt; &lt;/xref:System.Globalization.CompareOptions&gt;</target>       </trans-unit>
        <trans-unit id="255" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</source>
          <target state="translated">Aparatów rozpoznawania także zignorować nowych wierszy oraz dodatkowy biały znak i Traktuj znaki interpunkcyjne jako dane wejściowe literału.</target>       </trans-unit>
        <trans-unit id="256" translate="yes" xml:space="preserve">
          <source>The input for the recognition operation.</source>
          <target state="translated">Dane wejściowe dla operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="257" translate="yes" xml:space="preserve">
          <source>The recognizer has no speech recognition grammars loaded, or the recognizer has an asynchronous recognition operation that is not yet complete.</source>
          <target state="translated">Aparat rozpoznawania ma nie gramatyki rozpoznawania mowy załadowany lub aparat rozpoznawania ma operację asynchroniczną rozpoznawania, która nie jest jeszcze zakończona.</target>       </trans-unit>
        <trans-unit id="258" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;inputText&lt;/code&gt;</ph> is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;inputText&lt;/code&gt;</ph>is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="259" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;inputText&lt;/code&gt;</ph> is the empty string ("").</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;inputText&lt;/code&gt;</ph>jest pustym ciągiem ("").</target>       </trans-unit>
        <trans-unit id="260" translate="yes" xml:space="preserve">
          <source>Emulates input of specific words to the speech recognizer, using an array of <bpt id="p1">&lt;xref href="System.Speech.Recognition.RecognizedWordUnit"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> objects in place of audio for asynchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the words and the loaded speech recognition grammars.</source>
          <target state="translated">Emuluje wprowadzania słów do rozpoznawania mowy, użycie tablicy <bpt id="p1">&lt;xref href="System.Speech.Recognition.RecognizedWordUnit"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> obiektów zamiast audio rozpoznawania mowy asynchroniczne i określa sposób obsługi przez aparat rozpoznawania porównanie Unicode słów i gramatyki rozpoznawania mowy załadowany.</target>       </trans-unit>
        <trans-unit id="261" translate="yes" xml:space="preserve" extradata="MT">
          <source>The speech recognizer raises the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; events as if the recognition operation is not emulated.</source>
          <target state="translated">Generuje aparatu rozpoznawania mowy &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;, i &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;zdarzeń tak, jakby operacji rozpoznawania nie jest emulowana.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</target>       </trans-unit>
        <trans-unit id="262" translate="yes" xml:space="preserve" extradata="MT">
          <source>When the recognizer completes the asynchronous recognition operation, it raises the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt; event.</source>
          <target state="translated">Po ukończeniu operacji asynchronicznej rozpoznawania aparat rozpoznawania zgłasza &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;zdarzeń.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</target>       </trans-unit>
        <trans-unit id="263" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer uses <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">Aparat rozpoznawania używa <ph id="ph1">`compareOptions`</ph> po stosuje reguły gramatyki do frazy wejściowych.</target>       </trans-unit>
        <trans-unit id="264" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the &lt;xref:System.Globalization.CompareOptions&gt; or &lt;xref:System.Globalization.CompareOptions&gt; value is present.</source>
          <target state="translated">Aparaty rozpoznawania, które są dostarczane z Vista i Windows 7 Ignoruj wielkość liter, jeśli &lt;xref:System.Globalization.CompareOptions&gt;lub &lt;xref:System.Globalization.CompareOptions&gt;ma wartość.&lt;/xref:System.Globalization.CompareOptions&gt; &lt;/xref:System.Globalization.CompareOptions&gt;</target>       </trans-unit>
        <trans-unit id="265" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
          <target state="translated">Aparatów rozpoznawania zawsze Ignoruj szerokość znaku i nigdy nie Ignoruj typu znaki Kana.</target>       </trans-unit>
        <trans-unit id="266" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</source>
          <target state="translated">Aparatów rozpoznawania także zignorować nowych wierszy oraz dodatkowy biały znak i Traktuj znaki interpunkcyjne jako dane wejściowe literału.</target>       </trans-unit>
        <trans-unit id="267" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about character width and Kana type, see the &lt;xref:System.Globalization.CompareOptions&gt; enumeration.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat szerokość znaków i wpisz znaki Kana, zobacz &lt;xref:System.Globalization.CompareOptions&gt;wyliczenie.&lt;/xref:System.Globalization.CompareOptions&gt;</target>       </trans-unit>
        <trans-unit id="268" translate="yes" xml:space="preserve">
          <source>An array of word units that contains the input for the recognition operation.</source>
          <target state="translated">Tablica jednostki słowa zawierającego dane wejściowe dla operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="269" translate="yes" xml:space="preserve">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">Bitowe połączenie wartości wyliczenia, które opisują typ porównania do użycia dla operacji rozpoznawania emulowanej.</target>       </trans-unit>
        <trans-unit id="270" translate="yes" xml:space="preserve">
          <source>The recognizer has no speech recognition grammars loaded, or the recognizer has an asynchronous recognition operation that is not yet complete.</source>
          <target state="translated">Aparat rozpoznawania ma nie gramatyki rozpoznawania mowy załadowany lub aparat rozpoznawania ma operację asynchroniczną rozpoznawania, która nie jest jeszcze zakończona.</target>       </trans-unit>
        <trans-unit id="271" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;wordUnits&lt;/code&gt;</ph> is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;wordUnits&lt;/code&gt;</ph>is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="272" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;wordUnits&lt;/code&gt;</ph> contains one or more <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> elements.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;wordUnits&lt;/code&gt;</ph>zawiera co najmniej jeden <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> elementów.</target>       </trans-unit>
        <trans-unit id="273" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;compareOptions&lt;/code&gt;</ph> contains the <ph id="ph2">&lt;xref:System.Globalization.CompareOptions&gt;</ph>, <ph id="ph3">&lt;xref:System.Globalization.CompareOptions&gt;</ph>, or <ph id="ph4">&lt;xref:System.Globalization.CompareOptions&gt;</ph> flag.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;compareOptions&lt;/code&gt;</ph>zawiera <ph id="ph2">&lt;xref:System.Globalization.CompareOptions&gt;</ph>, <ph id="ph3">&lt;xref:System.Globalization.CompareOptions&gt;</ph>, lub <ph id="ph4">&lt;xref:System.Globalization.CompareOptions&gt;</ph> flagi.</target>       </trans-unit>
        <trans-unit id="274" translate="yes" xml:space="preserve">
          <source>Emulates input of a phrase to the speech recognizer, using text in place of audio for asynchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the phrase and the loaded speech recognition grammars.</source>
          <target state="translated">Emuluje wprowadzania frazę do rozpoznawania mowy, przy użyciu tekstu zamiast audio rozpoznawania mowy asynchroniczne i określa sposób obsługi przez aparat rozpoznawania Unicode porównanie frazę gramatyki rozpoznawania mowy załadowany.</target>       </trans-unit>
        <trans-unit id="275" translate="yes" xml:space="preserve" extradata="MT">
          <source>The speech recognizer raises the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; events as if the recognition operation is not emulated.</source>
          <target state="translated">Generuje aparatu rozpoznawania mowy &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;, i &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;zdarzeń tak, jakby operacji rozpoznawania nie jest emulowana.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</target>       </trans-unit>
        <trans-unit id="276" translate="yes" xml:space="preserve" extradata="MT">
          <source>When the recognizer completes the asynchronous recognition operation, it raises the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt; event.</source>
          <target state="translated">Po ukończeniu operacji asynchronicznej rozpoznawania aparat rozpoznawania zgłasza &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;zdarzeń.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;</target>       </trans-unit>
        <trans-unit id="277" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer uses <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">Aparat rozpoznawania używa <ph id="ph1">`compareOptions`</ph> po stosuje reguły gramatyki do frazy wejściowych.</target>       </trans-unit>
        <trans-unit id="278" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the &lt;xref:System.Globalization.CompareOptions&gt; or &lt;xref:System.Globalization.CompareOptions&gt; value is present.</source>
          <target state="translated">Aparaty rozpoznawania, które są dostarczane z Vista i Windows 7 Ignoruj wielkość liter, jeśli &lt;xref:System.Globalization.CompareOptions&gt;lub &lt;xref:System.Globalization.CompareOptions&gt;ma wartość.&lt;/xref:System.Globalization.CompareOptions&gt; &lt;/xref:System.Globalization.CompareOptions&gt;</target>       </trans-unit>
        <trans-unit id="279" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
          <target state="translated">Aparatów rozpoznawania zawsze Ignoruj szerokość znaku i nigdy nie Ignoruj typu znaki Kana.</target>       </trans-unit>
        <trans-unit id="280" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</source>
          <target state="translated">Aparatów rozpoznawania także zignorować nowych wierszy oraz dodatkowy biały znak i Traktuj znaki interpunkcyjne jako dane wejściowe literału.</target>       </trans-unit>
        <trans-unit id="281" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about character width and Kana type, see the &lt;xref:System.Globalization.CompareOptions&gt; enumeration.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat szerokość znaków i wpisz znaki Kana, zobacz &lt;xref:System.Globalization.CompareOptions&gt;wyliczenie.&lt;/xref:System.Globalization.CompareOptions&gt;</target>       </trans-unit>
        <trans-unit id="282" translate="yes" xml:space="preserve">
          <source>The input phrase for the recognition operation.</source>
          <target state="translated">Wyrażenie wejściowych dla operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="283" translate="yes" xml:space="preserve">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">Bitowe połączenie wartości wyliczenia, które opisują typ porównania do użycia dla operacji rozpoznawania emulowanej.</target>       </trans-unit>
        <trans-unit id="284" translate="yes" xml:space="preserve">
          <source>The recognizer has no speech recognition grammars loaded, or the recognizer has an asynchronous recognition operation that is not yet complete.</source>
          <target state="translated">Aparat rozpoznawania ma nie gramatyki rozpoznawania mowy załadowany lub aparat rozpoznawania ma operację asynchroniczną rozpoznawania, która nie jest jeszcze zakończona.</target>       </trans-unit>
        <trans-unit id="285" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;inputText&lt;/code&gt;</ph> is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;inputText&lt;/code&gt;</ph>is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="286" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;inputText&lt;/code&gt;</ph> is the empty string ("").</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;inputText&lt;/code&gt;</ph>jest pustym ciągiem ("").</target>       </trans-unit>
        <trans-unit id="287" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;compareOptions&lt;/code&gt;</ph> contains the <ph id="ph2">&lt;xref:System.Globalization.CompareOptions&gt;</ph>, <ph id="ph3">&lt;xref:System.Globalization.CompareOptions&gt;</ph>, or <ph id="ph4">&lt;xref:System.Globalization.CompareOptions&gt;</ph> flag.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;compareOptions&lt;/code&gt;</ph>zawiera <ph id="ph2">&lt;xref:System.Globalization.CompareOptions&gt;</ph>, <ph id="ph3">&lt;xref:System.Globalization.CompareOptions&gt;</ph>, lub <ph id="ph4">&lt;xref:System.Globalization.CompareOptions&gt;</ph> flagi.</target>       </trans-unit>
        <trans-unit id="288" translate="yes" xml:space="preserve">
          <source>Raised when the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> finalizes an asynchronous recognition operation of emulated input.</source>
          <target state="translated">Wywoływane, gdy <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> Kończenie znajdujących się w operacji asynchronicznych rozpoznawania emulowanej danych wejściowych.</target>       </trans-unit>
        <trans-unit id="289" translate="yes" xml:space="preserve" extradata="MT">
          <source>Each &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt; method begins an asynchronous recognition operation.</source>
          <target state="translated">Każdy &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;Metoda rozpoczyna operację asynchroniczną rozpoznawania.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</target>       </trans-unit>
        <trans-unit id="290" translate="yes" xml:space="preserve" extradata="MT">
          <source>The &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; raises the EmulateRecognizeCompleted event when it finalizes the asynchronous operation.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;Wywołuje zdarzenie EmulateRecognizeCompleted podczas jego Kończenie znajdujących się w operacji asynchronicznej.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="291" translate="yes" xml:space="preserve" extradata="MT">
          <source>The &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt; operation can raise the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; events.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;Może wiązać się z operacji &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;, i &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;zdarzeń.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;</target>       </trans-unit>
        <trans-unit id="292" translate="yes" xml:space="preserve" extradata="MT">
          <source>The EmulateRecognizeCompleted event is the last such event that the recognizer raises for a given operation.</source>
          <target state="translated">Zdarzenie EmulateRecognizeCompleted jest ostatni tych zdarzeń, że aparat rozpoznawania zgłasza dla danej operacji.</target>       </trans-unit>
        <trans-unit id="293" translate="yes" xml:space="preserve" extradata="MT">
          <source>If emulated recognition was successful, you can access the recognition result using the either of the following:      -   The &lt;xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A&gt; property in the &lt;xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt; object in the handler for the EmulateRecognizeCompleted event.</source>
          <target state="translated">Rozpoznawanie emulowanej zakończyło się pomyślnie, można przejść do wyników rozpoznawania przy użyciu jednej z następujących czynności: - &lt;xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A&gt;Właściwości w &lt;xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt;obiekt obsługi dla zdarzenia EmulateRecognizeCompleted.&lt;/xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt; &lt;/xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A&gt;</target>       </trans-unit>
        <trans-unit id="294" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   &lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt; property in the &lt;xref:System.Speech.Recognition.SpeechRecognizedEventArgs&gt; object in the handler for the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; event.</source>
          <target state="translated">- &lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;Właściwości w &lt;xref:System.Speech.Recognition.SpeechRecognizedEventArgs&gt;obiekt obsługi dla &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;zdarzeń.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognizedEventArgs&gt; &lt;/xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</target>       </trans-unit>
        <trans-unit id="295" translate="yes" xml:space="preserve" extradata="MT">
          <source>If emulated recognition was not successful, the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; event is not raised and the &lt;xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A&gt; will be null.</source>
          <target state="translated">Jeśli emulowanej rozpoznawania zakończyła się niepowodzeniem, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;nie zdarzenia i &lt;xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A&gt;będzie mieć wartość null.&lt;/xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</target>       </trans-unit>
        <trans-unit id="296" translate="yes" xml:space="preserve" extradata="MT">
          <source>&lt;xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt; derives from &lt;xref:System.ComponentModel.AsyncCompletedEventArgs&gt;.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt;pochodną &lt;xref:System.ComponentModel.AsyncCompletedEventArgs&gt;.&lt;/xref:System.ComponentModel.AsyncCompletedEventArgs&gt;&lt;/xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt;</target>       </trans-unit>
        <trans-unit id="297" translate="yes" xml:space="preserve" extradata="MT">
          <source>&lt;xref:System.Speech.Recognition.SpeechRecognizedEventArgs&gt; derives from &lt;xref:System.Speech.Recognition.RecognitionEventArgs&gt;.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.SpeechRecognizedEventArgs&gt;pochodną &lt;xref:System.Speech.Recognition.RecognitionEventArgs&gt;.&lt;/xref:System.Speech.Recognition.RecognitionEventArgs&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognizedEventArgs&gt;</target>       </trans-unit>
        <trans-unit id="298" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create an EmulateRecognizeCompleted delegate, you identify the method that will handle the event.</source>
          <target state="translated">Podczas tworzenia obiektu delegowanego EmulateRecognizeCompleted, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="299" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="300" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływana, gdy wystąpi zdarzenie, o ile nie usuniesz delegata.</target>       </trans-unit>
        <trans-unit id="301" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="302" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">Do dodania.</target>       </trans-unit>
        <trans-unit id="303" translate="yes" xml:space="preserve">
          <source>Gets or sets the interval of silence that the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> will accept at the end of unambiguous input before finalizing a recognition operation.</source>
          <target state="translated">Pobiera lub ustawia interwał wyciszenia, który <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> będzie akceptować na końcu danych wejściowych jednoznaczne przed zakończeniem operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="304" translate="yes" xml:space="preserve" extradata="MT">
          <source>The speech recognizer uses this timeout interval when the recognition input is unambiguous.</source>
          <target state="translated">Aparat rozpoznawania mowy używa ten limit czasu podczas rozpoznawania danych wejściowych jest jednoznaczny.</target>       </trans-unit>
        <trans-unit id="305" translate="yes" xml:space="preserve" extradata="MT">
          <source>For example, for a speech recognition grammar that supports recognition of either "new game please" or "new game", "new game please" is an unambiguous input, and "new game" is an ambiguous input.</source>
          <target state="translated">Na przykład dla gramatyki rozpoznawania mowy, która obsługuje rozpoznawanie albo "nowe gier, skontaktuj" lub "nowej gry", "nowe gier, skontaktuj" jest wejściem jednoznaczne i "nowej gry" jest niejednoznaczny danych wejściowych.</target>       </trans-unit>
        <trans-unit id="306" translate="yes" xml:space="preserve" extradata="MT">
          <source>This property determines how long the speech recognition engine will wait for additional input before finalizing a recognition operation.</source>
          <target state="translated">Ta właściwość określa, jak długo aparat rozpoznawania mowy będzie czekać na dodatkowe dane wejściowe przed zakończeniem operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="307" translate="yes" xml:space="preserve" extradata="MT">
          <source>The timeout interval can be from 0 seconds to 10 seconds, inclusive.</source>
          <target state="translated">Interwał limitu czasu może być z zakresu od 0 do 10 sekund włącznie.</target>       </trans-unit>
        <trans-unit id="308" translate="yes" xml:space="preserve" extradata="MT">
          <source>The default is 150 milliseconds.</source>
          <target state="translated">Wartość domyślna wynosi 150 milisekund.</target>       </trans-unit>
        <trans-unit id="309" translate="yes" xml:space="preserve" extradata="MT">
          <source>To set the timeout interval for ambiguous input, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt; property.</source>
          <target state="translated">Aby ustawić interwał limitu czasu dla danych wejściowych niejednoznaczny, należy użyć &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;Właściwości.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</target>       </trans-unit>
        <trans-unit id="310" translate="yes" xml:space="preserve">
          <source>The duration of the interval of silence.</source>
          <target state="translated">Czas trwania interwału wyciszenia.</target>       </trans-unit>
        <trans-unit id="311" translate="yes" xml:space="preserve">
          <source>This property is set to less than 0 seconds or greater than 10 seconds.</source>
          <target state="translated">Ta właściwość ma wartość mniejszą niż 0 sekund lub większej niż 10 sekund.</target>       </trans-unit>
        <trans-unit id="312" translate="yes" xml:space="preserve">
          <source>Gets or sets the interval of silence that the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> will accept at the end of ambiguous input before finalizing a recognition operation.</source>
          <target state="translated">Pobiera lub ustawia interwał wyciszenia, który <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> będzie akceptować na końcu danych wejściowych niejednoznaczne przed zakończeniem operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="313" translate="yes" xml:space="preserve" extradata="MT">
          <source>The speech recognizer uses this timeout interval when the recognition input is ambiguous.</source>
          <target state="translated">Aparat rozpoznawania mowy używa ten limit czasu podczas rozpoznawania danych wejściowych jest niejednoznaczna.</target>       </trans-unit>
        <trans-unit id="314" translate="yes" xml:space="preserve" extradata="MT">
          <source>For example, for a speech recognition grammar that supports recognition of either "new game please" or "new game", "new game please" is an unambiguous input, and "new game" is an ambiguous input.</source>
          <target state="translated">Na przykład dla gramatyki rozpoznawania mowy, która obsługuje rozpoznawanie albo "nowe gier, skontaktuj" lub "nowej gry", "nowe gier, skontaktuj" jest wejściem jednoznaczne i "nowej gry" jest niejednoznaczny danych wejściowych.</target>       </trans-unit>
        <trans-unit id="315" translate="yes" xml:space="preserve" extradata="MT">
          <source>This property determines how long the speech recognition engine will wait for additional input before finalizing a recognition operation.</source>
          <target state="translated">Ta właściwość określa, jak długo aparat rozpoznawania mowy będzie czekać na dodatkowe dane wejściowe przed zakończeniem operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="316" translate="yes" xml:space="preserve" extradata="MT">
          <source>The timeout interval can be from 0 seconds to 10 seconds, inclusive.</source>
          <target state="translated">Interwał limitu czasu może być z zakresu od 0 do 10 sekund włącznie.</target>       </trans-unit>
        <trans-unit id="317" translate="yes" xml:space="preserve" extradata="MT">
          <source>The default is 500 milliseconds.</source>
          <target state="translated">Wartość domyślna to 500 milisekund.</target>       </trans-unit>
        <trans-unit id="318" translate="yes" xml:space="preserve" extradata="MT">
          <source>To set the timeout interval for unambiguous input, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt; property.</source>
          <target state="translated">Aby ustawić interwał limitu czasu dla danych wejściowych jednoznaczne, użyj &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;Właściwości.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</target>       </trans-unit>
        <trans-unit id="319" translate="yes" xml:space="preserve">
          <source>The duration of the interval of silence.</source>
          <target state="translated">Czas trwania interwału wyciszenia.</target>       </trans-unit>
        <trans-unit id="320" translate="yes" xml:space="preserve">
          <source>This property is set to less than 0 seconds or greater than 10 seconds.</source>
          <target state="translated">Ta właściwość ma wartość mniejszą niż 0 sekund lub większej niż 10 sekund.</target>       </trans-unit>
        <trans-unit id="321" translate="yes" xml:space="preserve">
          <source>Gets a collection of the <bpt id="p1">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> objects that are loaded in this <bpt id="p2">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p2">&lt;/xref&gt;</ept> instance.</source>
          <target state="translated">Pobiera kolekcję <bpt id="p1">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> obiektów, które są ładowane w tym <bpt id="p2">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p2">&lt;/xref&gt;</ept> wystąpienia.</target>       </trans-unit>
        <trans-unit id="322" translate="yes" xml:space="preserve">
          <source>The collection of <bpt id="p1">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> objects.</source>
          <target state="translated">Kolekcja <bpt id="p1">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> obiektów.</target>       </trans-unit>
        <trans-unit id="323" translate="yes" xml:space="preserve">
          <source>Gets or sets the time interval during which a <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> accepts input containing only silence before finalizing recognition.</source>
          <target state="translated">Pobiera lub ustawia przedział czasu, w którym <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> akceptuje wejściowych zawierających tylko wyciszenia przed zakończeniem rozpoznawania.</target>       </trans-unit>
        <trans-unit id="324" translate="yes" xml:space="preserve" extradata="MT">
          <source>Each speech recognizer has an algorithm to distinguish between silence and speech.</source>
          <target state="translated">Każdy aparat rozpoznawania mowy zawiera algorytm odróżnić wyciszenia mowy.</target>       </trans-unit>
        <trans-unit id="325" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the recognizer input is silence during the initial silence timeout period, then the recognizer finalizes that recognition operation.</source>
          <target state="translated">Jeśli dane wejściowe aparatu rozpoznawania jest wyciszenia podczas początkowej wyciszenia limitu czasu aparatu rozpoznawania Kończenie znajdujących się w tej operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="326" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   For asynchronous recognition operations and emulation, the recognizer raises the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt; event, where the &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A?displayProperty=fullName&gt; property is <ph id="ph1">`true`</ph>, and the &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=fullName&gt; property is <ph id="ph2">`null`</ph>.</source>
          <target state="translated">— Dla operacji rozpoznawania asynchroniczne i emulacji zgłasza aparat rozpoznawania &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;zdarzeń, gdy &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A?displayProperty=fullName&gt;właściwość jest <ph id="ph1">`true`</ph>i &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=fullName&gt;jest właściwość <ph id="ph2">`null`</ph>.&lt;/xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=fullName&gt; &lt;/xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A?displayProperty=fullName&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</target>       </trans-unit>
        <trans-unit id="327" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   For synchronous recognition operations and emulation, the recognizer returns <ph id="ph1">`null`</ph>, instead of a valid &lt;xref:System.Speech.Recognition.RecognitionResult&gt;.</source>
          <target state="translated">— Dla operacji rozpoznawania synchroniczne i emulacji zwraca aparat rozpoznawania <ph id="ph1">`null`</ph>, zamiast prawidłową &lt;xref:System.Speech.Recognition.RecognitionResult&gt;.&lt;/xref:System.Speech.Recognition.RecognitionResult&gt;</target>       </trans-unit>
        <trans-unit id="328" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the initial silence timeout interval is set to 0, the recognizer does not perform an initial silence timeout check.</source>
          <target state="translated">Jeśli interwał limitu czasu początkowej wyciszenia jest ustawiony na 0, aparat rozpoznawania nie sprawdzić początkowej wyciszenia limitu czasu.</target>       </trans-unit>
        <trans-unit id="329" translate="yes" xml:space="preserve" extradata="MT">
          <source>The timeout interval can be any non-negative value.</source>
          <target state="translated">Interwał limitu czasu może być wartością nieujemną.</target>       </trans-unit>
        <trans-unit id="330" translate="yes" xml:space="preserve" extradata="MT">
          <source>The default is 0 seconds.</source>
          <target state="translated">Wartość domyślna to 0 sekund.</target>       </trans-unit>
        <trans-unit id="331" translate="yes" xml:space="preserve">
          <source>The duration of the interval of silence.</source>
          <target state="translated">Czas trwania interwału wyciszenia.</target>       </trans-unit>
        <trans-unit id="332" translate="yes" xml:space="preserve">
          <source>This property is set to less than 0 seconds.</source>
          <target state="translated">Ta właściwość ma ustawioną mniejszy niż 0 sekund.</target>       </trans-unit>
        <trans-unit id="333" translate="yes" xml:space="preserve">
          <source>Returns information for all of the installed speech recognizers on the current system.</source>
          <target state="translated">Zwraca informacje dla wszystkich aparatów rozpoznawania mowy zainstalowanych w systemie.</target>       </trans-unit>
        <trans-unit id="334" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get information about the current recognizer, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A&gt; property.</source>
          <target state="translated">Aby uzyskać informacje dotyczące bieżącego aparatu rozpoznawania, użyj &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A&gt;Właściwości.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A&gt;</target>       </trans-unit>
        <trans-unit id="335" translate="yes" xml:space="preserve">
          <source>A read-only collection of the <bpt id="p1">&lt;xref href="System.Speech.Recognition.RecognizerInfo"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> objects that describe the installed recognizers.</source>
          <target state="translated">Kolekcja tylko do odczytu <bpt id="p1">&lt;xref href="System.Speech.Recognition.RecognizerInfo"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> obiektów, które opisują zainstalowanych aparatów rozpoznawania.</target>       </trans-unit>
        <trans-unit id="336" translate="yes" xml:space="preserve">
          <source>Synchronously loads a <bpt id="p1">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> object.</source>
          <target state="translated">Ładuje synchronicznie <bpt id="p1">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> obiektu.</target>       </trans-unit>
        <trans-unit id="337" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer throws an exception if the &lt;xref:System.Speech.Recognition.Grammar&gt; object is already loaded, is being asynchronously loaded, or has failed to load into any recognizer.</source>
          <target state="translated">Aparat rozpoznawania zgłasza wyjątek, jeśli &lt;xref:System.Speech.Recognition.Grammar&gt;obiektu jest już załadowany, jest ładowany asynchronicznie lub nie można załadować do dowolnego aparatu rozpoznawania.&lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="338" translate="yes" xml:space="preserve" extradata="MT">
          <source>You cannot load the same &lt;xref:System.Speech.Recognition.Grammar&gt; object into multiple instances of &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;.</source>
          <target state="translated">Nie można załadować samego &lt;xref:System.Speech.Recognition.Grammar&gt;obiektu do wielu wystąpień &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; &lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="339" translate="yes" xml:space="preserve" extradata="MT">
          <source>Instead, create a new &lt;xref:System.Speech.Recognition.Grammar&gt; object for each &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; instance.</source>
          <target state="translated">Zamiast tego utwórz nową &lt;xref:System.Speech.Recognition.Grammar&gt;obiekt dla każdego &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;wystąpienia.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; &lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="340" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the recognizer is running, applications must use &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt; to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
          <target state="translated">Jeśli aparat rozpoznawania jest uruchomiona, aplikacje muszą używać &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;wstrzymania aparat rozpoznawania mowy przed ładowania, zwalnianie, włączanie lub wyłączanie gramatyki.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</target>       </trans-unit>
        <trans-unit id="341" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you load a grammar, it is enabled by default.</source>
          <target state="translated">Podczas ładowania gramatyki jest włączona domyślnie.</target>       </trans-unit>
        <trans-unit id="342" translate="yes" xml:space="preserve" extradata="MT">
          <source>To disable a loaded grammar, use the &lt;xref:System.Speech.Recognition.Grammar.Enabled%2A&gt; property.</source>
          <target state="translated">Aby wyłączyć załadować gramatyki, należy użyć &lt;xref:System.Speech.Recognition.Grammar.Enabled%2A&gt;Właściwości.&lt;/xref:System.Speech.Recognition.Grammar.Enabled%2A&gt;</target>       </trans-unit>
        <trans-unit id="343" translate="yes" xml:space="preserve" extradata="MT">
          <source>To load a &lt;xref:System.Speech.Recognition.Grammar&gt; object asynchronously, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt; method.</source>
          <target state="translated">Aby załadować &lt;xref:System.Speech.Recognition.Grammar&gt;asynchronicznie obiektów, użyj &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt; &lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="344" translate="yes" xml:space="preserve">
          <source>The grammar object to load.</source>
          <target state="translated">Obiekt gramatyki do załadowania.</target>       </trans-unit>
        <trans-unit id="345" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;Grammar&lt;/code&gt;</ph> is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;Grammar&lt;/code&gt;</ph>is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="346" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;Grammar&lt;/code&gt;</ph> is not in a valid state.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;Grammar&lt;/code&gt;</ph>nie jest w prawidłowym stanie.</target>       </trans-unit>
        <trans-unit id="347" translate="yes" xml:space="preserve">
          <source>Asynchronously loads a speech recognition grammar.</source>
          <target state="translated">Asynchronicznie ładuje gramatyki rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="348" translate="yes" xml:space="preserve" extradata="MT">
          <source>When the recognizer completes loading a &lt;xref:System.Speech.Recognition.Grammar&gt; object, it raises a &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted&gt; event.</source>
          <target state="translated">Gdy aparat rozpoznawania zakończeniu ładowania &lt;xref:System.Speech.Recognition.Grammar&gt;obiekt zgłasza &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted&gt;zdarzeń.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted&gt; &lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="349" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer throws an exception if the &lt;xref:System.Speech.Recognition.Grammar&gt; object is already loaded, is being asynchronously loaded, or has failed to load into any recognizer.</source>
          <target state="translated">Aparat rozpoznawania zgłasza wyjątek, jeśli &lt;xref:System.Speech.Recognition.Grammar&gt;obiektu jest już załadowany, jest ładowany asynchronicznie lub nie można załadować do dowolnego aparatu rozpoznawania.&lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="350" translate="yes" xml:space="preserve" extradata="MT">
          <source>You cannot load the same &lt;xref:System.Speech.Recognition.Grammar&gt; object into multiple instances of &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;.</source>
          <target state="translated">Nie można załadować samego &lt;xref:System.Speech.Recognition.Grammar&gt;obiektu do wielu wystąpień &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; &lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="351" translate="yes" xml:space="preserve" extradata="MT">
          <source>Instead, create a new &lt;xref:System.Speech.Recognition.Grammar&gt; object for each &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; instance.</source>
          <target state="translated">Zamiast tego utwórz nową &lt;xref:System.Speech.Recognition.Grammar&gt;obiekt dla każdego &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;wystąpienia.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; &lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="352" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the recognizer is running, applications must use &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt; to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
          <target state="translated">Jeśli aparat rozpoznawania jest uruchomiona, aplikacje muszą używać &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;wstrzymania aparat rozpoznawania mowy przed ładowania, zwalnianie, włączanie lub wyłączanie gramatyki.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</target>       </trans-unit>
        <trans-unit id="353" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you load a grammar, it is enabled by default.</source>
          <target state="translated">Podczas ładowania gramatyki jest włączona domyślnie.</target>       </trans-unit>
        <trans-unit id="354" translate="yes" xml:space="preserve" extradata="MT">
          <source>To disable a loaded grammar, use the &lt;xref:System.Speech.Recognition.Grammar.Enabled%2A&gt; property.</source>
          <target state="translated">Aby wyłączyć załadować gramatyki, należy użyć &lt;xref:System.Speech.Recognition.Grammar.Enabled%2A&gt;Właściwości.&lt;/xref:System.Speech.Recognition.Grammar.Enabled%2A&gt;</target>       </trans-unit>
        <trans-unit id="355" translate="yes" xml:space="preserve" extradata="MT">
          <source>To load a speech recognition grammar synchronously, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt; method.</source>
          <target state="translated">Aby załadować gramatyki rozpoznawania mowy synchronicznie, należy użyć &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A&gt;</target>       </trans-unit>
        <trans-unit id="356" translate="yes" xml:space="preserve">
          <source>The speech recognition grammar to load.</source>
          <target state="translated">Rozpoznawanie mowy gramatyki do załadowania.</target>       </trans-unit>
        <trans-unit id="357" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;Grammar&lt;/code&gt;</ph> is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;Grammar&lt;/code&gt;</ph>is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="358" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;Grammar&lt;/code&gt;</ph> is not in a valid state.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;Grammar&lt;/code&gt;</ph>nie jest w prawidłowym stanie.</target>       </trans-unit>
        <trans-unit id="359" translate="yes" xml:space="preserve">
          <source>The asynchronous operation was canceled.</source>
          <target state="translated">Operacja asynchroniczna została anulowana.</target>       </trans-unit>
        <trans-unit id="360" translate="yes" xml:space="preserve">
          <source>Raised when the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> finishes the asynchronous loading of a <bpt id="p2">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt><ept id="p2">&lt;/xref&gt;</ept> object.</source>
          <target state="translated">Wywoływane, gdy <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> zakończeniu asynchroniczne ładowanie <bpt id="p2">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt> <ept id="p2">&lt;/xref&gt;</ept> obiektu.</target>       </trans-unit>
        <trans-unit id="361" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer's &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt; method initiates an asynchronous operation.</source>
          <target state="translated">Aparat rozpoznawania &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;Metoda inicjuje operację asynchroniczną.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A&gt;</target>       </trans-unit>
        <trans-unit id="362" translate="yes" xml:space="preserve" extradata="MT">
          <source>The &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; raises this event when it completes the operation.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;Zgłasza zdarzenie, to po zakończeniu tej operacji.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="363" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get the &lt;xref:System.Speech.Recognition.Grammar&gt; object that the recognizer loaded, use the &lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A&gt; property of the associated &lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt;.</source>
          <target state="translated">Aby uzyskać &lt;xref:System.Speech.Recognition.Grammar&gt;obiekt, który aparat rozpoznawania załadowane, użyj &lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A&gt;właściwości skojarzone &lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt;.&lt;/xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt; &lt;/xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A&gt; &lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="364" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get the current &lt;xref:System.Speech.Recognition.Grammar&gt; objects the recognizer has loaded, use the recognizer's &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A&gt; property.</source>
          <target state="translated">Aby uzyskać bieżącą &lt;xref:System.Speech.Recognition.Grammar&gt;obiekty aparat rozpoznawania został załadowany, używają aparat rozpoznawania &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A&gt;Właściwości.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A&gt; &lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="365" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the recognizer is running, applications must use &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt; to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
          <target state="translated">Jeśli aparat rozpoznawania jest uruchomiona, aplikacje muszą używać &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;wstrzymania aparat rozpoznawania mowy przed ładowania, zwalnianie, włączanie lub wyłączanie gramatyki.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</target>       </trans-unit>
        <trans-unit id="366" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create a LoadGrammarCompleted delegate, you identify the method that will handle the event.</source>
          <target state="translated">Podczas tworzenia delegata LoadGrammarCompleted, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="367" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="368" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływana, gdy wystąpi zdarzenie, o ile nie usuniesz delegata.</target>       </trans-unit>
        <trans-unit id="369" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="370" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">Do dodania.</target>       </trans-unit>
        <trans-unit id="371" translate="yes" xml:space="preserve">
          <source>Gets or sets the maximum number of alternate recognition results that the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> returns for each recognition operation.</source>
          <target state="translated">Pobiera lub ustawia maksymalną liczbę wyników rozpoznawania alternatywnego, który <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> zwraca dla każdej operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="372" translate="yes" xml:space="preserve" extradata="MT">
          <source>The &lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt; property of the &lt;xref:System.Speech.Recognition.RecognitionResult&gt; class contains the collection of &lt;xref:System.Speech.Recognition.RecognizedPhrase&gt; objects that represent possible interpretations of the input.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;Właściwość &lt;xref:System.Speech.Recognition.RecognitionResult&gt;klasy zawiera kolekcję &lt;xref:System.Speech.Recognition.RecognizedPhrase&gt;obiekty reprezentujące możliwe interpretacje danych wejściowych.&lt;/xref:System.Speech.Recognition.RecognizedPhrase&gt; &lt;/xref:System.Speech.Recognition.RecognitionResult&gt; &lt;/xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</target>       </trans-unit>
        <trans-unit id="373" translate="yes" xml:space="preserve" extradata="MT">
          <source>The default value for MaxAlternates is 10.</source>
          <target state="translated">Domyślna wartość MaxAlternates wynosi 10.</target>       </trans-unit>
        <trans-unit id="374" translate="yes" xml:space="preserve">
          <source>The number of alternate results to return.</source>
          <target state="translated">Liczba alternatywny wyników do zwrócenia.</target>       </trans-unit>
        <trans-unit id="375" translate="yes" xml:space="preserve">
          <source>MaxAlternates is set to a value less than 0.</source>
          <target state="translated">MaxAlternates jest ustawiona na wartość mniejszą niż 0.</target>       </trans-unit>
        <trans-unit id="376" translate="yes" xml:space="preserve">
          <source>Returns the values of settings for the recognizer.</source>
          <target state="translated">Zwraca wartości ustawień przez aparat rozpoznawania.</target>       </trans-unit>
        <trans-unit id="377" translate="yes" xml:space="preserve" extradata="MT">
          <source>Recognizer settings can contain string, 64-bit integer, or memory address data.</source>
          <target state="translated">Ustawienia aparatu rozpoznawania może zawierać ciągu, 64-bitową liczbą całkowitą lub dane adresów pamięci.</target>       </trans-unit>
        <trans-unit id="378" translate="yes" xml:space="preserve" extradata="MT">
          <source>The following table describes the settings that are defined for a Microsoft Speech API (SAPI)-compliant recognizer.</source>
          <target state="translated">W poniższej tabeli opisano ustawienia, które są zdefiniowane dla interfejsu API mowy firmy Microsoft (SAPI)-zgodne aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="379" translate="yes" xml:space="preserve" extradata="MT">
          <source>The following settings must have the same range for each recognizer that supports the setting.</source>
          <target state="translated">Następujące ustawienia należy skonfigurować każdy aparat rozpoznawania, który obsługuje ustawienie tego samego zakresu.</target>       </trans-unit>
        <trans-unit id="380" translate="yes" xml:space="preserve" extradata="MT">
          <source>A SAPI-compliant recognizer is not required to support these settings and can support other settings.</source>
          <target state="translated">Zgodne SAPI aparat rozpoznawania nie jest wymagany do obsługi tych ustawień i może obsługiwać inne ustawienia.</target>       </trans-unit>
        <trans-unit id="381" translate="yes" xml:space="preserve" extradata="MT">
          <source>|Name|Description|   |----------|-----------------|   |<ph id="ph1">`ResourceUsage`</ph>|Specifies the recognizer's CPU consumption.</source>
          <target state="translated">| Nazwa | Opis elementu |   |----------|-----------------|   | <ph id="ph1">`ResourceUsage`</ph>| Określa użycie procesora CPU przez aparat rozpoznawania.</target>       </trans-unit>
        <trans-unit id="382" translate="yes" xml:space="preserve" extradata="MT">
          <source>The range is from 0 to 100.</source>
          <target state="translated">Zakres wynosi od 0 do 100.</target>       </trans-unit>
        <trans-unit id="383" translate="yes" xml:space="preserve" extradata="MT">
          <source>The default value is 50.|   |<ph id="ph1">`ResponseSpeed`</ph>|Indicates the length of silence at the end of unambiguous input before the speech recognizer completes a recognition operation.</source>
          <target state="translated">Wartością domyślną jest 50. |   | <ph id="ph1">`ResponseSpeed`</ph>| Wskazuje długość wyciszenia na końcu danych wejściowych jednoznaczne ukończenia operacji rozpoznawania rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="384" translate="yes" xml:space="preserve" extradata="MT">
          <source>The range is from 0 to 10,000 milliseconds (ms).</source>
          <target state="translated">Zakres wynosi od 0 do 10 000 w milisekundach (ms).</target>       </trans-unit>
        <trans-unit id="385" translate="yes" xml:space="preserve" extradata="MT">
          <source>This setting corresponds to the recognizer's &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt; property.</source>
          <target state="translated">To ustawienie odpowiada aparat rozpoznawania &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;Właściwości.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;</target>       </trans-unit>
        <trans-unit id="386" translate="yes" xml:space="preserve" extradata="MT">
          <source>Default = 150ms.|   |<ph id="ph1">`ComplexResponseSpeed`</ph>|Indicates the length of silence at the end of ambiguous input before the speech recognizer completes a recognition operation.</source>
          <target state="translated">Domyślne = 150ms. |   | <ph id="ph1">`ComplexResponseSpeed`</ph>| Wskazuje długość wyciszenia na końcu danych wejściowych niejednoznaczne ukończenia operacji rozpoznawania rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="387" translate="yes" xml:space="preserve" extradata="MT">
          <source>The range is from 0 to 10,000ms.</source>
          <target state="translated">Zakres wynosi od 0 do 10,000ms.</target>       </trans-unit>
        <trans-unit id="388" translate="yes" xml:space="preserve" extradata="MT">
          <source>This setting corresponds to the recognizer's &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt; property.</source>
          <target state="translated">To ustawienie odpowiada aparat rozpoznawania &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;Właściwości.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</target>       </trans-unit>
        <trans-unit id="389" translate="yes" xml:space="preserve" extradata="MT">
          <source>Default = 500ms.|   |<ph id="ph1">`AdaptationOn`</ph>|Indicates whether adaptation of the acoustic model is ON (value = <ph id="ph2">`1`</ph>) or OFF (value = <ph id="ph3">`0`</ph>).</source>
          <target state="translated">Domyślnie 500 MS. |   | <ph id="ph1">`AdaptationOn`</ph>| Wskazuje, czy dostosowania modelu akustycznego jest ON (wartość = <ph id="ph2">`1`</ph>) lub OFF (wartość = <ph id="ph3">`0`</ph>).</target>       </trans-unit>
        <trans-unit id="390" translate="yes" xml:space="preserve" extradata="MT">
          <source>The default value is <ph id="ph1">`1`</ph> (ON).|   |<ph id="ph2">`PersistedBackgroundAdaptation`</ph>|Indicates whether background adaptation is ON (value = <ph id="ph3">`1`</ph>) or OFF (value = <ph id="ph4">`0`</ph>), and persists the setting in the registry.</source>
          <target state="translated">Wartość domyślna to <ph id="ph1">`1`</ph> (dalej). |   | <ph id="ph2">`PersistedBackgroundAdaptation`</ph>| Wskazuje, czy adaptacja w tle jest ON (wartość = <ph id="ph3">`1`</ph>) lub OFF (wartość = <ph id="ph4">`0`</ph>), będzie się powtarzał ustawienie w rejestrze.</target>       </trans-unit>
        <trans-unit id="391" translate="yes" xml:space="preserve" extradata="MT">
          <source>The default value is <ph id="ph1">`1`</ph> (ON).|       To update a setting for the recognizer, use one of the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt; methods.</source>
          <target state="translated">Wartość domyślna to <ph id="ph1">`1`</ph> (dalej). |       Aby zaktualizować ustawienia przez aparat rozpoznawania, użyj jednej z &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</target>       </trans-unit>
        <trans-unit id="392" translate="yes" xml:space="preserve">
          <source>The name of the setting to return.</source>
          <target state="translated">Nazwa ustawienia do zwrócenia.</target>       </trans-unit>
        <trans-unit id="393" translate="yes" xml:space="preserve">
          <source>The value of the setting.</source>
          <target state="translated">Wartość ustawienia.</target>       </trans-unit>
        <trans-unit id="394" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;settingName&lt;/code&gt;</ph> is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;settingName&lt;/code&gt;</ph>is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="395" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;settingName&lt;/code&gt;</ph> is the empty string ("").</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;settingName&lt;/code&gt;</ph>jest pustym ciągiem ("").</target>       </trans-unit>
        <trans-unit id="396" translate="yes" xml:space="preserve">
          <source>The recognizer does not have a setting by that name.</source>
          <target state="translated">Aparat rozpoznawania nie ma ustawienie o takiej nazwie.</target>       </trans-unit>
        <trans-unit id="397" translate="yes" xml:space="preserve">
          <source>Performs a synchronous speech recognition operation.</source>
          <target state="translated">Wykonuje operację rozpoznawania mowy synchronicznego.</target>       </trans-unit>
        <trans-unit id="398" translate="yes" xml:space="preserve" extradata="MT">
          <source>This method performs a single recognition operation.</source>
          <target state="translated">Ta metoda wykonuje operację pojedynczego rozpoznawania.</target>       </trans-unit>
        <trans-unit id="399" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer performs this operation against its loaded and enabled speech recognition grammars.</source>
          <target state="translated">Aparat rozpoznawania wykonuje tę operację przed jego gramatyki rozpoznawania mowy załadowany i włączona.</target>       </trans-unit>
        <trans-unit id="400" translate="yes" xml:space="preserve" extradata="MT">
          <source>During a call to this method, the recognizer can raise the following events:      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;.</source>
          <target state="translated">Podczas wywoływania tej metody, aparat rozpoznawania może wiązać się z następujących zdarzeń:- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</target>       </trans-unit>
        <trans-unit id="401" translate="yes" xml:space="preserve" extradata="MT">
          <source>Raised when the recognizer detects input that it can identify as speech.</source>
          <target state="translated">Wywoływane, gdy aparat rozpoznawania wykrywa danych wejściowych, którą można zidentyfikować jako mowy.</target>       </trans-unit>
        <trans-unit id="402" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;.</source>
          <target state="translated">-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</target>       </trans-unit>
        <trans-unit id="403" translate="yes" xml:space="preserve" extradata="MT">
          <source>Raised when input creates an ambiguous match with one of the active grammars.</source>
          <target state="translated">Wywoływane, gdy dane wejściowe tworzy niejednoznaczne dopasowanie z jednej aktywnej gramatyki.</target>       </trans-unit>
        <trans-unit id="404" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;.</source>
          <target state="translated">-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</target>       </trans-unit>
        <trans-unit id="405" translate="yes" xml:space="preserve" extradata="MT">
          <source>Raised when the recognizer finalizes a recognition operation.</source>
          <target state="translated">Wywoływane, gdy aparat rozpoznawania Kończenie znajdujących się w operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="406" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer does not raise the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt; event when using this method.</source>
          <target state="translated">Aparat rozpoznawania nie wygenerował &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;zdarzeń przy użyciu tej metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</target>       </trans-unit>
        <trans-unit id="407" translate="yes" xml:space="preserve" extradata="MT">
          <source>The Recognize method returns a &lt;xref:System.Speech.Recognition.RecognitionResult&gt; object, or <ph id="ph1">`null`</ph> if the operation is not successful.</source>
          <target state="translated">Zwraca metodę rozpoznawanie &lt;xref:System.Speech.Recognition.RecognitionResult&gt;obiekt, lub <ph id="ph1">`null`</ph> Jeśli operacja nie powiedzie.&lt;/xref:System.Speech.Recognition.RecognitionResult&gt;</target>       </trans-unit>
        <trans-unit id="408" translate="yes" xml:space="preserve" extradata="MT">
          <source>A synchronous recognition operation can fail for the following reasons:      -   Speech is not detected before the timeout intervals expire for the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt; properties.</source>
          <target state="translated">Operacja synchroniczna rozpoznawania może się nie powieść z następujących powodów:-mowy nie wykrywa odstępach czasu wygaśnięcia dla &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;lub &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;Właściwości.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</target>       </trans-unit>
        <trans-unit id="409" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   The recognition engine detects speech but finds no matches in any of its loaded and enabled &lt;xref:System.Speech.Recognition.Grammar&gt; objects.</source>
          <target state="translated">-Aparat rozpoznawania mowy wykrywa, ale znajduje żadnych dopasowań w dowolnej z załadowanych i włączona &lt;xref:System.Speech.Recognition.Grammar&gt;obiektów.&lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="410" translate="yes" xml:space="preserve" extradata="MT">
          <source>To perform asynchronous recognition, use one of the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt; methods.</source>
          <target state="translated">Aby przeprowadzić rozpoznawanie asynchroniczne, użyj jednej z &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</target>       </trans-unit>
        <trans-unit id="411" translate="yes" xml:space="preserve">
          <source>The recognition result for the input, or <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> if the operation is not successful or the recognizer is not enabled.</source>
          <target state="translated">Wynik rozpoznawania dla danych wejściowych, lub <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> Jeśli operacja nie powiedzie się lub nie włączono aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="412" translate="yes" xml:space="preserve">
          <source>Performs a synchronous speech recognition operation with a specified initial silence timeout period.</source>
          <target state="translated">Wykonuje operację rozpoznawania mowy synchroniczne okres limitu czasu określonego wyciszenia początkowej.</target>       </trans-unit>
        <trans-unit id="413" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the speech recognition engine detects speech within the time interval specified by <ph id="ph1">`initialSilenceTimeout`</ph> argument, Recognize performs a single recognition operation and then terminates.</source>
          <target state="translated">Jeśli aparat rozpoznawania mowy wykrywa mowy w czasie określonym przez <ph id="ph1">`initialSilenceTimeout`</ph> argument, rozpoznawanie wykonuje operację pojedynczego rozpoznawania i następnie kończy.</target>       </trans-unit>
        <trans-unit id="414" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <ph id="ph1">`initialSilenceTimeout`</ph> parameter supersedes the recognizer's &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt; property.</source>
          <target state="translated"><ph id="ph1">`initialSilenceTimeout`</ph> Parametru zastępuje aparat rozpoznawania &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;Właściwości.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;</target>       </trans-unit>
        <trans-unit id="415" translate="yes" xml:space="preserve" extradata="MT">
          <source>During a call to this method, the recognizer can raise the following events:      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;.</source>
          <target state="translated">Podczas wywoływania tej metody, aparat rozpoznawania może wiązać się z następujących zdarzeń:- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</target>       </trans-unit>
        <trans-unit id="416" translate="yes" xml:space="preserve" extradata="MT">
          <source>Raised when the recognizer detects input that it can identify as speech.</source>
          <target state="translated">Wywoływane, gdy aparat rozpoznawania wykrywa danych wejściowych, którą można zidentyfikować jako mowy.</target>       </trans-unit>
        <trans-unit id="417" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;.</source>
          <target state="translated">-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</target>       </trans-unit>
        <trans-unit id="418" translate="yes" xml:space="preserve" extradata="MT">
          <source>Raised when input creates an ambiguous match with one of the active grammars.</source>
          <target state="translated">Wywoływane, gdy dane wejściowe tworzy niejednoznaczne dopasowanie z jednej aktywnej gramatyki.</target>       </trans-unit>
        <trans-unit id="419" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;.</source>
          <target state="translated">-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</target>       </trans-unit>
        <trans-unit id="420" translate="yes" xml:space="preserve" extradata="MT">
          <source>Raised when the recognizer finalizes a recognition operation.</source>
          <target state="translated">Wywoływane, gdy aparat rozpoznawania Kończenie znajdujących się w operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="421" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer does not raise the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt; event when using this method.</source>
          <target state="translated">Aparat rozpoznawania nie wygenerował &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;zdarzeń przy użyciu tej metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</target>       </trans-unit>
        <trans-unit id="422" translate="yes" xml:space="preserve" extradata="MT">
          <source>The &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize&gt; method returns a &lt;xref:System.Speech.Recognition.RecognitionResult&gt; object, or <ph id="ph1">`null`</ph> if the operation is not successful.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize&gt;Metoda zwraca &lt;xref:System.Speech.Recognition.RecognitionResult&gt;obiekt, lub <ph id="ph1">`null`</ph> Jeśli operacja nie powiedzie.&lt;/xref:System.Speech.Recognition.RecognitionResult&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize&gt;</target>       </trans-unit>
        <trans-unit id="423" translate="yes" xml:space="preserve" extradata="MT">
          <source>A synchronous recognition operation can fail for the following reasons:      -   Speech is not detected before the timeout intervals expire for the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt; or for the <ph id="ph1">`initialSilenceTimeout`</ph> parameter.</source>
          <target state="translated">Operacja synchroniczna rozpoznawania może się nie powieść z następujących powodów:-mowy nie wykrywa odstępach czasu wygaśnięcia dla &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;lub <ph id="ph1">`initialSilenceTimeout`</ph> parametru.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</target>       </trans-unit>
        <trans-unit id="424" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   The recognition engine detects speech but finds no matches in any of its loaded and enabled &lt;xref:System.Speech.Recognition.Grammar&gt; objects.</source>
          <target state="translated">-Aparat rozpoznawania mowy wykrywa, ale znajduje żadnych dopasowań w dowolnej z załadowanych i włączona &lt;xref:System.Speech.Recognition.Grammar&gt;obiektów.&lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="425" translate="yes" xml:space="preserve" extradata="MT">
          <source>To perform asynchronous recognition, use one of the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt; methods.</source>
          <target state="translated">Aby przeprowadzić rozpoznawanie asynchroniczne, użyj jednej z &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</target>       </trans-unit>
        <trans-unit id="426" translate="yes" xml:space="preserve">
          <source>The interval of time a speech recognizer accepts input containing only silence before finalizing recognition.</source>
          <target state="translated">Przedział czasu, który akceptuje rozpoznawania mowy wejściowych zawierających tylko wyciszenia przed zakończeniem rozpoznawania.</target>       </trans-unit>
        <trans-unit id="427" translate="yes" xml:space="preserve">
          <source>The recognition result for the input, or <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> if the operation is not successful or the recognizer is not enabled.</source>
          <target state="translated">Wynik rozpoznawania dla danych wejściowych, lub <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> Jeśli operacja nie powiedzie się lub nie włączono aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="428" translate="yes" xml:space="preserve">
          <source>Performs a single, asynchronous speech recognition operation.</source>
          <target state="translated">Wykonuje operację rozpoznawania mowy pojedynczego, asynchronicznego.</target>       </trans-unit>
        <trans-unit id="429" translate="yes" xml:space="preserve" extradata="MT">
          <source>This method performs a single, asynchronous recognition operation.</source>
          <target state="translated">Ta metoda wykonuje operację rozpoznawania pojedynczego, asynchronicznego.</target>       </trans-unit>
        <trans-unit id="430" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer performs the operation against its loaded and enabled speech recognition grammars.</source>
          <target state="translated">Aparat rozpoznawania wykonuje operację względem jego gramatyki rozpoznawania mowy załadowany i włączona.</target>       </trans-unit>
        <trans-unit id="431" translate="yes" xml:space="preserve" extradata="MT">
          <source>During a call to this method, the recognizer can raise the following events:      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;.</source>
          <target state="translated">Podczas wywoływania tej metody, aparat rozpoznawania może wiązać się z następujących zdarzeń:- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</target>       </trans-unit>
        <trans-unit id="432" translate="yes" xml:space="preserve" extradata="MT">
          <source>Raised when the recognizer detects input that it can identify as speech.</source>
          <target state="translated">Wywoływane, gdy aparat rozpoznawania wykrywa danych wejściowych, którą można zidentyfikować jako mowy.</target>       </trans-unit>
        <trans-unit id="433" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;.</source>
          <target state="translated">-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</target>       </trans-unit>
        <trans-unit id="434" translate="yes" xml:space="preserve" extradata="MT">
          <source>Raised when input creates an ambiguous match with one of the active grammars.</source>
          <target state="translated">Wywoływane, gdy dane wejściowe tworzy niejednoznaczne dopasowanie z jednej aktywnej gramatyki.</target>       </trans-unit>
        <trans-unit id="435" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;.</source>
          <target state="translated">-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</target>       </trans-unit>
        <trans-unit id="436" translate="yes" xml:space="preserve" extradata="MT">
          <source>Raised when the recognizer finalizes a recognition operation.</source>
          <target state="translated">Wywoływane, gdy aparat rozpoznawania Kończenie znajdujących się w operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="437" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;.</source>
          <target state="translated">-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</target>       </trans-unit>
        <trans-unit id="438" translate="yes" xml:space="preserve" extradata="MT">
          <source>Raised when a &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt; operation finishes.</source>
          <target state="translated">Wywoływane, gdy &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;Zakończenie operacji.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</target>       </trans-unit>
        <trans-unit id="439" translate="yes" xml:space="preserve" extradata="MT">
          <source>To retrieve the result of an asynchronous recognition operation, attach an event handler to the recognizer's &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; event.</source>
          <target state="translated">Aby uzyskać wynik operacji asynchronicznej rozpoznawania, Dołącz program obsługi zdarzeń dla aparatu rozpoznawania &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;zdarzeń.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</target>       </trans-unit>
        <trans-unit id="440" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer raises this event whenever it successfully completes a synchronous or asynchronous recognition operation.</source>
          <target state="translated">Aparat rozpoznawania zgłasza tego zdarzenia przy każdym pomyślnym zakończeniu operacji rozpoznawania synchroniczna lub asynchroniczna.</target>       </trans-unit>
        <trans-unit id="441" translate="yes" xml:space="preserve" extradata="MT">
          <source>If recognition was not successful, the &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A&gt; property on &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt; object, which you can access in the handler for the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt; event, will be <ph id="ph1">`null`</ph>.</source>
          <target state="translated">Jeśli rozpoznawania zakończyła się niepowodzeniem, &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A&gt;Właściwość &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;obiektu, który można uzyskać dostępu do programu obsługi dla &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;będzie zdarzenia <ph id="ph1">`null`</ph>.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt; &lt;/xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt; &lt;/xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A&gt;</target>       </trans-unit>
        <trans-unit id="442" translate="yes" xml:space="preserve" extradata="MT">
          <source>To perform synchronous recognition, use one of the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt; methods.</source>
          <target state="translated">Aby przeprowadzić rozpoznawanie synchroniczne, użyj jednej z &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</target>       </trans-unit>
        <trans-unit id="443" translate="yes" xml:space="preserve">
          <source>Performs one or more asynchronous speech recognition operations.</source>
          <target state="translated">Wykonuje jeden lub więcej operacji rozpoznawania mowy asynchronicznego.</target>       </trans-unit>
        <trans-unit id="444" translate="yes" xml:space="preserve" extradata="MT">
          <source>If <ph id="ph1">`mode`</ph> is &lt;xref:System.Speech.Recognition.RecognizeMode&gt;, the recognizer continues performing asynchronous recognition operations until the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A&gt; method is called.</source>
          <target state="translated">Jeśli <ph id="ph1">`mode`</ph> jest &lt;xref:System.Speech.Recognition.RecognizeMode&gt;, aparat rozpoznawania kontynuuje wykonywanie operacji asynchronicznych rozpoznawania do &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A&gt;lub &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A&gt;Metoda jest wywoływana.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A&gt; &lt;/xref:System.Speech.Recognition.RecognizeMode&gt;</target>       </trans-unit>
        <trans-unit id="445" translate="yes" xml:space="preserve" extradata="MT">
          <source>During a call to this method, the recognizer can raise the following events:      -   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;.</source>
          <target state="translated">Podczas wywoływania tej metody, aparat rozpoznawania może wiązać się z następujących zdarzeń:- &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected&gt;</target>       </trans-unit>
        <trans-unit id="446" translate="yes" xml:space="preserve" extradata="MT">
          <source>Raised when the recognizer detects input that it can identify as speech.</source>
          <target state="translated">Wywoływane, gdy aparat rozpoznawania wykrywa danych wejściowych, którą można zidentyfikować jako mowy.</target>       </trans-unit>
        <trans-unit id="447" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;.</source>
          <target state="translated">-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;</target>       </trans-unit>
        <trans-unit id="448" translate="yes" xml:space="preserve" extradata="MT">
          <source>Raised when input creates an ambiguous match with one of the active grammars.</source>
          <target state="translated">Wywoływane, gdy dane wejściowe tworzy niejednoznaczne dopasowanie z jednej aktywnej gramatyki.</target>       </trans-unit>
        <trans-unit id="449" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;.</source>
          <target state="translated">-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</target>       </trans-unit>
        <trans-unit id="450" translate="yes" xml:space="preserve" extradata="MT">
          <source>Raised when the recognizer finalizes a recognition operation.</source>
          <target state="translated">Wywoływane, gdy aparat rozpoznawania Kończenie znajdujących się w operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="451" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;.</source>
          <target state="translated">-   &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</target>       </trans-unit>
        <trans-unit id="452" translate="yes" xml:space="preserve" extradata="MT">
          <source>Raised when a &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt; operation finishes.</source>
          <target state="translated">Wywoływane, gdy &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;Zakończenie operacji.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</target>       </trans-unit>
        <trans-unit id="453" translate="yes" xml:space="preserve" extradata="MT">
          <source>To retrieve the result of an asynchronous recognition operation, attach an event handler to the recognizer's &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; event.</source>
          <target state="translated">Aby uzyskać wynik operacji asynchronicznej rozpoznawania, Dołącz program obsługi zdarzeń dla aparatu rozpoznawania &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;zdarzeń.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</target>       </trans-unit>
        <trans-unit id="454" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer raises this event whenever it successfully completes a synchronous or asynchronous recognition operation.</source>
          <target state="translated">Aparat rozpoznawania zgłasza tego zdarzenia przy każdym pomyślnym zakończeniu operacji rozpoznawania synchroniczna lub asynchroniczna.</target>       </trans-unit>
        <trans-unit id="455" translate="yes" xml:space="preserve" extradata="MT">
          <source>If recognition was not successful, the &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A&gt; property on &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt; object, which you can access in the handler for the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt; event, will be <ph id="ph1">`null`</ph>.</source>
          <target state="translated">Jeśli rozpoznawania zakończyła się niepowodzeniem, &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A&gt;Właściwość &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;obiektu, który można uzyskać dostępu do programu obsługi dla &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;będzie zdarzenia <ph id="ph1">`null`</ph>.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt; &lt;/xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt; &lt;/xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A&gt;</target>       </trans-unit>
        <trans-unit id="456" translate="yes" xml:space="preserve" extradata="MT">
          <source>An asynchronous recognition operation can fail for the following reasons:      -   Speech is not detected before the timeout intervals expire for the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt; properties.</source>
          <target state="translated">Operacja asynchronicznego rozpoznawania może się nie powieść z następujących powodów:-mowy nie wykrywa odstępach czasu wygaśnięcia dla &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;lub &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;Właściwości.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</target>       </trans-unit>
        <trans-unit id="457" translate="yes" xml:space="preserve" extradata="MT">
          <source>-   The recognition engine detects speech but finds no matches in any of its loaded and enabled &lt;xref:System.Speech.Recognition.Grammar&gt; objects.</source>
          <target state="translated">-Aparat rozpoznawania mowy wykrywa, ale znajduje żadnych dopasowań w dowolnej z załadowanych i włączona &lt;xref:System.Speech.Recognition.Grammar&gt;obiektów.&lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="458" translate="yes" xml:space="preserve" extradata="MT">
          <source>To perform synchronous recognition, use one of the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt; methods.</source>
          <target state="translated">Aby przeprowadzić rozpoznawanie synchroniczne, użyj jednej z &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</target>       </trans-unit>
        <trans-unit id="459" translate="yes" xml:space="preserve">
          <source>Indicates whether to perform one or multiple recognition operations.</source>
          <target state="translated">Wskazuje, czy wykonywanie jednego lub wielu operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="460" translate="yes" xml:space="preserve">
          <source>Terminates asynchronous recognition without waiting for the current recognition operation to complete.</source>
          <target state="translated">Kończy asynchroniczne rozpoznawanie bez oczekiwania na ukończenie bieżącej operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="461" translate="yes" xml:space="preserve" extradata="MT">
          <source>This method immediately finalizes asynchronous recognition.</source>
          <target state="translated">Ta metoda natychmiast Kończenie znajdujących się w asynchronicznej rozpoznawania.</target>       </trans-unit>
        <trans-unit id="462" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the current asynchronous recognition operation is receiving input, the input is truncated and the operation completes with the existing input.</source>
          <target state="translated">Jeśli bieżąca operacja asynchroniczne rozpoznawanie otrzymuje dane wejściowe, dane wejściowe został obcięty i zakończeniu operacji przy użyciu istniejących danych wejściowych.</target>       </trans-unit>
        <trans-unit id="463" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer raises the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt; event when an asynchronous operation is canceled, and sets the &lt;xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A&gt; property of the &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt; to <ph id="ph1">`true`</ph>.</source>
          <target state="translated">Generuje aparatu rozpoznawania &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;lub &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;zdarzenie, gdy operacja asynchroniczna została anulowana i ustawia &lt;xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A&gt;Właściwość &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;do <ph id="ph1">`true`</ph>.&lt;/xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt; &lt;/xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</target>       </trans-unit>
        <trans-unit id="464" translate="yes" xml:space="preserve" extradata="MT">
          <source>This method cancels asynchronous operations initiated by the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt; and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt; methods.</source>
          <target state="translated">Ta metoda umożliwia anulowanie operacji asynchronicznych inicjowane przez &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;i &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</target>       </trans-unit>
        <trans-unit id="465" translate="yes" xml:space="preserve" extradata="MT">
          <source>To stop asynchronous recognition without truncating the input, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A&gt; method.</source>
          <target state="translated">Aby zatrzymać asynchroniczne rozpoznawanie bez obcinanie danych wejściowych, należy użyć &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A&gt;</target>       </trans-unit>
        <trans-unit id="466" translate="yes" xml:space="preserve">
          <source>Stops asynchronous recognition after the current recognition operation completes.</source>
          <target state="translated">Zatrzymuje rozpoznawania asynchronicznych po zakończeniu bieżącej operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="467" translate="yes" xml:space="preserve" extradata="MT">
          <source>This method finalizes asynchronous recognition without truncating input.</source>
          <target state="translated">Ta metoda Kończenie znajdujących się w asynchroniczne rozpoznawanie bez obcinanie danych wejściowych.</target>       </trans-unit>
        <trans-unit id="468" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the current asynchronous recognition operation is receiving input, the recognizer continues accepting input until the current recognition operation is completed.</source>
          <target state="translated">Jeśli bieżąca operacja asynchroniczne rozpoznawanie otrzymuje dane wejściowe, aparat rozpoznawania nadal akceptowanie danych wejściowych ukończenie bieżącej operacji rozpoznawania.</target>       </trans-unit>
        <trans-unit id="469" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer raises the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt; event when an asynchronous operation is stopped, and sets the &lt;xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A&gt; property of the &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt; to <ph id="ph1">`true`</ph>.</source>
          <target state="translated">Generuje aparatu rozpoznawania &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;lub &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt;zdarzenie, gdy operacja asynchroniczna została zatrzymana i ustawia &lt;xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A&gt;Właściwość &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;do <ph id="ph1">`true`</ph>.&lt;/xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt; &lt;/xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</target>       </trans-unit>
        <trans-unit id="470" translate="yes" xml:space="preserve" extradata="MT">
          <source>This method stops asynchronous operations initiated by the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt; and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt; methods.</source>
          <target state="translated">Ta metoda zatrzymuje operacje asynchroniczne inicjowane przez &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;i &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;</target>       </trans-unit>
        <trans-unit id="471" translate="yes" xml:space="preserve" extradata="MT">
          <source>To immediately cancel asynchronous recognition with only the existing input, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A&gt; method.</source>
          <target state="translated">Aby natychmiast anulować asynchroniczne rozpoznawanie przy użyciu tylko istniejących danych wejściowych, należy użyć &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A&gt;</target>       </trans-unit>
        <trans-unit id="472" translate="yes" xml:space="preserve">
          <source>Raised when the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> finalizes an asynchronous recognition operation.</source>
          <target state="translated">Wywoływane, gdy <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> Kończenie znajdujących się w operacji asynchronicznych rozpoznawania.</target>       </trans-unit>
        <trans-unit id="473" translate="yes" xml:space="preserve" extradata="MT">
          <source>The &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; object's &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt; method initiates an asynchronous recognition operation.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;Obiektu &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;Metoda inicjuje operację asynchroniczną rozpoznawania.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="474" translate="yes" xml:space="preserve" extradata="MT">
          <source>When the recognizer finalizes the asynchronous operation, it raises this event.</source>
          <target state="translated">Gdy aparat rozpoznawania Kończenie znajdujących się operację asynchroniczną, uruchamia to zdarzenie.</target>       </trans-unit>
        <trans-unit id="475" translate="yes" xml:space="preserve" extradata="MT">
          <source>Using the handler for the RecognizeCompleted event, you can access the &lt;xref:System.Speech.Recognition.RecognitionResult&gt; in the &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt; object.</source>
          <target state="translated">Przy użyciu procedury obsługi dla zdarzenia RecognizeCompleted, są dostępne &lt;xref:System.Speech.Recognition.RecognitionResult&gt;w &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;obiektu.&lt;/xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt; &lt;/xref:System.Speech.Recognition.RecognitionResult&gt;</target>       </trans-unit>
        <trans-unit id="476" translate="yes" xml:space="preserve" extradata="MT">
          <source>If recognition was not successful, &lt;xref:System.Speech.Recognition.RecognitionResult&gt; will be <ph id="ph1">`null`</ph>.</source>
          <target state="translated">Jeśli rozpoznawania zakończyła się niepowodzeniem, &lt;xref:System.Speech.Recognition.RecognitionResult&gt;będzie <ph id="ph1">`null`</ph>.&lt;/xref:System.Speech.Recognition.RecognitionResult&gt;</target>       </trans-unit>
        <trans-unit id="477" translate="yes" xml:space="preserve" extradata="MT">
          <source>To determine whether a timeout or an interruption in audio input caused recognition to fail, you can access the properties for &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A&gt;, &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A&gt;, or &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded%2A&gt;.</source>
          <target state="translated">Aby ustalić, czy rozpoznawanie niepowodzenie przyczyną przekroczenie limitu czasu lub przerw w wejściowych danych audio, można uzyskać dostępu do właściwości &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A&gt;, &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A&gt;, lub &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded%2A&gt;.&lt;/xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded%2A&gt; &lt;/xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A&gt; &lt;/xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A&gt;</target>       </trans-unit>
        <trans-unit id="478" translate="yes" xml:space="preserve" extradata="MT">
          <source>See the &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt; class for more information.</source>
          <target state="translated">Zobacz &lt;xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;klasy, aby uzyskać więcej informacji.&lt;/xref:System.Speech.Recognition.RecognizeCompletedEventArgs&gt;</target>       </trans-unit>
        <trans-unit id="479" translate="yes" xml:space="preserve" extradata="MT">
          <source>To obtain details on the best rejected recognition candidates, attach a handler for the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; event.</source>
          <target state="translated">Aby uzyskać szczegółowe informacje o najbardziej odpowiednich odrzucone rozpoznawania, Dołącz obsługi dla &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;zdarzeń.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;</target>       </trans-unit>
        <trans-unit id="480" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create a RecognizeCompleted delegate, you identify the method that will handle the event.</source>
          <target state="translated">Podczas tworzenia delegata RecognizeCompleted, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="481" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="482" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływana, gdy wystąpi zdarzenie, o ile nie usuniesz delegata.</target>       </trans-unit>
        <trans-unit id="483" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="484" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">Do dodania.</target>       </trans-unit>
        <trans-unit id="485" translate="yes" xml:space="preserve">
          <source>Gets the current location of the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> in the audio input that it is processing.</source>
          <target state="translated">Pobiera bieżącą lokalizację <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> w wejściowych danych audio, który przetwarzania.</target>       </trans-unit>
        <trans-unit id="486" translate="yes" xml:space="preserve" extradata="MT">
          <source>The audio position is specific to each speech recognizer.</source>
          <target state="translated">Pozycja audio jest specyficzne dla każdego rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="487" translate="yes" xml:space="preserve" extradata="MT">
          <source>The zero value of an input stream is established when it is enabled.</source>
          <target state="translated">Wartość zero strumień wejściowy jest ustanawiane, jeśli jest włączona.</target>       </trans-unit>
        <trans-unit id="488" translate="yes" xml:space="preserve" extradata="MT">
          <source>The RecognizerAudioPosition property references the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; object's position within its audio input.</source>
          <target state="translated">Odwołań do właściwości RecognizerAudioPosition &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;Położenie obiektu w jego wejście audio.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="489" translate="yes" xml:space="preserve" extradata="MT">
          <source>By contrast, the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt; property references the input device's position in its generated audio stream.</source>
          <target state="translated">Z kolei &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;właściwość odwołuje się do pozycji urządzenia wejściowego w jego wygenerowanego strumieniem audio.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</target>       </trans-unit>
        <trans-unit id="490" translate="yes" xml:space="preserve" extradata="MT">
          <source>These positions can be different.</source>
          <target state="translated">Te pozycje mogą być różne.</target>       </trans-unit>
        <trans-unit id="491" translate="yes" xml:space="preserve" extradata="MT">
          <source>For example, if the recognizer has received input for which it has not yet generated a recognition result then the value of the RecognizerAudioPosition property is less than the value of the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt; property.</source>
          <target state="translated">Na przykład, jeśli otrzymał aparat rozpoznawania wejściowych, do których nie ma jeszcze wygenerowane wyników rozpoznawania, a następnie wartość właściwości RecognizerAudioPosition jest mniejsza niż wartość &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;Właściwości.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;</target>       </trans-unit>
        <trans-unit id="492" translate="yes" xml:space="preserve">
          <source>The position of the recognizer in the audio input that it is processing.</source>
          <target state="translated">Pozycja rozpoznawania w wejściowych danych audio, który przetwarzania.</target>       </trans-unit>
        <trans-unit id="493" translate="yes" xml:space="preserve">
          <source>Gets information about the current instance of <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated">Pobiera informacje o bieżące wystąpienie klasy <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="494" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get information about all of the installed speech recognizers for the current system, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt; method.</source>
          <target state="translated">Aby uzyskać informacje na temat wszystkich aparatów rozpoznawania mowy zainstalowanych dla bieżącego systemu, należy użyć &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A&gt;</target>       </trans-unit>
        <trans-unit id="495" translate="yes" xml:space="preserve">
          <source>Information about the current speech recognizer.</source>
          <target state="translated">Informacje o bieżącym rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="496" translate="yes" xml:space="preserve">
          <source>Raised when a running <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> pauses to accept modifications.</source>
          <target state="translated">Wywoływane, gdy uruchomione <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> wstrzymuje działanie, aby zaakceptować zmiany.</target>       </trans-unit>
        <trans-unit id="497" translate="yes" xml:space="preserve" extradata="MT">
          <source>Applications must use &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt; to pause a running instance of &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; before modifying its settings or its &lt;xref:System.Speech.Recognition.Grammar&gt; objects.</source>
          <target state="translated">Aplikacje muszą używać &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;wstrzymania działającego wystąpienia &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;przed zmodyfikowaniem ustawienia lub jego &lt;xref:System.Speech.Recognition.Grammar&gt;obiektów.&lt;/xref:System.Speech.Recognition.Grammar&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</target>       </trans-unit>
        <trans-unit id="498" translate="yes" xml:space="preserve" extradata="MT">
          <source>The &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; raises this event when it is ready to accept modifications.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;Zgłasza to zdarzenie, gdy będzie gotowy do akceptowania modyfikacje.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="499" translate="yes" xml:space="preserve" extradata="MT">
          <source>For example, while the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; is paused, you can load, unload, enable, and disable &lt;xref:System.Speech.Recognition.Grammar&gt; objects, and modify values for the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt; properties.</source>
          <target state="translated">Na przykład &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;jest wstrzymana, możesz można załadować, zwolnienie, włączania i wyłączania &lt;xref:System.Speech.Recognition.Grammar&gt;obiektów i zmodyfikować wartości &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;, i &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;Właściwości.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt; &lt;/xref:System.Speech.Recognition.Grammar&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="500" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information, see the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt; method.</source>
          <target state="translated">Aby uzyskać więcej informacji, zobacz &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</target>       </trans-unit>
        <trans-unit id="501" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create a RecognizerUpdateReached delegate, you identify the method that will handle the event.</source>
          <target state="translated">Podczas tworzenia delegata RecognizerUpdateReached, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="502" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="503" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływana, gdy wystąpi zdarzenie, o ile nie usuniesz delegata.</target>       </trans-unit>
        <trans-unit id="504" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="505" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">Do dodania.</target>       </trans-unit>
        <trans-unit id="506" translate="yes" xml:space="preserve">
          <source>Requests that the recognizer pauses to update its state.</source>
          <target state="translated">Żądania, że aparat rozpoznawania wstrzymuje można zaktualizować stanu.</target>       </trans-unit>
        <trans-unit id="507" translate="yes" xml:space="preserve" extradata="MT">
          <source>When the recognizer generates the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt; event, the &lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt; property of the &lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; is <ph id="ph1">`null`</ph>.</source>
          <target state="translated">Gdy aparat rozpoznawania generuje &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;zdarzenia &lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;Właściwość &lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;jest <ph id="ph1">`null`</ph>.&lt;/xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; &lt;/xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</target>       </trans-unit>
        <trans-unit id="508" translate="yes" xml:space="preserve" extradata="MT">
          <source>To provide a user token, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt; method.</source>
          <target state="translated">Aby dostarczyć token użytkownika, użyj &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;lub &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</target>       </trans-unit>
        <trans-unit id="509" translate="yes" xml:space="preserve" extradata="MT">
          <source>To specify an audio position offset, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt; method.</source>
          <target state="translated">Aby określić przesunięcie pozycji audio, użyj &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</target>       </trans-unit>
        <trans-unit id="510" translate="yes" xml:space="preserve">
          <source>Requests that the recognizer pauses to update its state and provides a user token for the associated event.</source>
          <target state="translated">Żądania, który aparat rozpoznawania wstrzymuje można zaktualizować stanu oraz token użytkownika dla skojarzonego zdarzenia.</target>       </trans-unit>
        <trans-unit id="511" translate="yes" xml:space="preserve" extradata="MT">
          <source>When the recognizer generates the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt; event, the &lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt; property of the &lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; contains the value of the <ph id="ph1">`userToken`</ph> parameter.</source>
          <target state="translated">Gdy aparat rozpoznawania generuje &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;zdarzenia &lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;Właściwość &lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;zawiera wartość <ph id="ph1">`userToken`</ph> parametru.&lt;/xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; &lt;/xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</target>       </trans-unit>
        <trans-unit id="512" translate="yes" xml:space="preserve" extradata="MT">
          <source>To specify an audio position offset, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt; method.</source>
          <target state="translated">Aby określić przesunięcie pozycji audio, użyj &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</target>       </trans-unit>
        <trans-unit id="513" translate="yes" xml:space="preserve">
          <source>User-defined information that contains information for the operation.</source>
          <target state="translated">Informacje zdefiniowane przez użytkownika, zawierający informacje dla tej operacji.</target>       </trans-unit>
        <trans-unit id="514" translate="yes" xml:space="preserve">
          <source>Requests that the recognizer pauses to update its state and provides an offset and a user token for the associated event.</source>
          <target state="translated">Żądania, który aparat rozpoznawania wstrzymuje można zaktualizować stanu oraz przesunięcia i token użytkownika dla skojarzonego zdarzenia.</target>       </trans-unit>
        <trans-unit id="515" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer does not initiate the recognizer update request until the recognizer's &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt; equals the current &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt; plus <ph id="ph1">`audioPositionAheadToRaiseUpdate`</ph>.</source>
          <target state="translated">Aparat rozpoznawania nie zainicjował żądanie aktualizacji aparatu rozpoznawania do aparat rozpoznawania &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;jest równe bieżącego &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt;plus <ph id="ph1">`audioPositionAheadToRaiseUpdate`</ph>.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</target>       </trans-unit>
        <trans-unit id="516" translate="yes" xml:space="preserve" extradata="MT">
          <source>When the recognizer generates the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt; event, the &lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt; property of the &lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; contains the value of the <ph id="ph1">`userToken`</ph> parameter.</source>
          <target state="translated">Gdy aparat rozpoznawania generuje &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;zdarzenia &lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;Właściwość &lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;zawiera wartość <ph id="ph1">`userToken`</ph> parametru.&lt;/xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; &lt;/xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached&gt;</target>       </trans-unit>
        <trans-unit id="517" translate="yes" xml:space="preserve">
          <source>User-defined information that contains information for the operation.</source>
          <target state="translated">Informacje zdefiniowane przez użytkownika, zawierający informacje dla tej operacji.</target>       </trans-unit>
        <trans-unit id="518" translate="yes" xml:space="preserve">
          <source>The offset from the current &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition*&gt; to delay the request.</source>
          <target state="translated">Przesunięcie od bieżącej &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition*&gt;opóźnienia żądania.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition*&gt;</target>       </trans-unit>
        <trans-unit id="519" translate="yes" xml:space="preserve">
          <source>Configures the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> object to receive input from an audio stream.</source>
          <target state="translated">Konfiguruje <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> obiektu dla danych wejściowych z strumieniem audio.</target>       </trans-unit>
        <trans-unit id="520" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the recognizer reaches the end of the input stream during a recognition operation, the recognition operation finalizes with the available input.</source>
          <target state="translated">Jeśli aparat rozpoznawania osiągnie koniec strumienia wejściowego podczas operacji rozpoznawania, operacja rozpoznawania Kończenie znajdujących się przy użyciu dostępnych danych wejściowych.</target>       </trans-unit>
        <trans-unit id="521" translate="yes" xml:space="preserve" extradata="MT">
          <source>Any subsequent recognition operations can generate an exception, unless you update the input to the recognizer.</source>
          <target state="translated">Żadnych operacji rozpoznawania kolejnych może wygenerować wyjątek, chyba że aktualizacji danych wejściowych dla aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="522" translate="yes" xml:space="preserve">
          <source>The audio input stream.</source>
          <target state="translated">Strumień wejściowy audio.</target>       </trans-unit>
        <trans-unit id="523" translate="yes" xml:space="preserve">
          <source>The format of the audio input.</source>
          <target state="translated">Format wejście audio.</target>       </trans-unit>
        <trans-unit id="524" translate="yes" xml:space="preserve">
          <source>Configures the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> object to receive input from the default audio device.</source>
          <target state="translated">Konfiguruje <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> obiektu dla danych wejściowych z domyślnego urządzenia audio.</target>       </trans-unit>
        <trans-unit id="525" translate="yes" xml:space="preserve">
          <source>Disables the input to the speech recognizer.</source>
          <target state="translated">Wyłącza dane wejściowe do rozpoznawania mowy.</target>       </trans-unit>
        <trans-unit id="526" translate="yes" xml:space="preserve" extradata="MT">
          <source>Configure the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; object for no input when using the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt; and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt; methods, or when taking a recognition engine temporarily off line.</source>
          <target state="translated">Skonfiguruj &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;obiektu nie można wprowadzać przy użyciu &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;i &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;metody, lub w przypadku wykonywania aparatu rozpoznawania, tymczasowo wyłączony.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="527" translate="yes" xml:space="preserve">
          <source>Configures the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> object to receive input from a Waveform audio format (.wav) file.</source>
          <target state="translated">Konfiguruje <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> obiektu dla danych wejściowych z pliku fali format audio (wav).</target>       </trans-unit>
        <trans-unit id="528" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the recognizer reaches the end of the input file during a recognition operation, the recognition operation finalizes with the available input.</source>
          <target state="translated">Jeśli aparat rozpoznawania dociera do końca pliku wejściowego podczas operacji rozpoznawania, operacja rozpoznawania Kończenie znajdujących się przy użyciu dostępnych danych wejściowych.</target>       </trans-unit>
        <trans-unit id="529" translate="yes" xml:space="preserve" extradata="MT">
          <source>Any subsequent recognition operations can generate an exception, unless you update the input to the recognizer.</source>
          <target state="translated">Żadnych operacji rozpoznawania kolejnych może wygenerować wyjątek, chyba że aktualizacji danych wejściowych dla aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="530" translate="yes" xml:space="preserve">
          <source>The path of the file to use as input.</source>
          <target state="translated">Ścieżka pliku do użycia jako dane wejściowe.</target>       </trans-unit>
        <trans-unit id="531" translate="yes" xml:space="preserve">
          <source>Configures the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> object to receive input from a stream that contains Waveform audio format (.wav) data.</source>
          <target state="translated">Konfiguruje <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> obiektu dla danych wejściowych z strumienia, który zawiera dane przebiegu format audio (wav).</target>       </trans-unit>
        <trans-unit id="532" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the recognizer reaches the end of the input stream during a recognition operation, the recognition operation finalizes with the available input.</source>
          <target state="translated">Jeśli aparat rozpoznawania osiągnie koniec strumienia wejściowego podczas operacji rozpoznawania, operacja rozpoznawania Kończenie znajdujących się przy użyciu dostępnych danych wejściowych.</target>       </trans-unit>
        <trans-unit id="533" translate="yes" xml:space="preserve" extradata="MT">
          <source>Any subsequent recognition operations can generate an exception, unless you update the input to the recognizer.</source>
          <target state="translated">Żadnych operacji rozpoznawania kolejnych może wygenerować wyjątek, chyba że aktualizacji danych wejściowych dla aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="534" translate="yes" xml:space="preserve">
          <source>The stream containing the audio data.</source>
          <target state="translated">Strumień, zawierający dane audio.</target>       </trans-unit>
        <trans-unit id="535" translate="yes" xml:space="preserve">
          <source>Raised when the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> detects input that it can identify as speech.</source>
          <target state="translated">Wywoływane, gdy <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> wykrywa danych wejściowych, którą można zidentyfikować jako mowy.</target>       </trans-unit>
        <trans-unit id="536" translate="yes" xml:space="preserve" extradata="MT">
          <source>Each speech recognizer has an algorithm to distinguish between silence and speech.</source>
          <target state="translated">Każdy aparat rozpoznawania mowy zawiera algorytm odróżnić wyciszenia mowy.</target>       </trans-unit>
        <trans-unit id="537" translate="yes" xml:space="preserve" extradata="MT">
          <source>When the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; performs a speech recognition operation, it raises the SpeechDetected event when its algorithm identifies the input as speech.</source>
          <target state="translated">Gdy &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;wykonuje operację rozpoznawania mowy zgłasza zdarzenie SpeechDetected, gdy jego algorytmu identyfikuje danych wejściowych jako mowy.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="538" translate="yes" xml:space="preserve" extradata="MT">
          <source>The &lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A&gt; property of the associated &lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs&gt; object indicates location in the input stream where the recognizer detected speech.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A&gt;Właściwości skojarzonego &lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs&gt;obiektu wskazuje lokalizację, w przypadku wykrycia przez aparat rozpoznawania mowy strumień wejściowy.&lt;/xref:System.Speech.Recognition.SpeechDetectedEventArgs&gt; &lt;/xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A&gt;</target>       </trans-unit>
        <trans-unit id="539" translate="yes" xml:space="preserve" extradata="MT">
          <source>The &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; raises the SpeechDetected event before it raises any of the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;, or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; events.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;Wywołuje zdarzenie SpeechDetected przed zgłasza żadnego z &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;, lub &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt;zdarzeń.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="540" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information see the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt; methods.</source>
          <target state="translated">Aby uzyskać więcej informacji, zobacz &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;, i &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</target>       </trans-unit>
        <trans-unit id="541" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create a SpeechDetected delegate, you identify the method that will handle the event.</source>
          <target state="translated">Podczas tworzenia delegata SpeechDetected, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="542" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="543" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływana, gdy wystąpi zdarzenie, o ile nie usuniesz delegata.</target>       </trans-unit>
        <trans-unit id="544" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="545" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">Do dodania.</target>       </trans-unit>
        <trans-unit id="546" translate="yes" xml:space="preserve">
          <source>Raised when the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> has recognized a word or words that may be a component of multiple complete phrases in a grammar.</source>
          <target state="translated">Wywoływane, gdy <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> rozpoznał wyrazów, które mogą być składnika wiele wyrażeń pełną w gramatyce.</target>       </trans-unit>
        <trans-unit id="547" translate="yes" xml:space="preserve" extradata="MT">
          <source>The &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; generates numerous SpeechHypothesized events as it attempts to identify an input phrase.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;Generuje wiele zdarzeń SpeechHypothesized jako podejmie próbę identyfikacji wyrażenie wejściowe.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="548" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can access the text of partially recognized phrases in the &lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt; property of the &lt;xref:System.Speech.Recognition.SpeechHypothesizedEventArgs&gt; object in the handler for the SpeechHypothesized event.</source>
          <target state="translated">Dostęp można uzyskać tekstu częściowo rozpoznanym fraz w &lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;właściwości &lt;xref:System.Speech.Recognition.SpeechHypothesizedEventArgs&gt;obiekt obsługi dla zdarzenia SpeechHypothesized.&lt;/xref:System.Speech.Recognition.SpeechHypothesizedEventArgs&gt; &lt;/xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</target>       </trans-unit>
        <trans-unit id="549" translate="yes" xml:space="preserve" extradata="MT">
          <source>Typically, handling these events is useful only for debugging.</source>
          <target state="translated">Obsługa tych zdarzeń jest zazwyczaj przydatne tylko w przypadku debugowania.</target>       </trans-unit>
        <trans-unit id="550" translate="yes" xml:space="preserve" extradata="MT">
          <source>&lt;xref:System.Speech.Recognition.SpeechHypothesizedEventArgs&gt; derives from &lt;xref:System.Speech.Recognition.RecognitionEventArgs&gt;.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.SpeechHypothesizedEventArgs&gt;pochodną &lt;xref:System.Speech.Recognition.RecognitionEventArgs&gt;.&lt;/xref:System.Speech.Recognition.RecognitionEventArgs&gt;&lt;/xref:System.Speech.Recognition.SpeechHypothesizedEventArgs&gt;</target>       </trans-unit>
        <trans-unit id="551" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information see the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt; property and the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt; methods.</source>
          <target state="translated">Aby uzyskać więcej informacji, zobacz &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;Właściwości i &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt;, i &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;</target>       </trans-unit>
        <trans-unit id="552" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create a SpeechHypothesized delegate, you identify the method that will handle the event.</source>
          <target state="translated">Podczas tworzenia delegata SpeechHypothesized, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="553" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="554" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływana, gdy wystąpi zdarzenie, o ile nie usuniesz delegata.</target>       </trans-unit>
        <trans-unit id="555" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="556" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">Do dodania.</target>       </trans-unit>
        <trans-unit id="557" translate="yes" xml:space="preserve">
          <source>Raised when the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> receives input that does not match any of its loaded and enabled <bpt id="p2">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt><ept id="p2">&lt;/xref&gt;</ept> objects.</source>
          <target state="translated">Wywoływane, gdy <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> odbiera dane wejściowe, który nie pasuje do żadnego załadowany i włączone <bpt id="p2">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt> <ept id="p2">&lt;/xref&gt;</ept> obiektów.</target>       </trans-unit>
        <trans-unit id="558" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer raises this event if it determines that input does not match with sufficient confidence any of its loaded and enabled &lt;xref:System.Speech.Recognition.Grammar&gt; objects.</source>
          <target state="translated">Aparat rozpoznawania zgłasza to zdarzenie, gdy ustali, że dane wejściowe nie jest zgodna z wystarczający poziom zaufania załadowany i włączone &lt;xref:System.Speech.Recognition.Grammar&gt;obiektów.&lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="559" translate="yes" xml:space="preserve" extradata="MT">
          <source>The &lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt; property of the &lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; contains the rejected &lt;xref:System.Speech.Recognition.RecognitionResult&gt; object.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;Właściwość &lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;zawiera odrzucone &lt;xref:System.Speech.Recognition.RecognitionResult&gt;obiektu.&lt;/xref:System.Speech.Recognition.RecognitionResult&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; &lt;/xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</target>       </trans-unit>
        <trans-unit id="560" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can use the handler for the SpeechRecognitionRejected event to retrieve recognition &lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt; that were rejected and their &lt;xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A&gt; scores.</source>
          <target state="translated">Można użyć programu obsługi zdarzeń SpeechRecognitionRejected można pobrać rozpoznawania &lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;które zostały odrzucone i ich &lt;xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A&gt;wyniki.&lt;/xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A&gt; &lt;/xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</target>       </trans-unit>
        <trans-unit id="561" translate="yes" xml:space="preserve" extradata="MT">
          <source>If your application is using a &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; instance, you can modify the confidence level at which speech input is accepted or rejected with one of the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt; methods.</source>
          <target state="translated">Jeśli aplikacja korzysta &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;wystąpienia, można zmodyfikować poziom ufności, w których mowy danych wejściowych jest zaakceptowane lub odrzucone z jednym z &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="562" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can modify how the speech recognition responds to non-speech input using the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt; properties.</source>
          <target state="translated">Można zmodyfikować sposób rozpoznawania mowy odpowiadania na nie mowy przy użyciu &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;, i &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;Właściwości.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</target>       </trans-unit>
        <trans-unit id="563" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create a SpeechRecognitionRejected delegate, you identify the method that will handle the event.</source>
          <target state="translated">Podczas tworzenia delegata SpeechRecognitionRejected, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="564" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="565" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływana, gdy wystąpi zdarzenie, o ile nie usuniesz delegata.</target>       </trans-unit>
        <trans-unit id="566" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="567" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">Do dodania.</target>       </trans-unit>
        <trans-unit id="568" translate="yes" xml:space="preserve">
          <source>Raised when the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> receives input that matches any of its loaded and enabled <bpt id="p2">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt><ept id="p2">&lt;/xref&gt;</ept> objects.</source>
          <target state="translated">Wywoływane, gdy <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> odbiera wejścia odpowiadającego załadowany i włączone <bpt id="p2">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt> <ept id="p2">&lt;/xref&gt;</ept> obiektów.</target>       </trans-unit>
        <trans-unit id="569" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can initiate a recognition operation using the one of the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt; methods.</source>
          <target state="translated">Możesz zainicjować operacji rozpoznawania, przy użyciu jednej z &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;lub &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A&gt;</target>       </trans-unit>
        <trans-unit id="570" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer raises the SpeechRecognized event if it determines that input matches one of its loaded &lt;xref:System.Speech.Recognition.Grammar&gt; objects with a sufficient level of confidence to constitute recognition.</source>
          <target state="translated">Aparat rozpoznawania wywołuje zdarzenie SpeechRecognized, gdy ustali, że danych wejściowych odpowiada jednej z jej załadować &lt;xref:System.Speech.Recognition.Grammar&gt;obiekty o wystarczający poziom ufności stanowić rozpoznawania.&lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="571" translate="yes" xml:space="preserve" extradata="MT">
          <source>The &lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt; property of the &lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; contains the accepted &lt;xref:System.Speech.Recognition.RecognitionResult&gt; object.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;Właściwość &lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;zawiera zaakceptowane &lt;xref:System.Speech.Recognition.RecognitionResult&gt;obiektu.&lt;/xref:System.Speech.Recognition.RecognitionResult&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; &lt;/xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</target>       </trans-unit>
        <trans-unit id="572" translate="yes" xml:space="preserve" extradata="MT">
          <source>Handlers of SpeechRecognized events can obtain the recognized phrase as well as a list of recognition &lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt; with lower confidence scores.</source>
          <target state="translated">Programy obsługi zdarzeń SpeechRecognized można uzyskać rozpoznaną frazę, a także listę rozpoznawania &lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;z niższym wyniki zaufania.&lt;/xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</target>       </trans-unit>
        <trans-unit id="573" translate="yes" xml:space="preserve" extradata="MT">
          <source>If your application is using a &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; instance, you can modify the confidence level at which speech input is accepted or rejected with one of the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt; methods.</source>
          <target state="translated">Jeśli aplikacja korzysta &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;wystąpienia, można zmodyfikować poziom ufności, w których mowy danych wejściowych jest zaakceptowane lub odrzucone z jednym z &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="574" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can modify how the speech recognition responds to non-speech input using the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt; properties.</source>
          <target state="translated">Można zmodyfikować sposób rozpoznawania mowy odpowiadania na nie mowy przy użyciu &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt;, i &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt;Właściwości.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A&gt;</target>       </trans-unit>
        <trans-unit id="575" translate="yes" xml:space="preserve" extradata="MT">
          <source>When the recognizer receives input that matches a grammar, the &lt;xref:System.Speech.Recognition.Grammar&gt; object can raise its &lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt; event.</source>
          <target state="translated">Gdy aparat rozpoznawania otrzymuje wejścia odpowiadającego gramatyki, &lt;xref:System.Speech.Recognition.Grammar&gt;obiektu może wiązać się z jego &lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;zdarzeń.&lt;/xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt; &lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="576" translate="yes" xml:space="preserve" extradata="MT">
          <source>The &lt;xref:System.Speech.Recognition.Grammar&gt; object's &lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt; event is raised prior to the speech recognizer's SpeechRecognized event.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.Grammar&gt;Obiektu &lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;zdarzenie jest wywoływane przed zdarzeń SpeechRecognized rozpoznawania mowy.&lt;/xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt; &lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="577" translate="yes" xml:space="preserve" extradata="MT">
          <source>Any tasks specific to a particular grammar should always be performed by a handler for the &lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt; event.</source>
          <target state="translated">Wszystkie zadania, które są specyficzne dla konkretnego gramatyki zawsze powinny być wykonywane przez program obsługi &lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;zdarzeń.&lt;/xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</target>       </trans-unit>
        <trans-unit id="578" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create a SpeechRecognized delegate, you identify the method that will handle the event.</source>
          <target state="translated">Podczas tworzenia delegata SpeechRecognized, należy określić metodę, która obsłuży zdarzenie.</target>       </trans-unit>
        <trans-unit id="579" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Aby skojarzyć zdarzenie z obsługi zdarzenia, należy dodać wystąpienia delegata zdarzenia.</target>       </trans-unit>
        <trans-unit id="580" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Program obsługi zdarzeń jest wywoływana, gdy wystąpi zdarzenie, o ile nie usuniesz delegata.</target>       </trans-unit>
        <trans-unit id="581" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Aby uzyskać więcej informacji na temat delegatów obsługi zdarzeń, zobacz <bpt id="p1">[</bpt>zdarzenia i delegatów<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="582" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">Do dodania.</target>       </trans-unit>
        <trans-unit id="583" translate="yes" xml:space="preserve">
          <source>Unloads all <bpt id="p1">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> objects from the recognizer.</source>
          <target state="translated">Zwalnia wszystkie <bpt id="p1">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> obiektów z aparatu rozpoznawania.</target>       </trans-unit>
        <trans-unit id="584" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the recognizer is currently loading a &lt;xref:System.Speech.Recognition.Grammar&gt; asynchronously, this method waits until the &lt;xref:System.Speech.Recognition.Grammar&gt; is loaded, before it unloads all of the &lt;xref:System.Speech.Recognition.Grammar&gt; objects from the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; instance.</source>
          <target state="translated">Aparat rozpoznawania jest obecnie ładowania &lt;xref:System.Speech.Recognition.Grammar&gt;asynchronicznie, ta metoda będzie czekać &lt;xref:System.Speech.Recognition.Grammar&gt;został załadowany, zanim wszystkie zwalnia &lt;xref:System.Speech.Recognition.Grammar&gt;obiektów z &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;wystąpienia.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; &lt;/xref:System.Speech.Recognition.Grammar&gt; &lt;/xref:System.Speech.Recognition.Grammar&gt; &lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="585" translate="yes" xml:space="preserve" extradata="MT">
          <source>To unload a specific grammar, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A&gt; method.</source>
          <target state="translated">Aby zwolnić określonego gramatyki, użyj &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A&gt;</target>       </trans-unit>
        <trans-unit id="586" translate="yes" xml:space="preserve">
          <source>Unloads a specified <bpt id="p1">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> object from the <bpt id="p2">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p2">&lt;/xref&gt;</ept> instance.</source>
          <target state="translated">Zwalnia określony <bpt id="p1">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> obiekt z <bpt id="p2">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p2">&lt;/xref&gt;</ept> wystąpienia.</target>       </trans-unit>
        <trans-unit id="587" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the recognizer is running, applications must use &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt; to pause the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; instance before loading, unloading,  enabling, or disabling a &lt;xref:System.Speech.Recognition.Grammar&gt; object.</source>
          <target state="translated">Jeśli aparat rozpoznawania jest uruchomiona, aplikacje muszą używać &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;wstrzymania &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;wystąpienia przed ładowania, zwalnianie, włączanie lub wyłączanie &lt;xref:System.Speech.Recognition.Grammar&gt;obiektu.&lt;/xref:System.Speech.Recognition.Grammar&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A&gt;</target>       </trans-unit>
        <trans-unit id="588" translate="yes" xml:space="preserve" extradata="MT">
          <source>To unload all &lt;xref:System.Speech.Recognition.Grammar&gt; objects, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A&gt; method.</source>
          <target state="translated">Aby zwolnić wszystkie &lt;xref:System.Speech.Recognition.Grammar&gt;obiektów, użyj &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A&gt;metody.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A&gt; &lt;/xref:System.Speech.Recognition.Grammar&gt;</target>       </trans-unit>
        <trans-unit id="589" translate="yes" xml:space="preserve">
          <source>The grammar object to unload.</source>
          <target state="translated">Obiekt gramatyki do zwolnienia.</target>       </trans-unit>
        <trans-unit id="590" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;Grammar&lt;/code&gt;</ph> is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;Grammar&lt;/code&gt;</ph>is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="591" translate="yes" xml:space="preserve">
          <source>The grammar is not loaded in this recognizer, or this recognizer is currently loading the grammar asynchronously.</source>
          <target state="translated">Gramatyka nie został załadowany w tego aparatu rozpoznawania, lub tego aparatu rozpoznawania obecnie trwa ładowanie gramatyki asynchronicznie.</target>       </trans-unit>
        <trans-unit id="592" translate="yes" xml:space="preserve">
          <source>Updates the specified setting for the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> with the specified integer value.</source>
          <target state="translated">Aktualizuje określony ustawienie <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> z określonej liczby całkowitej.</target>       </trans-unit>
        <trans-unit id="593" translate="yes" xml:space="preserve" extradata="MT">
          <source>With the exception of <ph id="ph1">`PersistedBackgroundAdaptation`</ph>, property values set using the UpdateRecognizerSetting method remain in effect only for the current instance of &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;, after which they revert to their default settings.</source>
          <target state="translated">Z wyjątkiem produktów <ph id="ph1">`PersistedBackgroundAdaptation`</ph>, wartości właściwości ustawione za pomocą metody UpdateRecognizerSetting pozostaną aktywne tylko dla bieżącego wystąpienia elementu &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;, po którym one przywrócone do ich domyślnych ustawień.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="594" translate="yes" xml:space="preserve" extradata="MT">
          <source>See &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt; for descriptions of supported settings.</source>
          <target state="translated">Zobacz &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;opisy obsługiwanych ustawień.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</target>       </trans-unit>
        <trans-unit id="595" translate="yes" xml:space="preserve">
          <source>The name of the setting to update.</source>
          <target state="translated">Nazwa ustawienia do aktualizacji.</target>       </trans-unit>
        <trans-unit id="596" translate="yes" xml:space="preserve">
          <source>The new value for the setting.</source>
          <target state="translated">Nowa wartość ustawienia.</target>       </trans-unit>
        <trans-unit id="597" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;settingName&lt;/code&gt;</ph> is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;settingName&lt;/code&gt;</ph>is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="598" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;settingName&lt;/code&gt;</ph> is the empty string ("").</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;settingName&lt;/code&gt;</ph>jest pustym ciągiem ("").</target>       </trans-unit>
        <trans-unit id="599" translate="yes" xml:space="preserve">
          <source>The recognizer does not have a setting by that name.</source>
          <target state="translated">Aparat rozpoznawania nie ma ustawienie o takiej nazwie.</target>       </trans-unit>
        <trans-unit id="600" translate="yes" xml:space="preserve">
          <source>Updates the specified speech recognition engine setting with the specified string value.</source>
          <target state="translated">Aktualizuje ustawienia aparatu rozpoznawania mowy określonego określona wartość ciągu.</target>       </trans-unit>
        <trans-unit id="601" translate="yes" xml:space="preserve" extradata="MT">
          <source>With the exception of <ph id="ph1">`PersistedBackgroundAdaptation`</ph>, property values set using the UpdateRecognizerSetting method remain in effect only for the current instance of &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;, after which they revert to their default settings.</source>
          <target state="translated">Z wyjątkiem produktów <ph id="ph1">`PersistedBackgroundAdaptation`</ph>, wartości właściwości ustawione za pomocą metody UpdateRecognizerSetting pozostaną aktywne tylko dla bieżącego wystąpienia elementu &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;, po którym one przywrócone do ich domyślnych ustawień.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</target>       </trans-unit>
        <trans-unit id="602" translate="yes" xml:space="preserve" extradata="MT">
          <source>See &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt; for descriptions of supported settings.</source>
          <target state="translated">Zobacz &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;opisy obsługiwanych ustawień.&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A&gt;</target>       </trans-unit>
        <trans-unit id="603" translate="yes" xml:space="preserve">
          <source>The name of the setting to update.</source>
          <target state="translated">Nazwa ustawienia do aktualizacji.</target>       </trans-unit>
        <trans-unit id="604" translate="yes" xml:space="preserve">
          <source>The new value for the setting.</source>
          <target state="translated">Nowa wartość ustawienia.</target>       </trans-unit>
        <trans-unit id="605" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;settingName&lt;/code&gt;</ph> is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;settingName&lt;/code&gt;</ph>is <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>.</target>       </trans-unit>
        <trans-unit id="606" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;code&gt;settingName&lt;/code&gt;</ph> is the empty string ("").</source>
          <target state="translated"><ph id="ph1">&lt;code&gt;settingName&lt;/code&gt;</ph>jest pustym ciągiem ("").</target>       </trans-unit>
        <trans-unit id="607" translate="yes" xml:space="preserve">
          <source>The recognizer does not have a setting by that name.</source>
          <target state="translated">Aparat rozpoznawania nie ma ustawienie o takiej nazwie.</target>       </trans-unit>
      </group>
    </body>
  </file>
</xliff>