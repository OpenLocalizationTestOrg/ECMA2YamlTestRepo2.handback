<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.2" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="markdown" source-language="en-US" target-language="ja-jp">
    <header>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-192e1fd" tool-company="Microsoft" />
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">e644b88ade56f2c212e4da289a3165c87b0b7af8</xliffext:olfilehash>
      <xliffext:olfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">fulldocset\System.Speech.Recognition.SpeechRecognizer.yml</xliffext:olfilepath>
      <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">fulldocset</xliffext:oltranslationpriority>
      <xliffext:oltranslationtype xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">Human Translation</xliffext:oltranslationtype>
      <xliffext:olskeletonhash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">7e1e5ba2d559365c304779099905f94d66a88567</xliffext:olskeletonhash>
      <xliffext:olxliffhash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">d9f7993b11e2daa554a9769be3ed5465712c19c9</xliffext:olxliffhash>
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Provides access to the shared speech recognition service available on the Windows desktop.</source>
          <target state="translated">Windows デスクトップで使用可能な共有音声認識サービスへのアクセスを提供します。</target>       </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Applications use the shared recognizer to access Windows Speech Recognition.</source>
          <target state="translated">アプリケーションは、Windows 音声認識にアクセスするのに、共有認識エンジンを使用します。</target>       </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Use the SpeechRecognizer object to add to the Windows speech user experience.</source>
          <target state="translated">Windows 音声ユーザー エクスペリエンスに追加するには、れている SpeechRecognizer オブジェクトを使用します。</target>       </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>This class provides control over various aspects of the speech recognition process:      -   To manage speech recognition grammars, use the &lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A&gt;.</source>
          <target state="translated">このクラスは、音声認識プロセスのさまざまな側面を制御しますを使用して、音声認識の文法を管理する、 &lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A&gt;、 &lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;、 &lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A&gt;、 &lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A&gt;、 &lt;xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A&gt;。&lt;/xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A&gt; 。</target>       </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>-   To get information about current speech recognition operations, subscribe to the SpeechRecognizer’s &lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt; events.</source>
          <target state="translated">、認識操作を現在の音声に関する情報を取得するにはサブスクライブれている SpeechRecognizer の&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;、 &lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;、 &lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;、および&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;イベント&lt;/xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;。</target>       </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>-   To view or modify the number of alternate results the recognizer returns, use the &lt;xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A&gt; property.</source>
          <target state="translated">表示または変更、認識エンジンが返す代替結果の数、使用、&lt;xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A&gt;プロパティ&lt;/xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A&gt;。</target>       </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>The recognizer returns recognition results in a &lt;xref:System.Speech.Recognition.RecognitionResult&gt; object.</source>
          <target state="translated">認識エンジンで認識の結果が返されます、&lt;xref:System.Speech.Recognition.RecognitionResult&gt;オブジェクト&lt;/xref:System.Speech.Recognition.RecognitionResult&gt;。</target>       </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>-   To access or monitor the state of the shared recognizer, use the &lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt; properties and the &lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt; events.</source>
          <target state="translated">-にアクセスしたり、共有認識エンジンの状態を監視、使用、 &lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;、 &lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;、 &lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;、 &lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;、 &lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;、 &lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;、および&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;プロパティおよび&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated&gt;、 &lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred&gt;、 &lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged&gt;、および&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;イベント&lt;/xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;。</target>       </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>-   To synchronize changes to the recognizer, use the &lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt; method.</source>
          <target state="translated">、認識エンジンへの変更を同期するには使用、&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;メソッド&lt;/xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;。</target>       </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>The shared recognizer uses more than one thread to perform tasks.</source>
          <target state="translated">共有認識エンジンでは、複数のスレッドを使用して、タスクを実行します。</target>       </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>-   To emulate input to the shared recognizer, use the &lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt; and &lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt; methods.</source>
          <target state="translated">-エミュレートするために、共有認識エンジンへの入力を使用して、&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;と&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;メソッド&lt;/xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;。</target>       </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>The configuration of Windows Speech Recognition is managed by the use of the <bpt id="p1">**</bpt>Speech Properties<ept id="p1">**</ept> dialog in the <bpt id="p2">**</bpt>Control Panel<ept id="p2">**</ept>.</source>
          <target state="translated">Windows 音声認識の構成が使用することで管理されている、<bpt id="p1">**</bpt>音声プロパティ<ept id="p1">**</ept>] ダイアログ ボックス、<bpt id="p2">**</bpt>コントロール パネルの [<ept id="p2">**</ept>です。</target>       </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>This interface is used to select the default desktop speech recognition engine and language, the audio input device, and the sleep behavior of speech recognition.</source>
          <target state="translated">このインターフェイスを使用すると、既定のデスクトップの音声認識エンジンと言語、オーディオ入力デバイス、および音声認識のスリープ状態の動作を選択します。</target>       </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>If the configuration of Windows Speech Recognition is changed while the application is running, (for instance, if speech recognition is disabled or the input language is changed), the change affects all SpeechRecognizer objects.</source>
          <target state="translated">アプリケーションの実行中に、(たとえば、音声認識が無効か、入力言語が変更された) Windows 音声認識の構成が変更された場合、変更はすべてれている SpeechRecognizer オブジェクトに影響します。</target>       </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>To create an in-process speech recognizer that is independent of Windows Speech Recognition, use the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; class.</source>
          <target state="translated">Windows 音声認識から独立しているプロセスで音声認識エンジンを作成するには、&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;クラス&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;を使用します。</target>       </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>&gt; <ph id="ph1">[!NOTE]</ph> &gt;  Always call &lt;xref:System.Speech.Recognition.SpeechRecognizer.Dispose%2A&gt; before you release your last reference to the speech recognizer.</source>
          <target state="translated">&gt; <ph id="ph1">[!NOTE]</ph> &gt; 常に呼び出し&lt;xref:System.Speech.Recognition.SpeechRecognizer.Dispose%2A&gt;音声認識エンジンへの参照を解放する前にします&lt;/xref:System.Speech.Recognition.SpeechRecognizer.Dispose%2A&gt;。</target>       </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>Otherwise, the resources it is using will not be freed until the garbage collector calls the recognizer object's <ph id="ph1">`Finalize`</ph> method.</source>
          <target state="translated">それ以外の場合、使用されているリソースは解放されませんガベージ コレクターは、認識エンジン オブジェクトのまで<ph id="ph1">`Finalize`</ph>メソッドです。</target>       </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Initializes a new instance of the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognizer"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> class.</source>
          <target state="translated">新しいインスタンスを初期化、 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognizer"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept>クラスです。</target>       </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>Each &lt;xref:System.Speech.Recognition.SpeechRecognizer&gt; object maintains a separate set of speech recognition grammars.</source>
          <target state="translated">各&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;オブジェクトが別の音声認識の文法のセットを保持します&lt;/xref:System.Speech.Recognition.SpeechRecognizer&gt;。</target>       </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>Gets the format of the audio being received by the speech recognizer.</source>
          <target state="translated">音声認識エンジンによって受信されるオーディオの形式を取得します。</target>       </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>The audio input format for the speech recognizer, or <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> if the input to the recognizer is not configured.</source>
          <target state="translated">音声認識では、オーディオ入力フォーマットまたは<bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>認識エンジンへの入力が構成されていない場合。</target>       </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>Gets the level of the audio being received by the speech recognizer.</source>
          <target state="translated">音声認識エンジンによって受信されるオーディオのレベルを取得します。</target>       </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>The audio level of the input to the speech recognizer, from 0 through 100.</source>
          <target state="translated">入力、音声認識では、0 ~ 100 のオーディオ レベル。</target>       </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Occurs when the shared recognizer reports the level of its audio input.</source>
          <target state="translated">共有認識エンジンは、オーディオ入力のレベルを報告したときに発生します。</target>       </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>The recognizer raises this event multiple times per second.</source>
          <target state="translated">認識エンジンは、1 秒間に複数回、このイベントを発生させます。</target>       </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>The frequency with which the event is raised depends on the computer on which the application is running.</source>
          <target state="translated">イベントが発生する頻度は、アプリケーションが実行されているコンピューターによって異なります。</target>       </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>To get the audio level at the time of the event, use the &lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A&gt; property of the associated &lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt;.</source>
          <target state="translated">イベントの時点で、オーディオ レベルを取得するには、&lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A&gt;関連付けられている&lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt;。&lt;/xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt;のプロパティ&lt;/xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A&gt;を使用します。</target>       </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>To get the current audio level of the input to the recognizer, use the recognizer's &lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt; property.</source>
          <target state="translated">認識エンジンへの入力の現在のオーディオ レベルを取得するには、認識エンジンを使用&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;プロパティ&lt;/xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;。</target>       </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>When you create a delegate for an <ph id="ph1">`AudioLevelUpdated`</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">デリゲートを作成する場合、<ph id="ph1">`AudioLevelUpdated`</ph>イベント、イベントを処理するメソッドを指定します。</target>       </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">イベントをイベント ハンドラーに関連付けるには、イベントに、デリゲートのインスタンスを追加します。</target>       </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">デリゲートを削除しない限り、イベントが発生するたびに、イベント ハンドラーが呼び出されます。</target>       </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">イベント ハンドラー デリゲートの詳細については、次を参照してください。<bpt id="p1">[</bpt>イベントとデリゲート<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>です。</target>       </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">追加します。</target>       </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>Gets the current location in the audio stream being generated by the device that is providing input to the speech recognizer.</source>
          <target state="translated">音声認識エンジンへの入力を提供しているデバイスによって生成されるオーディオ ストリームの現在の場所を取得します。</target>       </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>The shared recognizer receives input while the desktop speech recognition is running.</source>
          <target state="translated">デスクトップの音声認識が実行中に、共有認識エンジンは入力を受け取ります。</target>       </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>The <ph id="ph1">`AudioPosition`</ph> property references the input device's position in its generated audio stream.</source>
          <target state="translated"><ph id="ph1">`AudioPosition`</ph>プロパティは、生成されたオーディオ ストリーム内の入力デバイスの位置を参照します。</target>       </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>By contrast, the &lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt; property references the recognizer's position in processing audio input.</source>
          <target state="translated">これに対し、&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;プロパティは、オーディオ入力の処理の認識エンジンの位置を参照します&lt;/xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;。</target>       </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>These positions can be different.</source>
          <target state="translated">これらの位置は別にすることはできます。</target>       </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>For example, if the recognizer has received input for which it has not yet generated a recognition result then the value of the &lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt; property is less than the value of the AudioPosition property.</source>
          <target state="translated">たとえば、認識エンジンが受信した場合どの it されていない入力が、認識結果が次の値を生成、&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;プロパティが AudioPosition プロパティの値より小さい&lt;/xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;。</target>       </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>The current location in the speech recognizer's audio input stream through which it has received input.</source>
          <target state="translated">音声認識エンジンのオーディオの入力ストリームを使用する入力を受信した現在の場所。</target>       </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>Occurs when the recognizer encounters a problem in the audio signal.</source>
          <target state="translated">認識エンジンには、オーディオ信号に問題が発生したときに発生します。</target>       </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>To get which problem occurred, use the &lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A&gt; property of the associated &lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt;.</source>
          <target state="translated">どのような問題が発生しましたを取得するには、&lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A&gt;関連付けられている&lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt;。&lt;/xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt;のプロパティ&lt;/xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A&gt;を使用します。</target>       </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>When you create a delegate for an <ph id="ph1">`AudioSignalProblemOccurred`</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">デリゲートを作成する場合、<ph id="ph1">`AudioSignalProblemOccurred`</ph>イベント、イベントを処理するメソッドを指定します。</target>       </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">イベントをイベント ハンドラーに関連付けるには、イベントに、デリゲートのインスタンスを追加します。</target>       </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">デリゲートを削除しない限り、イベントが発生するたびに、イベント ハンドラーが呼び出されます。</target>       </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">イベント ハンドラー デリゲートの詳細については、次を参照してください。<bpt id="p1">[</bpt>イベントとデリゲート<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>です。</target>       </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">追加します。</target>       </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>Gets the state of the audio being received by the speech recognizer.</source>
          <target state="translated">音声認識エンジンによって受信されるオーディオの状態を取得します。</target>       </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>The state of the audio input to the speech recognizer.</source>
          <target state="translated">音声認識にオーディオの入力の状態。</target>       </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>Occurs when the state changes in the audio being received by the recognizer.</source>
          <target state="translated">オーディオの状態の変更は、認識エンジンによって受信されると発生します。</target>       </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>To get the audio state at the time of the event, use the &lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A&gt; property of the associated &lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs&gt;.</source>
          <target state="translated">イベントの時点でオーディオの状態を取得するには、&lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A&gt;関連付けられている&lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs&gt;。&lt;/xref:System.Speech.Recognition.AudioStateChangedEventArgs&gt;のプロパティ&lt;/xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A&gt;を使用します。</target>       </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>To get the current audio state of the input to the recognizer, use the recognizer's &lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt; property.</source>
          <target state="translated">認識エンジンへの入力の現在のオーディオ状態を取得するには、使用、認識エンジンの&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;プロパティ&lt;/xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;。</target>       </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>For more information about audio state, see the &lt;xref:System.Speech.Recognition.AudioState&gt; enumeration.</source>
          <target state="translated">オーディオの状態に関する詳細については、次を参照してください、&lt;xref:System.Speech.Recognition.AudioState&gt;列挙体です。&lt;/xref:System.Speech.Recognition.AudioState&gt; 。</target>       </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>When you create a delegate for an <ph id="ph1">`AudioStateChanged`</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">デリゲートを作成する場合、<ph id="ph1">`AudioStateChanged`</ph>イベント、イベントを処理するメソッドを指定します。</target>       </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">イベントをイベント ハンドラーに関連付けるには、イベントに、デリゲートのインスタンスを追加します。</target>       </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">デリゲートを削除しない限り、イベントが発生するたびに、イベント ハンドラーが呼び出されます。</target>       </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">イベント ハンドラー デリゲートの詳細については、次を参照してください。<bpt id="p1">[</bpt>イベントとデリゲート<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>です。</target>       </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">追加します。</target>       </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>Disposes the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognizer"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> object.</source>
          <target state="translated">破棄、 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognizer"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept>オブジェクト。</target>       </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>Disposes the <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognizer"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> object and releases resources used during the session.</source>
          <target state="translated">破棄、 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognizer"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept>オブジェクトおよびリリースのリソースが、セッション中に使用します。</target>       </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source><bpt id="p1">&lt;xref uid="langword_csharp_true" name="true" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> to release both managed and unmanaged resources; <bpt id="p2">&lt;xref uid="langword_csharp_false" name="false" href=""&gt;</bpt><ept id="p2">&lt;/xref&gt;</ept> to release only unmanaged resources.</source>
          <target state="translated"><bpt id="p1">&lt;xref uid="langword_csharp_true" name="true" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>マネージ コードとアンマネージ リソースを解放するには<bpt id="p2">&lt;xref uid="langword_csharp_false" name="false" href=""&gt;</bpt> <ept id="p2">&lt;/xref&gt;</ept>アンマネージ リソースだけを解放します。</target>       </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>Emulates input of a phrase to the shared speech recognizer, using text instead of audio for synchronous speech recognition.</source>
          <target state="translated">同期の音声認識のオーディオの代わりにテキストを使用して、共有音声認識エンジンに語句の入力をエミュレートします。</target>       </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>The recognizers that ship with Vista and Windows 7 ignore case and character width when applying grammar rules to the input phrase.</source>
          <target state="translated">Vista および Windows 7 に付属しているレコグナイザーは、大文字小文字を区別し、入力の語句に文法ルールを適用するときに幅を文字です。</target>       </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>For more information about this type of comparison, see the &lt;xref:System.Globalization.CompareOptions&gt; enumeration values &lt;xref:System.Globalization.CompareOptions&gt; and &lt;xref:System.Globalization.CompareOptions&gt;.</source>
          <target state="translated">この種類の比較の詳細については、参照して&lt;xref:System.Globalization.CompareOptions&gt;列挙の値&lt;xref:System.Globalization.CompareOptions&gt;と&lt;xref:System.Globalization.CompareOptions&gt;。&lt;/xref:System.Globalization.CompareOptions&gt; &lt;/xref:System.Globalization.CompareOptions&gt; &lt;/xref:System.Globalization.CompareOptions&gt;</target>       </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</source>
          <target state="translated">認識は、新しい行と余分な空白を無視し、リテラルの入力として句読点を扱います。</target>       </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>The input for the recognition operation.</source>
          <target state="translated">認識操作の入力です。</target>       </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>The recognition result for the recognition operation, or <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>, if the operation is not successful or Windows Speech Recognition is in the <bpt id="p2">**</bpt>Sleeping<ept id="p2">**</ept> state.</source>
          <target state="translated">認識操作の結果を認識または<bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept>Windows 音声認識は、操作が成功しなかった場合は、<bpt id="p2">**</bpt>休止中<ept id="p2">**</ept>状態です。</target>       </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>Emulates input of specific words to the shared speech recognizer, using text instead of audio for synchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the words and the loaded speech recognition grammars.</source>
          <target state="translated">オーディオの代わりに、同期の音声認識のテキストを使用して、共有音声認識に特定の単語の入力をエミュレートし、認識エンジンが単語と読み込まれた音声認識の文法で Unicode 比較を処理する方法を指定します。</target>       </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>This method creates a &lt;xref:System.Speech.Recognition.RecognitionResult&gt; object using the information provided in the <ph id="ph1">`wordUnits`</ph> parameter.</source>
          <target state="translated">このメソッドを作成、&lt;xref:System.Speech.Recognition.RecognitionResult&gt;オブジェクトで提供される情報を使用して、<ph id="ph1">`wordUnits`</ph>パラメーター&lt;/xref:System.Speech.Recognition.RecognitionResult&gt; 。</target>       </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>The recognizer uses the <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">認識エンジンを使用して、<ph id="ph1">`compareOptions`</ph>ときに適用される文法ルール語句を入力します。</target>       </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the &lt;xref:System.Globalization.CompareOptions&gt; or &lt;xref:System.Globalization.CompareOptions&gt; value is present.</source>
          <target state="translated">Vista および Windows 7 に付属しているレコグナイザーが場合は、大文字小文字を区別、&lt;xref:System.Globalization.CompareOptions&gt;または&lt;xref:System.Globalization.CompareOptions&gt;値が存在します&lt;/xref:System.Globalization.CompareOptions&gt;&lt;/xref:System.Globalization.CompareOptions&gt;。</target>       </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
          <target state="translated">認識は、常に文字幅を無視し、カナ型を無視することはありません。</target>       </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">レコグナイザーは、新しい行と余分な空白を無視する、リテラルの入力として区切り記号を扱います。</target>       </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>For more information about character width and Kana type, see the &lt;xref:System.Globalization.CompareOptions&gt; enumeration.</source>
          <target state="translated">詳細については、文字幅、ひらがなとカタカナは、次を参照してください、&lt;xref:System.Globalization.CompareOptions&gt;列挙体です。&lt;/xref:System.Globalization.CompareOptions&gt; 。</target>       </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>An array of word units that contains the input for the recognition operation.</source>
          <target state="translated">認識操作の入力が含まれている単語単位の配列。</target>       </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">エミュレートされた認識操作に使用する比較の種類を記述する列挙値のビットごとの組み合わせ。</target>       </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source>The recognition result for the recognition operation, or <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>, if the operation is not successful or Windows Speech Recognition is in the <bpt id="p2">**</bpt>Sleeping<ept id="p2">**</ept> state.</source>
          <target state="translated">認識操作の結果を認識または<bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept>Windows 音声認識は、操作が成功しなかった場合は、<bpt id="p2">**</bpt>休止中<ept id="p2">**</ept>状態です。</target>       </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source>Emulates input of a phrase to the shared speech recognizer, using text instead of audio for synchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the phrase and the loaded speech recognition grammars.</source>
          <target state="translated">オーディオの代わりに、同期の音声認識のテキストを使用して、共有音声認識エンジンに語句の入力をエミュレートし、認識エンジンが、語句と読み込まれた音声認識の文法で Unicode 比較を処理する方法を指定します。</target>       </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source>The recognizer uses the <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">認識エンジンを使用して、<ph id="ph1">`compareOptions`</ph>ときに適用される文法ルール語句を入力します。</target>       </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the &lt;xref:System.Globalization.CompareOptions&gt; or &lt;xref:System.Globalization.CompareOptions&gt; value is present.</source>
          <target state="translated">Vista および Windows 7 に付属しているレコグナイザーが場合は、大文字小文字を区別、&lt;xref:System.Globalization.CompareOptions&gt;または&lt;xref:System.Globalization.CompareOptions&gt;値が存在します&lt;/xref:System.Globalization.CompareOptions&gt;&lt;/xref:System.Globalization.CompareOptions&gt;。</target>       </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
          <target state="translated">認識は、常に文字幅を無視し、カナ型を無視することはありません。</target>       </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source>The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">レコグナイザーは、新しい行と余分な空白を無視する、リテラルの入力として区切り記号を扱います。</target>       </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source>For more information about character width and Kana type, see the &lt;xref:System.Globalization.CompareOptions&gt; enumeration.</source>
          <target state="translated">詳細については、文字幅、ひらがなとカタカナは、次を参照してください、&lt;xref:System.Globalization.CompareOptions&gt;列挙体です。&lt;/xref:System.Globalization.CompareOptions&gt; 。</target>       </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source>The input phrase for the recognition operation.</source>
          <target state="translated">認識操作の入力フレーズです。</target>       </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">エミュレートされた認識操作に使用する比較の種類を記述する列挙値のビットごとの組み合わせ。</target>       </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source>The recognition result for the recognition operation, or <bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>, if the operation is not successful or Windows Speech Recognition is in the <bpt id="p2">**</bpt>Sleeping<ept id="p2">**</ept> state.</source>
          <target state="translated">認識操作の結果を認識または<bpt id="p1">&lt;xref uid="langword_csharp_null" name="null" href=""&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept>Windows 音声認識は、操作が成功しなかった場合は、<bpt id="p2">**</bpt>休止中<ept id="p2">**</ept>状態です。</target>       </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve">
          <source>Emulates input of a phrase to the shared speech recognizer, using text instead of audio for asynchronous speech recognition.</source>
          <target state="translated">非同期の音声認識のオーディオの代わりにテキストを使用して、共有音声認識エンジンに語句の入力をエミュレートします。</target>       </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source>The recognizers that ship with Vista and Windows 7 ignore case and character width when applying grammar rules to the input phrase.</source>
          <target state="translated">Vista および Windows 7 に付属しているレコグナイザーは、大文字小文字を区別し、入力の語句に文法ルールを適用するときに幅を文字です。</target>       </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source>For more information about this type of comparison, see the &lt;xref:System.Globalization.CompareOptions&gt; enumeration values &lt;xref:System.Globalization.CompareOptions&gt; and &lt;xref:System.Globalization.CompareOptions&gt;.</source>
          <target state="translated">この種類の比較の詳細については、参照して&lt;xref:System.Globalization.CompareOptions&gt;列挙の値&lt;xref:System.Globalization.CompareOptions&gt;と&lt;xref:System.Globalization.CompareOptions&gt;。&lt;/xref:System.Globalization.CompareOptions&gt; &lt;/xref:System.Globalization.CompareOptions&gt; &lt;/xref:System.Globalization.CompareOptions&gt;</target>       </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve">
          <source>The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</source>
          <target state="translated">認識は、新しい行と余分な空白を無視し、リテラルの入力として句読点を扱います。</target>       </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve">
          <source>The input for the recognition operation.</source>
          <target state="translated">認識操作の入力です。</target>       </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve">
          <source>Emulates input of specific words to the shared speech recognizer, using text instead of audio for asynchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the words and the loaded speech recognition grammars.</source>
          <target state="translated">オーディオの代わりに、非同期の音声認識のテキストを使用して、共有音声認識に特定の単語の入力をエミュレートし、認識エンジンが単語と読み込まれた音声認識の文法で Unicode 比較を処理する方法を指定します。</target>       </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve">
          <source>This method creates a &lt;xref:System.Speech.Recognition.RecognitionResult&gt; object using the information provided in the <ph id="ph1">`wordUnits`</ph> parameter.</source>
          <target state="translated">このメソッドを作成、&lt;xref:System.Speech.Recognition.RecognitionResult&gt;オブジェクトで提供される情報を使用して、<ph id="ph1">`wordUnits`</ph>パラメーター&lt;/xref:System.Speech.Recognition.RecognitionResult&gt; 。</target>       </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve">
          <source>The recognizer uses the <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">認識エンジンを使用して、<ph id="ph1">`compareOptions`</ph>ときに適用される文法ルール語句を入力します。</target>       </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the &lt;xref:System.Globalization.CompareOptions&gt; or &lt;xref:System.Globalization.CompareOptions&gt; value is present.</source>
          <target state="translated">Vista および Windows 7 に付属しているレコグナイザーが場合は、大文字小文字を区別、&lt;xref:System.Globalization.CompareOptions&gt;または&lt;xref:System.Globalization.CompareOptions&gt;値が存在します&lt;/xref:System.Globalization.CompareOptions&gt;&lt;/xref:System.Globalization.CompareOptions&gt;。</target>       </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
          <target state="translated">認識は、常に文字幅を無視し、カナ型を無視することはありません。</target>       </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve">
          <source>The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">レコグナイザーは、新しい行と余分な空白を無視する、リテラルの入力として区切り記号を扱います。</target>       </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve">
          <source>For more information about character width and Kana type, see the &lt;xref:System.Globalization.CompareOptions&gt; enumeration.</source>
          <target state="translated">詳細については、文字幅、ひらがなとカタカナは、次を参照してください、&lt;xref:System.Globalization.CompareOptions&gt;列挙体です。&lt;/xref:System.Globalization.CompareOptions&gt; 。</target>       </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve">
          <source>An array of word units that contains the input for the recognition operation.</source>
          <target state="translated">認識操作の入力が含まれている単語単位の配列。</target>       </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">エミュレートされた認識操作に使用する比較の種類を記述する列挙値のビットごとの組み合わせ。</target>       </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve">
          <source>Emulates input of a phrase to the shared speech recognizer, using text instead of audio for asynchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the phrase and the loaded speech recognition grammars.</source>
          <target state="translated">オーディオの代わりに、非同期の音声認識のテキストを使用して、共有音声認識エンジンに語句の入力をエミュレートし、認識エンジンが、語句と読み込まれた音声認識の文法で Unicode 比較を処理する方法を指定します。</target>       </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve">
          <source>The recognizer uses the <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">認識エンジンを使用して、<ph id="ph1">`compareOptions`</ph>ときに適用される文法ルール語句を入力します。</target>       </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the &lt;xref:System.Globalization.CompareOptions&gt; or &lt;xref:System.Globalization.CompareOptions&gt; value is present.</source>
          <target state="translated">Vista および Windows 7 に付属しているレコグナイザーが場合は、大文字小文字を区別、&lt;xref:System.Globalization.CompareOptions&gt;または&lt;xref:System.Globalization.CompareOptions&gt;値が存在します&lt;/xref:System.Globalization.CompareOptions&gt;&lt;/xref:System.Globalization.CompareOptions&gt;。</target>       </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
          <target state="translated">認識は、常に文字幅を無視し、カナ型を無視することはありません。</target>       </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve">
          <source>The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">レコグナイザーは、新しい行と余分な空白を無視する、リテラルの入力として区切り記号を扱います。</target>       </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve">
          <source>For more information about character width and Kana type, see the &lt;xref:System.Globalization.CompareOptions&gt; enumeration.</source>
          <target state="translated">詳細については、文字幅、ひらがなとカタカナは、次を参照してください、&lt;xref:System.Globalization.CompareOptions&gt;列挙体です。&lt;/xref:System.Globalization.CompareOptions&gt; 。</target>       </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve">
          <source>The input phrase for the recognition operation.</source>
          <target state="translated">認識操作の入力フレーズです。</target>       </trans-unit>
        <trans-unit id="208" translate="yes" xml:space="preserve">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">エミュレートされた認識操作に使用する比較の種類を記述する列挙値のビットごとの組み合わせ。</target>       </trans-unit>
        <trans-unit id="209" translate="yes" xml:space="preserve">
          <source>Occurs when the shared recognizer finalizes an asynchronous recognition operation for emulated input.</source>
          <target state="translated">エミュレートされた入力に対して非同期認識操作の終了処理として、共有認識エンジンと発生します。</target>       </trans-unit>
        <trans-unit id="210" translate="yes" xml:space="preserve">
          <source>Each &lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt; method begins an asynchronous recognition operation.</source>
          <target state="translated">各&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;メソッドが非同期認識操作を開始します&lt;/xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;。</target>       </trans-unit>
        <trans-unit id="211" translate="yes" xml:space="preserve">
          <source>The recognizer raises the <ph id="ph1">`EmulateRecognizeCompleted`</ph> event when it finalizes the asynchronous operation.</source>
          <target state="translated">認識エンジンが発生し、<ph id="ph1">`EmulateRecognizeCompleted`</ph>非同期操作を終了したときにイベント。</target>       </trans-unit>
        <trans-unit id="212" translate="yes" xml:space="preserve">
          <source>The asynchronous recognition operation can raise the &lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;, &lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;, and &lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt; events.</source>
          <target state="translated">非同期の認識操作を発生させることができます、 &lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;、 &lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;、 &lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;、および&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;イベント&lt;/xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;。</target>       </trans-unit>
        <trans-unit id="213" translate="yes" xml:space="preserve">
          <source>The EmulateRecognizeCompleted event is the last such event that the recognizer raises for a given operation.</source>
          <target state="translated">EmulateRecognizeCompleted イベントが最後にそのようなイベントが、認識エンジンは、指定した操作を発生させます。</target>       </trans-unit>
        <trans-unit id="214" translate="yes" xml:space="preserve">
          <source>When you create a delegate for an <ph id="ph1">`EmulateRecognizeCompleted`</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">デリゲートを作成する場合、<ph id="ph1">`EmulateRecognizeCompleted`</ph>イベント、イベントを処理するメソッドを指定します。</target>       </trans-unit>
        <trans-unit id="215" translate="yes" xml:space="preserve">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">イベントをイベント ハンドラーに関連付けるには、イベントに、デリゲートのインスタンスを追加します。</target>       </trans-unit>
        <trans-unit id="216" translate="yes" xml:space="preserve">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">デリゲートを削除しない限り、イベントが発生するたびに、イベント ハンドラーが呼び出されます。</target>       </trans-unit>
        <trans-unit id="217" translate="yes" xml:space="preserve">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">イベント ハンドラー デリゲートの詳細については、次を参照してください。<bpt id="p1">[</bpt>イベントとデリゲート<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>です。</target>       </trans-unit>
        <trans-unit id="218" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">追加します。</target>       </trans-unit>
        <trans-unit id="219" translate="yes" xml:space="preserve">
          <source>Gets or sets a value that indicates whether this <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognizer"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> object is ready to process speech.</source>
          <target state="translated">取得または設定を示す値かどうかこの<bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognizer"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>オブジェクトが音声認識を処理できる状態にします。</target>       </trans-unit>
        <trans-unit id="220" translate="yes" xml:space="preserve">
          <source>Changes to this property do not affect other instances of the &lt;xref:System.Speech.Recognition.SpeechRecognizer&gt; class.</source>
          <target state="translated">このプロパティに対する変更、&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;クラス&lt;/xref:System.Speech.Recognition.SpeechRecognizer&gt;の他のインスタンスには影響しません</target>       </trans-unit>
        <trans-unit id="221" translate="yes" xml:space="preserve">
          <source>By default, the value of the Enabled property is <ph id="ph1">`true`</ph> for a newly instantiated instance of &lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;.</source>
          <target state="translated">既定では、Enabled プロパティの値は<ph id="ph1">`true`</ph> &lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;.&lt;/xref:System.Speech.Recognition.SpeechRecognizer&gt;の新しくインスタンス化されたインスタンス</target>       </trans-unit>
        <trans-unit id="222" translate="yes" xml:space="preserve">
          <source>While the recognizer is disabled, none of the recognizer's speech recognition grammars are available for recognition operations.</source>
          <target state="translated">認識エンジンが無効にしたままの認識エンジンの音声認識の文法は一切認識操作に使用できます。</target>       </trans-unit>
        <trans-unit id="223" translate="yes" xml:space="preserve">
          <source>Setting the recognizer's Enabled property has no effect on the recognizer's &lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt; property.</source>
          <target state="translated">認識エンジンの Enabled プロパティを設定しても認識エンジンの上無効&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;プロパティ&lt;/xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;。</target>       </trans-unit>
        <trans-unit id="224" translate="yes" xml:space="preserve">
          <source><bpt id="p1">&lt;xref uid="langword_csharp_true" name="true" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> if this <bpt id="p2">&lt;xref href="System.Speech.Recognition.SpeechRecognizer"&gt;</bpt><ept id="p2">&lt;/xref&gt;</ept> object is performing speech recognition; otherwise, <bpt id="p3">&lt;xref uid="langword_csharp_false" name="false" href=""&gt;</bpt><ept id="p3">&lt;/xref&gt;</ept>.</source>
          <target state="translated"><bpt id="p1">&lt;xref uid="langword_csharp_true" name="true" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>この場合<bpt id="p2">&lt;xref href="System.Speech.Recognition.SpeechRecognizer"&gt;</bpt><ept id="p2">&lt;/xref&gt;</ept>オブジェクトは音声認識を実行して、それ以外の<bpt id="p3">&lt;xref uid="langword_csharp_false" name="false" href=""&gt;</bpt><ept id="p3">&lt;/xref&gt;</ept>です。</target>       </trans-unit>
        <trans-unit id="225" translate="yes" xml:space="preserve">
          <source>Gets a collection of the <bpt id="p1">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> objects that are loaded in this <bpt id="p2">&lt;xref href="System.Speech.Recognition.SpeechRecognizer"&gt;</bpt><ept id="p2">&lt;/xref&gt;</ept> instance.</source>
          <target state="translated">コレクションを取得、 <bpt id="p1">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept>この読み込まれているオブジェクト<bpt id="p2">&lt;xref href="System.Speech.Recognition.SpeechRecognizer"&gt;</bpt><ept id="p2">&lt;/xref&gt;</ept>インスタンス。</target>       </trans-unit>
        <trans-unit id="226" translate="yes" xml:space="preserve">
          <source>This property does not return any speech recognition grammars loaded by another application.</source>
          <target state="translated">このプロパティは返されません、音声認識文法が別のアプリケーションによって読み込まれます。</target>       </trans-unit>
        <trans-unit id="227" translate="yes" xml:space="preserve">
          <source>A collection of the <bpt id="p1">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> objects that the application loaded into the current instance of the shared recognizer.</source>
          <target state="translated">コレクション、 <bpt id="p1">&lt;xref href="System.Speech.Recognition.Grammar"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept>共有認識エンジンの現在のインスタンスに、アプリケーションが読み込まれているオブジェクト。</target>       </trans-unit>
        <trans-unit id="228" translate="yes" xml:space="preserve">
          <source>Loads a speech recognition grammar.</source>
          <target state="translated">音声認識の文法が読み込まれます。</target>       </trans-unit>
        <trans-unit id="229" translate="yes" xml:space="preserve">
          <source>The shared recognizer throws an exception if the speech recognition grammar is already loaded, is being asynchronously loaded, or has failed to load into any recognizer.</source>
          <target state="translated">共有認識エンジンは、音声認識の文法が既に読み込まれて、非同期的に読み込まれる、またはがすべての認識エンジンに読み込めませんだった場合に例外をスローします。</target>       </trans-unit>
        <trans-unit id="230" translate="yes" xml:space="preserve">
          <source>If the recognizer is running, applications must use &lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt; to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
          <target state="translated">認識エンジンが実行されている場合、アプリケーションが使用する必要があります&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;を読み込み、アンロードが有効にすると、または、文法を無効にする前に、音声認識エンジンを一時停止します&lt;/xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;。</target>       </trans-unit>
        <trans-unit id="231" translate="yes" xml:space="preserve">
          <source>To load a speech recognition grammar asynchronously, use the &lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt; method.</source>
          <target state="translated">音声認識の文法を非同期的に読み込むを使用して、&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;メソッド&lt;/xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;。</target>       </trans-unit>
        <trans-unit id="232" translate="yes" xml:space="preserve">
          <source>The speech recognition grammar to load.</source>
          <target state="translated">音声認識文法を読み込めません。</target>       </trans-unit>
        <trans-unit id="233" translate="yes" xml:space="preserve">
          <source>Asynchronously loads a speech recognition grammar.</source>
          <target state="translated">音声認識の文法を非同期的に読み込みます。</target>       </trans-unit>
        <trans-unit id="234" translate="yes" xml:space="preserve">
          <source>When the recognizer completes this asynchronous operation, it raises a &lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted&gt; event.</source>
          <target state="translated">認識エンジンには、この非同期操作が完了すると、それを発生させる、&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted&gt;イベント&lt;/xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted&gt;。</target>       </trans-unit>
        <trans-unit id="235" translate="yes" xml:space="preserve">
          <source>The recognizer throws an exception if the speech recognition grammar is already loaded, is being asynchronously loaded, or has failed to load into any recognizer.</source>
          <target state="translated">認識エンジンは、音声認識の文法が既に読み込まれて、非同期的に読み込まれる、またはがすべての認識エンジンに読み込めませんだった場合に例外をスローします。</target>       </trans-unit>
        <trans-unit id="236" translate="yes" xml:space="preserve">
          <source>If the recognizer is running, applications must use &lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt; to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
          <target state="translated">認識エンジンが実行されている場合、アプリケーションが使用する必要があります&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;を読み込み、アンロードが有効にすると、または、文法を無効にする前に、音声認識エンジンを一時停止します&lt;/xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;。</target>       </trans-unit>
        <trans-unit id="237" translate="yes" xml:space="preserve">
          <source>To load a speech recognition grammar synchronously, use the &lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A&gt; method.</source>
          <target state="translated">音声認識の文法を同期的に読み込むを使用して、&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A&gt;メソッド&lt;/xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A&gt;。</target>       </trans-unit>
        <trans-unit id="238" translate="yes" xml:space="preserve">
          <source>The speech recognition grammar to load.</source>
          <target state="translated">音声認識文法を読み込めません。</target>       </trans-unit>
        <trans-unit id="239" translate="yes" xml:space="preserve">
          <source>Occurs when the recognizer finishes the asynchronous loading of a speech recognition grammar.</source>
          <target state="translated">認識エンジンには、音声認識の文法の非同期読み込みが完了したときに発生します。</target>       </trans-unit>
        <trans-unit id="240" translate="yes" xml:space="preserve">
          <source>The recognizer's &lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt; method initiates an asynchronous operation.</source>
          <target state="translated">認識エンジンの&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;メソッドが非同期操作を開始します&lt;/xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;。</target>       </trans-unit>
        <trans-unit id="241" translate="yes" xml:space="preserve">
          <source>The recognizer raises the <ph id="ph1">`LoadGrammarCompleted`</ph> event when it completes the operation.</source>
          <target state="translated">認識エンジンが発生し、<ph id="ph1">`LoadGrammarCompleted`</ph>イベント、操作が完了するとします。</target>       </trans-unit>
        <trans-unit id="242" translate="yes" xml:space="preserve">
          <source>To get the &lt;xref:System.Speech.Recognition.Grammar&gt; object that the recognizer loaded, use the &lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A&gt; property of the associated &lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt;.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.Grammar&gt;認識エンジンが読み込まれているオブジェクトが&lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A&gt;関連付けられている&lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt;。&lt;/xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt;のプロパティ&lt;/xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A&gt;を使用して&lt;/xref:System.Speech.Recognition.Grammar&gt;取得するには</target>       </trans-unit>
        <trans-unit id="243" translate="yes" xml:space="preserve">
          <source>To get the current &lt;xref:System.Speech.Recognition.Grammar&gt; objects the recognizer has loaded, use the recognizer's &lt;xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A&gt; property.</source>
          <target state="translated">現在の取得に&lt;xref:System.Speech.Recognition.Grammar&gt;認識エンジンが読み込まれたオブジェクトは、認識エンジンを使用して&lt;xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A&gt;プロパティ&lt;/xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A&gt;&lt;/xref:System.Speech.Recognition.Grammar&gt;。</target>       </trans-unit>
        <trans-unit id="244" translate="yes" xml:space="preserve">
          <source>When you create a delegate for a <ph id="ph1">`LoadGrammarCompleted`</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">デリゲートを作成する場合、<ph id="ph1">`LoadGrammarCompleted`</ph>イベント、イベントを処理するメソッドを指定します。</target>       </trans-unit>
        <trans-unit id="245" translate="yes" xml:space="preserve">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">イベントをイベント ハンドラーに関連付けるには、イベントに、デリゲートのインスタンスを追加します。</target>       </trans-unit>
        <trans-unit id="246" translate="yes" xml:space="preserve">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">デリゲートを削除しない限り、イベントが発生するたびに、イベント ハンドラーが呼び出されます。</target>       </trans-unit>
        <trans-unit id="247" translate="yes" xml:space="preserve">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">イベント ハンドラー デリゲートの詳細については、次を参照してください。<bpt id="p1">[</bpt>イベントとデリゲート<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>です。</target>       </trans-unit>
        <trans-unit id="248" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">追加します。</target>       </trans-unit>
        <trans-unit id="249" translate="yes" xml:space="preserve">
          <source>Gets or sets the maximum number of alternate recognition results that the shared recognizer returns for each recognition operation.</source>
          <target state="translated">取得または認識操作ごとに、共有認識エンジンを表す代替認識の結果の最大数を設定します。</target>       </trans-unit>
        <trans-unit id="250" translate="yes" xml:space="preserve">
          <source>The &lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt; property of the &lt;xref:System.Speech.Recognition.RecognitionResult&gt; class contains the collection of &lt;xref:System.Speech.Recognition.RecognizedPhrase&gt; objects that represent other candidate interpretations of the input.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;のプロパティ、&lt;xref:System.Speech.Recognition.RecognitionResult&gt;クラスのコレクションを格納する&lt;xref:System.Speech.Recognition.RecognizedPhrase&gt;入力の他の候補の解釈を表すオブジェクト&lt;/xref:System.Speech.Recognition.RecognizedPhrase&gt;&lt;/xref:System.Speech.Recognition.RecognitionResult&gt;&lt;/xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;。</target>       </trans-unit>
        <trans-unit id="251" translate="yes" xml:space="preserve">
          <source>The default value for MaxAlternates is 10.</source>
          <target state="translated">MaxAlternates の既定値は 10 です。</target>       </trans-unit>
        <trans-unit id="252" translate="yes" xml:space="preserve">
          <source>The maximum number of alternate results that the speech recognizer returns for each recognition operation.</source>
          <target state="translated">音声認識エンジンが認識操作ごとに返す代替結果の最大数。</target>       </trans-unit>
        <trans-unit id="253" translate="yes" xml:space="preserve">
          <source>Gets or sets a value that indicates whether the shared recognizer pauses recognition operations while an application is handling a <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> event.</source>
          <target state="translated">取得またはアプリケーションの処理中には、共有認識エンジンが認識操作を一時停止するかどうかを示す値を設定、 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept>イベント。</target>       </trans-unit>
        <trans-unit id="254" translate="yes" xml:space="preserve">
          <source>Set this property to <ph id="ph1">`true`</ph>, if within the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; event handler your application needs to change the state of the speech recognition service or change the loaded or enabled speech recognition grammars before the speech recognition service processes more input.</source>
          <target state="translated">このプロパティを設定<ph id="ph1">`true`</ph>場合は、内で、&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;イベント ハンドラーが、アプリケーションは、音声認識サービスの状態を変更するか、音声認識サービスは、複数の入力を処理する前に読み込まれたまたは有効な音声認識の文法を変更する必要があります&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;。</target>       </trans-unit>
        <trans-unit id="255" translate="yes" xml:space="preserve">
          <source>&gt; <ph id="ph1">[!NOTE]</ph> &gt;  Setting the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; property to <ph id="ph2">`true`</ph> causes each &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; event handler in every application to block the Windows speech recognition service.</source>
          <target state="translated">&gt; <ph id="ph1">[!NOTE]</ph> &gt; 設定、&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;プロパティを<ph id="ph2">`true`</ph>と、 &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;Windows 音声認識サービスをブロックするすべてのアプリケーション内のイベント ハンドラー&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; 。</target>       </trans-unit>
        <trans-unit id="256" translate="yes" xml:space="preserve">
          <source>To synchronize the changes to the shared recognizer with your application state, use the &lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt; method.</source>
          <target state="translated">アプリケーションの状態で、共有認識エンジンへの変更を同期するために使用して、&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;メソッド&lt;/xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;。</target>       </trans-unit>
        <trans-unit id="257" translate="yes" xml:space="preserve">
          <source>When PauseRecognizerOnRecognition is <ph id="ph1">`true`</ph>, during the execution of the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; handler the speech recognition service pauses and buffers new audio input as it arrives.</source>
          <target state="translated">PauseRecognizerOnRecognition が場合<ph id="ph1">`true`</ph>の実行中に、&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;ハンドラー、音声認識サービスが一時停止し、受信する新しいオーディオ入力をバッファーします&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;。</target>       </trans-unit>
        <trans-unit id="258" translate="yes" xml:space="preserve">
          <source>Once the &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt; event handler exits, the speech recognition service resumes recognition and starts processing information from its input buffer.</source>
          <target state="translated">1 回、&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;イベント ハンドラーが終了する音声の認識サービスを再開し、入力バッファーからの情報の処理を開始します&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;。</target>       </trans-unit>
        <trans-unit id="259" translate="yes" xml:space="preserve">
          <source>To enable or disable the speech recognition service, use the &lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt; property.</source>
          <target state="translated">を有効にするにまたは音声認識サービスを無効にするには、&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;プロパティ。&lt;/xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</target>       </trans-unit>
        <trans-unit id="260" translate="yes" xml:space="preserve">
          <source><bpt id="p1">&lt;xref uid="langword_csharp_true" name="true" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> if the shared recognizer waits to process input while any application is handling the <bpt id="p2">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized"&gt;</bpt><ept id="p2">&lt;/xref&gt;</ept> event; otherwise, <bpt id="p3">&lt;xref uid="langword_csharp_false" name="false" href=""&gt;</bpt><ept id="p3">&lt;/xref&gt;</ept>.</source>
          <target state="translated"><bpt id="p1">&lt;xref uid="langword_csharp_true" name="true" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept>任意のアプリケーションの処理中に入力を処理する、共有認識エンジンが待機する場合、 <bpt id="p2">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized"&gt;</bpt> <ept id="p2">&lt;/xref&gt;</ept>イベントです。 それ以外の場合、 <bpt id="p3">&lt;xref uid="langword_csharp_false" name="false" href=""&gt;</bpt><ept id="p3">&lt;/xref&gt;</ept>です。</target>       </trans-unit>
        <trans-unit id="261" translate="yes" xml:space="preserve">
          <source>Gets the current location of the recognizer in the audio input that it is processing.</source>
          <target state="translated">オーディオの入力を処理しているので、認識エンジンの現在の場所を取得します。</target>       </trans-unit>
        <trans-unit id="262" translate="yes" xml:space="preserve">
          <source>The <ph id="ph1">`RecognizerAudioPosition`</ph> property references the recognizer's position in processing its audio input.</source>
          <target state="translated"><ph id="ph1">`RecognizerAudioPosition`</ph>プロパティは、オーディオ入力の処理の認識エンジンの位置を参照します。</target>       </trans-unit>
        <trans-unit id="263" translate="yes" xml:space="preserve">
          <source>By contrast, the &lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt; property references the input device's position in its generated audio stream.</source>
          <target state="translated">これに対し、&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;プロパティは、生成されたオーディオ ストリーム内の入力デバイスの位置を参照します&lt;/xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;。</target>       </trans-unit>
        <trans-unit id="264" translate="yes" xml:space="preserve">
          <source>These positions can be different.</source>
          <target state="translated">これらの位置は別にすることはできます。</target>       </trans-unit>
        <trans-unit id="265" translate="yes" xml:space="preserve">
          <source>For example, if the recognizer has received input for which it has not yet generated a recognition result then the value of the RecognizerAudioPosition property is less than the value of the &lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt; property.</source>
          <target state="translated">たとえば、認識エンジンが受信したがされていない入力をまだ場合 RecognizerAudioPosition プロパティの値がの値より小さい、認識の結果を生成、&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;プロパティ&lt;/xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;。</target>       </trans-unit>
        <trans-unit id="266" translate="yes" xml:space="preserve">
          <source>The position of the recognizer in the audio input that it is processing.</source>
          <target state="translated">オーディオの入力を処理しているので、認識エンジンの位置。</target>       </trans-unit>
        <trans-unit id="267" translate="yes" xml:space="preserve">
          <source>Gets information about the shared speech recognizer.</source>
          <target state="translated">共有音声認識エンジンに関する情報を取得します。</target>       </trans-unit>
        <trans-unit id="268" translate="yes" xml:space="preserve">
          <source>This property returns information about the speech recognizer in use by Windows Speech Recognition.</source>
          <target state="translated">このプロパティは、Windows 音声認識で使用中の音声認識エンジンに関する情報を返します。</target>       </trans-unit>
        <trans-unit id="269" translate="yes" xml:space="preserve">
          <source>Information about the shared speech recognizer.</source>
          <target state="translated">共有音声認識機能について説明します。</target>       </trans-unit>
        <trans-unit id="270" translate="yes" xml:space="preserve">
          <source>Occurs when the recognizer pauses to synchronize recognition and other operations.</source>
          <target state="translated">認識エンジンが認識し、その他の操作を同期するために置いたときに発生します。</target>       </trans-unit>
        <trans-unit id="271" translate="yes" xml:space="preserve">
          <source>Applications must use &lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt; to pause a running instance of &lt;xref:System.Speech.Recognition.SpeechRecognizer&gt; before modifying its &lt;xref:System.Speech.Recognition.Grammar&gt; objects.</source>
          <target state="translated">アプリケーションを使用する必要があります&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;を実行中のインスタンスを一時停止する&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;変更する前にその&lt;xref:System.Speech.Recognition.Grammar&gt;オブジェクト&lt;/xref:System.Speech.Recognition.Grammar&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognizer&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;。</target>       </trans-unit>
        <trans-unit id="272" translate="yes" xml:space="preserve">
          <source>For example, while the &lt;xref:System.Speech.Recognition.SpeechRecognizer&gt; is paused, you can load, unload, enable, and disable &lt;xref:System.Speech.Recognition.Grammar&gt; objects.</source>
          <target state="translated">などの&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;が一時停止していることができますをロード、アンロード、有効にするには、または無効化する&lt;xref:System.Speech.Recognition.Grammar&gt;オブジェクト&lt;/xref:System.Speech.Recognition.Grammar&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognizer&gt;。</target>       </trans-unit>
        <trans-unit id="273" translate="yes" xml:space="preserve">
          <source>The &lt;xref:System.Speech.Recognition.SpeechRecognizer&gt; raises this event when it is ready to accept modifications.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;変更を受け入れる準備ができたときにこのイベントを発生させます&lt;/xref:System.Speech.Recognition.SpeechRecognizer&gt;。</target>       </trans-unit>
        <trans-unit id="274" translate="yes" xml:space="preserve">
          <source>When you create a delegate for a RecognizerUpdateReached event, you identify the method that will handle the event.</source>
          <target state="translated">RecognizerUpdateReached イベントのデリゲートを作成するときに、イベントを処理するメソッドを特定します。</target>       </trans-unit>
        <trans-unit id="275" translate="yes" xml:space="preserve">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">イベントをイベント ハンドラーに関連付けるには、イベントに、デリゲートのインスタンスを追加します。</target>       </trans-unit>
        <trans-unit id="276" translate="yes" xml:space="preserve">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">デリゲートを削除しない限り、イベントが発生するたびに、イベント ハンドラーが呼び出されます。</target>       </trans-unit>
        <trans-unit id="277" translate="yes" xml:space="preserve">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">イベント ハンドラー デリゲートの詳細については、次を参照してください。<bpt id="p1">[</bpt>イベントとデリゲート<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>です。</target>       </trans-unit>
        <trans-unit id="278" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">追加します。</target>       </trans-unit>
        <trans-unit id="279" translate="yes" xml:space="preserve">
          <source>Requests that the shared recognizer pause and update its state.</source>
          <target state="translated">要求、共有認識エンジンが一時停止し、その状態を更新します。</target>       </trans-unit>
        <trans-unit id="280" translate="yes" xml:space="preserve">
          <source>When the recognizer generates the &lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt; event, the &lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt; property of the &lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; is <ph id="ph1">`null`</ph>.</source>
          <target state="translated">認識エンジンが生成するとき、&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;イベント、&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;のプロパティ、&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;は<ph id="ph1">`null`</ph>&lt;/xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;&lt;/xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;。</target>       </trans-unit>
        <trans-unit id="281" translate="yes" xml:space="preserve">
          <source>To provide a user token, use the &lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt; method.</source>
          <target state="translated">ユーザー トークンを指定するには、&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;または&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;メソッド&lt;/xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;。</target>       </trans-unit>
        <trans-unit id="282" translate="yes" xml:space="preserve">
          <source>To specify an audio position offset, use the &lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt; method.</source>
          <target state="translated">オーディオの位置のオフセットを指定するには、使用、&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;メソッド&lt;/xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;。</target>       </trans-unit>
        <trans-unit id="283" translate="yes" xml:space="preserve">
          <source>Requests that the shared recognizer pause and update its state and provides a user token for the associated event.</source>
          <target state="translated">要求を共有認識エンジンを一時停止の状態の更新プログラムと関連付けられているイベントのユーザー トークンを提供します。</target>       </trans-unit>
        <trans-unit id="284" translate="yes" xml:space="preserve">
          <source>When the recognizer generates the &lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt; event, the &lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt; property of the &lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; contains the value of the <ph id="ph1">`userToken`</ph> parameter.</source>
          <target state="translated">認識エンジンが生成するとき、&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;イベント、&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;のプロパティ、&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;の値が含まれています、<ph id="ph1">`userToken`</ph>パラメーター&lt;/xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; &lt;/xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt; 。</target>       </trans-unit>
        <trans-unit id="285" translate="yes" xml:space="preserve">
          <source>To specify an audio position offset, use the &lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt; method.</source>
          <target state="translated">オーディオの位置のオフセットを指定するには、使用、&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;メソッド&lt;/xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;。</target>       </trans-unit>
        <trans-unit id="286" translate="yes" xml:space="preserve">
          <source>User-defined information that contains information for the operation.</source>
          <target state="translated">ユーザー定義情報を操作の情報が含まれています。</target>       </trans-unit>
        <trans-unit id="287" translate="yes" xml:space="preserve">
          <source>Requests that the shared recognizer pause and update its state and provides an offset and a user token for the associated event.</source>
          <target state="translated">要求を共有認識エンジンを一時停止の状態の更新プログラムと関連付けられているイベントのオフセット、およびユーザーのトークンを提供します。</target>       </trans-unit>
        <trans-unit id="288" translate="yes" xml:space="preserve">
          <source>The recognizer does not initiate the recognizer update request until the recognizer's &lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt; equals the current &lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt; plus the value of the <ph id="ph1">`audioPositionAheadToRaiseUpdate`</ph> parameter.</source>
          <target state="translated">認識エンジンが認識エンジンのまで認識エンジンの更新要求を開始できません&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;現在に等しい&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;の値に加えて、<ph id="ph1">`audioPositionAheadToRaiseUpdate`</ph>パラメーター&lt;/xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt; 。</target>       </trans-unit>
        <trans-unit id="289" translate="yes" xml:space="preserve">
          <source>When the recognizer generates the &lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt; event, the &lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt; property of the &lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; contains the value of the <ph id="ph1">`userToken`</ph> parameter.</source>
          <target state="translated">認識エンジンが生成するとき、&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;イベント、&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;のプロパティ、&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;の値が含まれています、<ph id="ph1">`userToken`</ph>パラメーター&lt;/xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; &lt;/xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt; 。</target>       </trans-unit>
        <trans-unit id="290" translate="yes" xml:space="preserve">
          <source>User-defined information that contains information for the operation.</source>
          <target state="translated">ユーザー定義情報を操作の情報が含まれています。</target>       </trans-unit>
        <trans-unit id="291" translate="yes" xml:space="preserve">
          <source>The offset from the current &lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition*&gt; to delay the request.</source>
          <target state="translated">現在のオフセット&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition*&gt;を要求を遅延します&lt;/xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition*&gt;。</target>       </trans-unit>
        <trans-unit id="292" translate="yes" xml:space="preserve">
          <source>Occurs when the recognizer detects input that it can identify as speech.</source>
          <target state="translated">認識エンジンが音声として特定することの入力を検出したときに発生します。</target>       </trans-unit>
        <trans-unit id="293" translate="yes" xml:space="preserve">
          <source>The shared recognizer can raise this event in response to input.</source>
          <target state="translated">共有認識エンジンには、このイベントの入力に応答を生成できます。</target>       </trans-unit>
        <trans-unit id="294" translate="yes" xml:space="preserve">
          <source>The &lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A&gt; property of the associated &lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs&gt; object indicates location in the input stream where the recognizer detected speech.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A&gt;、関連するプロパティ&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs&gt;オブジェクトを認識エンジンが音声を認識する場合、入力ストリーム内の場所を示します&lt;/xref:System.Speech.Recognition.SpeechDetectedEventArgs&gt;&lt;/xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A&gt;。</target>       </trans-unit>
        <trans-unit id="295" translate="yes" xml:space="preserve">
          <source>For more information see the &lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt; and &lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt; properties and the &lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt; and &lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt; methods.</source>
          <target state="translated">詳細については、次を参照してください、&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;と&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;プロパティおよび&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;と&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;メソッド。&lt;/xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt; &lt;/xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt; 。</target>       </trans-unit>
        <trans-unit id="296" translate="yes" xml:space="preserve">
          <source>When you create a delegate for a SpeechDetected event, you identify the method that will handle the event.</source>
          <target state="translated">SpeechDetected イベントのデリゲートを作成するときに、イベントを処理するメソッドを特定します。</target>       </trans-unit>
        <trans-unit id="297" translate="yes" xml:space="preserve">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">イベントをイベント ハンドラーに関連付けるには、イベントに、デリゲートのインスタンスを追加します。</target>       </trans-unit>
        <trans-unit id="298" translate="yes" xml:space="preserve">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">デリゲートを削除しない限り、イベントが発生するたびに、イベント ハンドラーが呼び出されます。</target>       </trans-unit>
        <trans-unit id="299" translate="yes" xml:space="preserve">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">イベント ハンドラー デリゲートの詳細については、次を参照してください。<bpt id="p1">[</bpt>イベントとデリゲート<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>です。</target>       </trans-unit>
        <trans-unit id="300" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">追加します。</target>       </trans-unit>
        <trans-unit id="301" translate="yes" xml:space="preserve">
          <source>Occurs when the recognizer has recognized a word or words that may be a component of multiple complete phrases in a grammar.</source>
          <target state="translated">単語または単語を文法で語句全体を複数のコンポーネントである可能性があります、認識エンジンが認識されたときに発生します。</target>       </trans-unit>
        <trans-unit id="302" translate="yes" xml:space="preserve">
          <source>The shared recognizer can raise this event when the input is ambiguous.</source>
          <target state="translated">共有認識エンジンには、入力があいまいな場合は、このイベントを生成できます。</target>       </trans-unit>
        <trans-unit id="303" translate="yes" xml:space="preserve">
          <source>For example, for a speech recognition grammar that supports recognition of either "new game please" or "new game", "new game please" is an unambiguous input, and "new game" is an ambiguous input.</source>
          <target state="translated">たとえば、いずれかの認識をサポートする音声認識文法"新しいゲームをしてください。"または"新しいゲーム"、"新しいゲームをしてください"、あいまいさのない入力は、"新しいゲーム"はあいまいな入力です。</target>       </trans-unit>
        <trans-unit id="304" translate="yes" xml:space="preserve">
          <source>When you create a delegate for a SpeechHypothesized event, you identify the method that will handle the event.</source>
          <target state="translated">SpeechHypothesized イベントのデリゲートを作成するときに、イベントを処理するメソッドを特定します。</target>       </trans-unit>
        <trans-unit id="305" translate="yes" xml:space="preserve">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">イベントをイベント ハンドラーに関連付けるには、イベントに、デリゲートのインスタンスを追加します。</target>       </trans-unit>
        <trans-unit id="306" translate="yes" xml:space="preserve">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">デリゲートを削除しない限り、イベントが発生するたびに、イベント ハンドラーが呼び出されます。</target>       </trans-unit>
        <trans-unit id="307" translate="yes" xml:space="preserve">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">イベント ハンドラー デリゲートの詳細については、次を参照してください。<bpt id="p1">[</bpt>イベントとデリゲート<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>です。</target>       </trans-unit>
        <trans-unit id="308" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">追加します。</target>       </trans-unit>
        <trans-unit id="309" translate="yes" xml:space="preserve">
          <source>Occurs when the recognizer receives input that does not match any of the speech recognition grammars it has loaded.</source>
          <target state="translated">認識エンジンが読み込まれた音声認識の文法のいずれかに一致しない入力を受け取ると発生します。</target>       </trans-unit>
        <trans-unit id="310" translate="yes" xml:space="preserve">
          <source>The shared recognizer raises this event if it determines that input does not match with sufficient confidence any of the loaded speech recognition grammars.</source>
          <target state="translated">共有認識エンジンは、入力が一致しないことための十分な信頼で読み込まれた音声認識の文法のいずれかを判断した場合、このイベントを発生させます。</target>       </trans-unit>
        <trans-unit id="311" translate="yes" xml:space="preserve">
          <source>The &lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt; property of the &lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; contains the rejected &lt;xref:System.Speech.Recognition.RecognitionResult&gt; object.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;のプロパティ、 &lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;、拒否されたを含む&lt;xref:System.Speech.Recognition.RecognitionResult&gt;オブジェクト&lt;/xref:System.Speech.Recognition.RecognitionResult&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;&lt;/xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;。</target>       </trans-unit>
        <trans-unit id="312" translate="yes" xml:space="preserve">
          <source>Confidence thresholds for the shared recognizer, managed by &lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;, are associated with a user profile and stored in the Windows registry.</source>
          <target state="translated">信頼度のしきい値によって管理される共有認識エンジンを&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;のユーザー プロファイルに関連付けられているし、Windows レジストリに格納されている&lt;/xref:System.Speech.Recognition.SpeechRecognizer&gt;。</target>       </trans-unit>
        <trans-unit id="313" translate="yes" xml:space="preserve">
          <source>Applications should not write changes to the registry for the properties of the shared recognizer.</source>
          <target state="translated">アプリケーションは、プロパティ、共有認識エンジンのレジストリに変更を書き込めません必要があります。</target>       </trans-unit>
        <trans-unit id="314" translate="yes" xml:space="preserve">
          <source>When you create a delegate for a SpeechRecognitionRejected event, you identify the method that will handle the event.</source>
          <target state="translated">SpeechRecognitionRejected イベントのデリゲートを作成するときに、イベントを処理するメソッドを特定します。</target>       </trans-unit>
        <trans-unit id="315" translate="yes" xml:space="preserve">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">イベントをイベント ハンドラーに関連付けるには、イベントに、デリゲートのインスタンスを追加します。</target>       </trans-unit>
        <trans-unit id="316" translate="yes" xml:space="preserve">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">デリゲートを削除しない限り、イベントが発生するたびに、イベント ハンドラーが呼び出されます。</target>       </trans-unit>
        <trans-unit id="317" translate="yes" xml:space="preserve">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">イベント ハンドラー デリゲートの詳細については、次を参照してください。<bpt id="p1">[</bpt>イベントとデリゲート<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>です。</target>       </trans-unit>
        <trans-unit id="318" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">追加します。</target>       </trans-unit>
        <trans-unit id="319" translate="yes" xml:space="preserve">
          <source>Occurs when the recognizer receives input that matches one of its speech recognition grammars.</source>
          <target state="translated">認識エンジンが、音声認識の文法の&amp;1; つに一致する入力を受け取ると発生します。</target>       </trans-unit>
        <trans-unit id="320" translate="yes" xml:space="preserve">
          <source>The recognizer raises the <ph id="ph1">`SpeechRecognized`</ph> event if it determines with sufficient confidence that input matches one of the loaded and enabled speech recognition grammars.</source>
          <target state="translated">認識エンジンが発生し、<ph id="ph1">`SpeechRecognized`</ph>自信のための十分な入力はアンロードされ、有効な音声認識の文法の&amp;1; つに一致するいると判断した場合のイベントです。</target>       </trans-unit>
        <trans-unit id="321" translate="yes" xml:space="preserve">
          <source>The &lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt; property of the &lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; contains the accepted &lt;xref:System.Speech.Recognition.RecognitionResult&gt; object.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;のプロパティ、&lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;承諾が含まれています&lt;xref:System.Speech.Recognition.RecognitionResult&gt;オブジェクト&lt;/xref:System.Speech.Recognition.RecognitionResult&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;&lt;/xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;。</target>       </trans-unit>
        <trans-unit id="322" translate="yes" xml:space="preserve">
          <source>Confidence thresholds for the shared recognizer, managed by &lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;, are associated with a user profile and stored in the Windows registry.</source>
          <target state="translated">信頼度のしきい値によって管理される共有認識エンジンを&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;のユーザー プロファイルに関連付けられているし、Windows レジストリに格納されている&lt;/xref:System.Speech.Recognition.SpeechRecognizer&gt;。</target>       </trans-unit>
        <trans-unit id="323" translate="yes" xml:space="preserve">
          <source>Applications should not write changes to the registry for the properties of the shared recognizer.</source>
          <target state="translated">アプリケーションは、プロパティ、共有認識エンジンのレジストリに変更を書き込めません必要があります。</target>       </trans-unit>
        <trans-unit id="324" translate="yes" xml:space="preserve">
          <source>When the recognizer receives input that matches a grammar, the &lt;xref:System.Speech.Recognition.Grammar&gt; object can raise the &lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt; event.</source>
          <target state="translated">認識エンジンが、文法に一致する入力を受け取るときに、&lt;xref:System.Speech.Recognition.Grammar&gt;オブジェクトを発生させることができます、&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;イベント&lt;/xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;&lt;/xref:System.Speech.Recognition.Grammar&gt;。</target>       </trans-unit>
        <trans-unit id="325" translate="yes" xml:space="preserve">
          <source>The &lt;xref:System.Speech.Recognition.Grammar&gt; object's &lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt; event is raised prior to the speech recognizer's SpeechRecognized event.</source>
          <target state="translated">&lt;xref:System.Speech.Recognition.Grammar&gt;オブジェクトの&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;イベントは、音声認識エンジンの SpeechRecognized イベントの前に発生します&lt;/xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;&lt;/xref:System.Speech.Recognition.Grammar&gt;。</target>       </trans-unit>
        <trans-unit id="326" translate="yes" xml:space="preserve">
          <source>When you create a delegate for a SpeechRecognized event, you identify the method that will handle the event.</source>
          <target state="translated">SpeechRecognized イベントのデリゲートを作成するときに、イベントを処理するメソッドを特定します。</target>       </trans-unit>
        <trans-unit id="327" translate="yes" xml:space="preserve">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">イベントをイベント ハンドラーに関連付けるには、イベントに、デリゲートのインスタンスを追加します。</target>       </trans-unit>
        <trans-unit id="328" translate="yes" xml:space="preserve">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">デリゲートを削除しない限り、イベントが発生するたびに、イベント ハンドラーが呼び出されます。</target>       </trans-unit>
        <trans-unit id="329" translate="yes" xml:space="preserve">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">イベント ハンドラー デリゲートの詳細については、次を参照してください。<bpt id="p1">[</bpt>イベントとデリゲート<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>です。</target>       </trans-unit>
        <trans-unit id="330" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">追加します。</target>       </trans-unit>
        <trans-unit id="331" translate="yes" xml:space="preserve">
          <source>Gets the state of a <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognizer"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> object.</source>
          <target state="translated">状態を取得、 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognizer"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept>オブジェクト。</target>       </trans-unit>
        <trans-unit id="332" translate="yes" xml:space="preserve">
          <source>This read-only property indicates whether the shared recognizer resident in Windows is in the <ph id="ph1">`Stopped`</ph> or the <ph id="ph2">`Listening`</ph> state.</source>
          <target state="translated">この読み取り専用プロパティは、Windows に常駐している、共有認識エンジンがかどうかを示す、<ph id="ph1">`Stopped`</ph>または<ph id="ph2">`Listening`</ph>状態です。</target>       </trans-unit>
        <trans-unit id="333" translate="yes" xml:space="preserve">
          <source>For more information, see the &lt;xref:System.Speech.Recognition.RecognizerState&gt; enumeration.</source>
          <target state="translated">詳細については、次を参照してください、&lt;xref:System.Speech.Recognition.RecognizerState&gt;列挙体です。&lt;/xref:System.Speech.Recognition.RecognizerState&gt; 。</target>       </trans-unit>
        <trans-unit id="334" translate="yes" xml:space="preserve">
          <source>The state of the <bpt id="p1">&lt;xref uid="langword_csharp_SpeechRecognizer" name="SpeechRecognizer" href=""&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> object.</source>
          <target state="translated">状態、 <bpt id="p1">&lt;xref uid="langword_csharp_SpeechRecognizer" name="SpeechRecognizer" href=""&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept>オブジェクト。</target>       </trans-unit>
        <trans-unit id="335" translate="yes" xml:space="preserve">
          <source>Occurs when the running state of the Windows Desktop Speech Technology recognition engine changes.</source>
          <target state="translated">Windows デスクトップ音声テクノロジ認識エンジンの実行状態が変更されたときに発生します。</target>       </trans-unit>
        <trans-unit id="336" translate="yes" xml:space="preserve">
          <source>The shared recognizer raises this event when the state of Windows Speech Recognition changes to the &lt;xref:System.Speech.Recognition.RecognizerState&gt; or &lt;xref:System.Speech.Recognition.RecognizerState&gt; state.</source>
          <target state="translated">共有認識エンジンが Windows 音声認識の状態に変更したときに、このイベントを発生させる、&lt;xref:System.Speech.Recognition.RecognizerState&gt;または&lt;xref:System.Speech.Recognition.RecognizerState&gt;状態&lt;/xref:System.Speech.Recognition.RecognizerState&gt;&lt;/xref:System.Speech.Recognition.RecognizerState&gt;。</target>       </trans-unit>
        <trans-unit id="337" translate="yes" xml:space="preserve">
          <source>To get the state of the shared recognizer at the time of the event, use the &lt;xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A&gt; property of the associated &lt;xref:System.Speech.Recognition.StateChangedEventArgs&gt;.</source>
          <target state="translated">イベントの時点で、共有認識エンジンの状態を取得するには、&lt;xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A&gt;関連付けられている&lt;xref:System.Speech.Recognition.StateChangedEventArgs&gt;。&lt;/xref:System.Speech.Recognition.StateChangedEventArgs&gt;のプロパティ&lt;/xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A&gt;を使用します。</target>       </trans-unit>
        <trans-unit id="338" translate="yes" xml:space="preserve">
          <source>To get the current state of the shared recognizer, use the recognizer's &lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt; property.</source>
          <target state="translated">共有認識エンジンの現在の状態を取得するには、認識エンジンを使用&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;プロパティ&lt;/xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;。</target>       </trans-unit>
        <trans-unit id="339" translate="yes" xml:space="preserve">
          <source>When you create a delegate for a StateChanged event, you identify the method that will handle the event.</source>
          <target state="translated">StateChanged イベントのデリゲートを作成するときに、イベントを処理するメソッドを特定します。</target>       </trans-unit>
        <trans-unit id="340" translate="yes" xml:space="preserve">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">イベントをイベント ハンドラーに関連付けるには、イベントに、デリゲートのインスタンスを追加します。</target>       </trans-unit>
        <trans-unit id="341" translate="yes" xml:space="preserve">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">デリゲートを削除しない限り、イベントが発生するたびに、イベント ハンドラーが呼び出されます。</target>       </trans-unit>
        <trans-unit id="342" translate="yes" xml:space="preserve">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">イベント ハンドラー デリゲートの詳細については、次を参照してください。<bpt id="p1">[</bpt>イベントとデリゲート<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>です。</target>       </trans-unit>
        <trans-unit id="343" translate="yes" xml:space="preserve">
          <source>To be added.</source>
          <target state="translated">追加します。</target>       </trans-unit>
        <trans-unit id="344" translate="yes" xml:space="preserve">
          <source>Unloads all speech recognition grammars from the shared recognizer.</source>
          <target state="translated">共有認識エンジンからのすべての音声認識文法をアンロードします。</target>       </trans-unit>
        <trans-unit id="345" translate="yes" xml:space="preserve">
          <source>If the recognizer is currently loading a grammar asynchronously, this method waits until the grammar is loaded, before it unloads all of the recognizer's grammars.</source>
          <target state="translated">場合は、認識エンジンが現在を読み込んで、文法に非同期的に、このメソッドは、文法が読み込まれるまで、すべての認識エンジンの文法がアンロードする前に待機します。</target>       </trans-unit>
        <trans-unit id="346" translate="yes" xml:space="preserve">
          <source>To unload a specific grammar, use the &lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A&gt; method.</source>
          <target state="translated">特定の文法をアンロードするを使用して、&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A&gt;メソッド&lt;/xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A&gt;。</target>       </trans-unit>
        <trans-unit id="347" translate="yes" xml:space="preserve">
          <source>Unloads a specified speech recognition grammar from the shared recognizer.</source>
          <target state="translated">共有認識エンジンから、指定した音声認識の文法をアンロードします。</target>       </trans-unit>
        <trans-unit id="348" translate="yes" xml:space="preserve">
          <source>If the recognizer is running, applications must use &lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt; to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
          <target state="translated">認識エンジンが実行されている場合、アプリケーションが使用する必要があります&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;を読み込み、アンロードが有効にすると、または、文法を無効にする前に、音声認識エンジンを一時停止します&lt;/xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;。</target>       </trans-unit>
        <trans-unit id="349" translate="yes" xml:space="preserve">
          <source>To unload all grammars, use the &lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A&gt; method.</source>
          <target state="translated">すべての文法をアンロードするを使用して、&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A&gt;メソッド&lt;/xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A&gt;。</target>       </trans-unit>
        <trans-unit id="350" translate="yes" xml:space="preserve">
          <source>The grammar to unload.</source>
          <target state="translated">文法をアンロードします。</target>       </trans-unit>
      </group>
    </body>
  </file>
</xliff>