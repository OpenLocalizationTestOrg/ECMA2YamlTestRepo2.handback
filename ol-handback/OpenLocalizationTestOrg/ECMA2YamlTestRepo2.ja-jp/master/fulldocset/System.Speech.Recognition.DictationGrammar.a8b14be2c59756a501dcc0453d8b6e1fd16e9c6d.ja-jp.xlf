<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.2" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="markdown" source-language="en-US" target-language="ja-jp">
    <header>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-192e1fd" tool-company="Microsoft" />
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">22f39385ecce684bcfb895105100a0f9470eb8e3</xliffext:olfilehash>
      <xliffext:olfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">fulldocset\System.Speech.Recognition.DictationGrammar.yml</xliffext:olfilepath>
      <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">fulldocset</xliffext:oltranslationpriority>
      <xliffext:oltranslationtype xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">Human Translation</xliffext:oltranslationtype>
      <xliffext:olskeletonhash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">c20bfebe91132c14e63a2d4700648996861efb72</xliffext:olskeletonhash>
      <xliffext:olxliffhash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">288085b48535164a30aa62a9c56a3aeaf48064e7</xliffext:olxliffhash>
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Represents a speech recognition grammar used for free text dictation.</source>
          <target state="translated">フリー テキストのディクテーション モードを使用する音声認識の文法を表します。</target>       </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>This class provides applications with a predefined language model that can process spoken user input into text.</source>
          <target state="translated">このクラスは、話されたユーザーが入力テキストに処理できる定義済みの言語モデルを含むアプリケーションを提供します。</target>       </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>This class supports both default and custom DictationGrammar objects.</source>
          <target state="translated">このクラスは、既定とカスタム DictationGrammar オブジェクトの両方をサポートします。</target>       </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>For information about selecting a dictation grammar, see the &lt;xref:System.Speech.Recognition.DictationGrammar.%23ctor%28System.String%29&gt; constructor.</source>
          <target state="translated">ディクテーション文法の選択については、次を参照してください、&lt;xref:System.Speech.Recognition.DictationGrammar.%23ctor%28System.String%29&gt;コンス トラクター。&lt;/xref:System.Speech.Recognition.DictationGrammar.%23ctor%28System.String%29&gt; 。</target>       </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>By default, the DictationGrammar language model is context free.</source>
          <target state="translated">既定では、DictationGrammar 言語モデルは、無料のコンテキストです。</target>       </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>It does not make use of specific words or word order to identify and interpret audio input.</source>
          <target state="translated">特定の語句の使用または word の順序を特定し、オーディオ入力の解釈を行いません。</target>       </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>To add context to the dictation grammar, use the &lt;xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A&gt; method.</source>
          <target state="translated">ディクテーション文法にコンテキストを追加するには、使用、&lt;xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A&gt;メソッド&lt;/xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A&gt;。</target>       </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>&gt; <ph id="ph1">[!NOTE]</ph> &gt;  DictationGrammar objects do not support the &lt;xref:System.Speech.Recognition.Grammar.Priority%2A&gt; property.</source>
          <target state="translated">&gt; <ph id="ph1">[!NOTE]</ph> &gt; DictationGrammar オブジェクトでサポートされない、&lt;xref:System.Speech.Recognition.Grammar.Priority%2A&gt;プロパティ&lt;/xref:System.Speech.Recognition.Grammar.Priority%2A&gt;。</target>       </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>DictationGrammar throws a &lt;xref:System.NotSupportedException&gt; if &lt;xref:System.Speech.Recognition.Grammar.Priority%2A&gt; is set.</source>
          <target state="translated">DictationGrammar スロー、&lt;xref:System.NotSupportedException&gt;場合&lt;xref:System.Speech.Recognition.Grammar.Priority%2A&gt;が設定されています&lt;/xref:System.Speech.Recognition.Grammar.Priority%2A&gt;&lt;/xref:System.NotSupportedException&gt;。</target>       </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>Initializes a new instance of the <bpt id="p1">&lt;xref href="System.Speech.Recognition.DictationGrammar"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> class for the default dictation grammar provided by Windows Desktop Speech Technology.</source>
          <target state="translated">新しいインスタンスを初期化、 <bpt id="p1">&lt;xref href="System.Speech.Recognition.DictationGrammar"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept> Windows デスクトップ音声テクノロジによって提供される既定のディクテーション文法のクラスです。</target>       </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>The default dictation grammar emulates standard dictation practices, including punctuation.</source>
          <target state="translated">既定のディクテーション文法では、標準ディクテーション プラクティス、句読点を含むをエミュレートします。</target>       </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>It does not support the spelling of a word.</source>
          <target state="translated">単語のスペル チェックはサポートされません。</target>       </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>Initializes a new instance of the <bpt id="p1">&lt;xref href="System.Speech.Recognition.DictationGrammar"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> class with a specific dictation grammar.</source>
          <target state="translated">新しいインスタンスを初期化、 <bpt id="p1">&lt;xref href="System.Speech.Recognition.DictationGrammar"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept>特定ディクテーション文法を持つクラス。</target>       </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>The Speech platform uses a specialized URI syntax to define the custom dictation grammar.</source>
          <target state="translated">Speech プラットフォームでは、特殊な URI 構文を使用して、カスタム ディクテーション文法を定義します。</target>       </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>The value <ph id="ph1">`grammar:dictation`</ph> indicates the default dictation grammar.</source>
          <target state="translated">値<ph id="ph1">`grammar:dictation`</ph>既定ディクテーション文法を示します。</target>       </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>The value <ph id="ph1">`grammar:dictation#spelling`</ph> indicates the spelling dictation grammar.</source>
          <target state="translated">値<ph id="ph1">`grammar:dictation#spelling`</ph>文章ディクテーション モードを示します。</target>       </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>An XML-compliant Universal Resource Identifier (URI) that specifies the dictation grammar, either <ph id="ph1">`grammar:dictation`</ph> or <ph id="ph2">`grammar:dictation#spelling`</ph>.</source>
          <target state="translated">XML に準拠したユニバーサル リソース識別子 (URI) ディクテーション文法をいずれかを指定する<ph id="ph1">`grammar:dictation`</ph>または<ph id="ph2">`grammar:dictation#spelling`</ph>です。</target>       </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Adds a context to a dictation grammar that has been loaded by a <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognizer"&gt;</bpt><ept id="p1">&lt;/xref&gt;</ept> or a <bpt id="p2">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p2">&lt;/xref&gt;</ept> object.</source>
          <target state="translated">によって読み込まれているディクテーション文法にコンテキストを追加、 <bpt id="p1">&lt;xref href="System.Speech.Recognition.SpeechRecognizer"&gt;</bpt> <ept id="p1">&lt;/xref&gt;</ept>または<bpt id="p2">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine"&gt;</bpt><ept id="p2">&lt;/xref&gt;</ept>オブジェクト。</target>       </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>By default, the dictation grammar does not make use of specific words or word order to identify and interpret audio input.</source>
          <target state="translated">既定では、特定の語句の使用または word の順序を識別およびオーディオ入力を解釈することと、ディクテーション文法はありません。</target>       </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>When a context is added to a dictation grammar, the recognition engine uses the <ph id="ph1">`precedingText`</ph> and <ph id="ph2">`subsequentText`</ph> to identify when to interpret speech as dictation.</source>
          <target state="translated">認識エンジンを使用して、ディクテーション文法にコンテキストを追加するときに、<ph id="ph1">`precedingText`</ph>と<ph id="ph2">`subsequentText`</ph>ディクテーションと音声を解釈するタイミングを識別します。</target>       </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>&gt; <ph id="ph1">[!NOTE]</ph> &gt;  A dictation grammar must be loaded by a &lt;xref:System.Speech.Recognition.SpeechRecognizer&gt; or &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; object before you can use SetDictationContext to add a context.</source>
          <target state="translated">&gt; <ph id="ph1">[!NOTE]</ph> &gt; によってディクテーション文法を読み込む必要がある、&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;または&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;SetDictationContext を使用するには、コンテキストを追加する前にオブジェクトします&lt;/xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;&lt;/xref:System.Speech.Recognition.SpeechRecognizer&gt;。</target>       </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>The following table describes how the recognition engine uses the two parameters to determine when to use the dictation grammar.</source>
          <target state="translated">次の表では、認識エンジンが&amp;2; つのパラメーターを使用して、ディクテーション文法を使用するかを判断する方法について説明します。</target>       </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>|<ph id="ph1">`precedingText`</ph><ph id="ph2">|</ph><ph id="ph3">`subsequentText`</ph>|Description|   |---------------------|----------------------|-----------------|   |not <ph id="ph4">`null`</ph>|not <ph id="ph5">`null`</ph>|The recognition engine uses the terms to bracket possible candidate phrases.|   |<ph id="ph6">`null`</ph>|not <ph id="ph7">`null`</ph>|The recognition engine uses the <ph id="ph8">`subsequentText`</ph> to finish dictation.|   |not <ph id="ph9">`null`</ph><ph id="ph10">|</ph><ph id="ph11">`null`</ph>|The recognition engine uses the <ph id="ph12">`precedingText`</ph> to start dictation.|   |<ph id="ph13">`null`</ph><ph id="ph14">|</ph><ph id="ph15">`null`</ph>|The recognition engine does not use a context when using the dictation grammar.|</source>
          <target state="translated">|<ph id="ph1">`precedingText`</ph><ph id="ph2">|</ph><ph id="ph3">`subsequentText`</ph>|説明 |  |---------------------|----------------------|-----------------|  |not <ph id="ph4">`null`</ph>|not <ph id="ph5">`null`</ph>|認識エンジンは、用語を使用して候補語句を角かっこをします |。  |<ph id="ph6">`null`</ph>|not <ph id="ph7">`null`</ph>|認識エンジンを使用して、<ph id="ph8">`subsequentText`</ph>ディクテーション モードを終了する |。  |not <ph id="ph9">`null`</ph><ph id="ph10">|</ph><ph id="ph11">`null`</ph>|認識エンジンを使用して、<ph id="ph12">`precedingText`</ph>をディクテーション モードを開始します |。  |<ph id="ph13">`null`</ph><ph id="ph14">|</ph><ph id="ph15">`null`</ph>|ディクテーション文法を使用する場合、認識エンジンがコンテキストを使用しません |。</target>       </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Text that indicates the start of a dictation context.</source>
          <target state="translated">ディクテーション コンテキストの開始を示すテキスト。</target>       </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>Text that indicates the end of a dictation context.</source>
          <target state="translated">ディクテーション コンテキストの終了を示すテキストです。</target>       </trans-unit>
      </group>
    </body>
  </file>
</xliff>